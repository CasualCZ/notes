'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/notes/docs/technology/program/Revision/git/','title':"Git",'content':"Git简介 #  git是一个分布式版本控制软件，最初由林纳斯·托瓦兹（Linus Torvalds）创作，于2005年以GPL发布。最初目的是为更好地管理Linux内核开发而设计。\n  特点\n  速度\n  简单的设计\n  对非线性开发模式的强力支持（允许成千上万个并行开发的分支）\n  完全分布式\n  有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）\n    三种状态[工作区域]\n  已提交(commit),[Git仓库]\n  已修改(modified),[工作目录]\n  已暂存(staged),[暂存区域]\n    基本工作流程\n  在工作目录中修改文件\n  暂存文件，将文件的快照放入暂存区域。\n  提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n     Git安装 #  Git操作 #  "});index.add({'id':1,'href':'/notes/docs/technology/program/Revision/git/install/','title':"Git安装",'content':"Git安装 #    yum安装\n $ sudo yum install git    源码安装\n依赖包安装\n $ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc xmlto docbook2x  从 https://www.kernel.org/pub/software/scm/git获取最新的版本包\n编译安装\n $ tar -zxf git-2.0.0.tar.gz $ cd git-2.0.0 $ make configure $ ./configure --prefix=/usr/local/git $ make all doc info $ sudo make install install-doc install-html install-info  升级\n $ git clone git://git.kernel.org/pub/scm/git/git.git     Git初始配置 #  Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n  /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 \u0026ndash;system 选项的 git config 时，它会从此文件读写配置变量。\n  ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 \u0026ndash;global 选项让 Git 读写此文件。\n  当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n  每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n用户信息 #  当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n$ git config --global user.name \u0026quot;CodeCC\u0026quot; $ git config --global user.email CodeCC@example.com  再次强调，如果使用了 \u0026ndash;global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 \u0026ndash;global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n检查配置信息 #  如果想要检查你的配置，可以使用 git config \u0026ndash;list 命令来列出所有 Git 当时能找到的配置。\n$ git config --list user.name=CodeCC user.email=CodeCC@example.com ...  也可以通过输入 git config ： 来检查 Git 的某一项配置\n$ git config user.name CodeCC  "});index.add({'id':2,'href':'/notes/docs/technology/program/Revision/git/operation/','title':"Git操作",'content':"Git操作 #  创建版本库 #    创建一个空目录\n$ cd /usr/local/src\n $ mkdir project    创建版本库\n  初始化\n$ git init Initialized empty Git repository in /usr/local/src/project/.git/\n  克隆现有仓库\n$ git clone [url]\n    添加文件\n$ git add README.md\n $ git commit -m 'first commit'     记录更新 #  记录每次更新到仓库 #    文件状态\n  已跟踪文件\n  未修改\n  已修改\n  已放入暂存区\n    未跟踪文件\n    使用 Git 时文件的生命周期如下：\n  文件状态 #  git status 命令，用于查看哪些文件处于什么状态。\n已跟踪文件未被更改过，且没有处于未跟踪状态的新文件。会看到类似这样的输出：\n$ git status On branch master nothing to commit, working directory clean  存在新的未跟踪文件。会看到类似这样的输出：\n$ echo 'My Project' \u0026gt; README.md $ git status # On branch master # # Initial commit # # Untracked files: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed) # # README.md nothing added to commit but untracked files present (use \u0026quot;git add\u0026quot; to track)   跟踪新文件 #  使用命令 git add 开始跟踪一个文件。\n$ git add README.md  存在已跟踪文件，并处于暂存状态。会看到类似这样的输出：\n# On branch master # # Initial commit # # Changes to be committed: # (use \u0026quot;git rm --cached \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # new file: README.md #   暂存已修改文件 #  已跟踪文件的内容发生了变化，但还没有放到暂存区。会看到类似这样的输出：\n$ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # new file: README.md # # Changed but not updated: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # modified: CONTRIBUTING.md #  要暂存这次更新，需要运行 git add 命令。这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。\n$ git add CONTRIBUTING.md $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: CONTRIBUTING.md # new file: README.md #   状态简览 #  使用 git status -s 命令或 git status \u0026ndash;short 命令，获取一种更为紧凑的格式输出。 状态报告输出如下：\n$ git status -s M CONTRIBUTING.md A README.md ?? HELLO.md  状态标记详解\n??：新添加的未跟踪文件 A ：新添加到暂存区中的文件 M ：修改过得文件，并放入暂存区 M：修改过得文件，还未放入暂存区 MM：修改并提交到暂存区后又在工作区被修改   忽略文件 #  创建一个名为 .gitignore 的文件，列出要忽略的文件模式。\n$ cat .gitignore *.[oa] *~  文件 .gitignore 的格式规范如下：\n  所有空行或者以 # 开头的行都会被 Git 忽略。\n  可以使用标准的 glob 模式匹配。\n 星号（*）匹配零个或多个任意字符； [abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）; 问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。    匹配模式可以以（/）开头防止递归。\n  匹配模式可以以（/）结尾指定目录。\n  要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。\n  我们再看一个 .gitignore 文件的例子：\n# no .a files *.a # but do track lib.a, even though you're ignoring .a files above !lib.a # only ignore the TODO file in the current directory, not subdir/TODO /TODO # ignore all files in the build/ directory build/ # ignore doc/notes.txt, but not doc/server/arch.txt doc/*.txt # ignore all .pdf files in the doc/ directory doc/**/*.pdf  TIP GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表，你可以在 https://github.com/github/gitignore 找到它.\n 查看已暂存和未暂存的修改 #  git diff 命令，查看具体修改内容。 git diff 将通过文件补丁的格式显示具体哪些行发生了改变。\n查看尚未暂存的文件更新内容，直接输入 git diff：\n$ git diff diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 23509e0..90f904d 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -1,2 +1,3 @@ hello git +add con  此命令比较的是工作目录中当前文件和暂存区域快照之间的差异， 也就是修改之后还没有暂存起来的变化内容。\n若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff \u0026ndash;cached 命令。（Git 1.6.1 及更高版本还允许使用 git diff \u0026ndash;staged，效果是相同的，但更好记些。）\n$ git diff --staged diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index ce01362..90f904d 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -1 +1,3 @@ hello +git +add con diff --git a/README.md b/README.md new file mode 100644 index 0000000..de369b6 --- /dev/null +++ b/README.md @@ -0,0 +1,2 @@ +My Project +abc  请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。\n 提交更新 #  现在的暂存区域已经准备妥当可以提交了。 在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit, 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示：\n$ git commit -m 'modify file' [master d19800e] modify file 2 files changed, 4 insertions(+), 0 deletions(-) create mode 100644 README.md  好，现在你已经创建了第一个提交！ 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。\n请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。\n 跳过使用暂存区域 #  尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤：\n$ echo \u0026quot;follow me\u0026quot; \u0026gt;\u0026gt; CONTRIBUTING.md $ git status # On branch master # Changed but not updated: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # modified: CONTRIBUTING.md # no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) $ git commit -a -m 'added new benchmarks' [master 3bcc140] added new benchmarks 1 files changed, 1 insertions(+), 0 deletions(-)   移除文件 #  要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。\n如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 “Changes not staged for commit” 部分（也就是 未暂存清单）看到：\n$ rm project.md $ git status # On branch master # Changed but not updated: # (use \u0026quot;git add/rm \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # deleted: project.md # no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;)  然后再运行 git rm 记录此次移除文件的操作：\n$ git rm project.md rm 'project.md' $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # deleted: project.md #  下一次提交时，该文件就不再纳入版本管理了。 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母）。 这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。\n另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 \u0026ndash;cached 选项：\n$ git rm --cached README  git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说：\n$ git rm log/\\*.log  注意到星号 * 之前的反斜杠 \\， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如：\n$ git rm \\*~  该命令为删除以 ~ 结尾的所有文件。\n 移动文件 #  不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。\n既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做：\n$ git mv file_from file_to 它会恰如预期般正常工作。 实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明：\n$ git mv README.md README # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # renamed: README.md -\u0026gt; README #  其实，运行 git mv 就相当于运行了下面三条命令：\n$ mv README.md README $ git rm README.md $ git add README  如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式结果都一样。 两者唯一的区别是，mv 是一条命令而另一种方式需要三条命令，直接用 git mv 轻便得多。 不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。\n 提交历史 #  查看提交历史 #  git log 命令，查看提交历史。\n$ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit  ​ 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。\n git log 常用选项 #  -p，用来显示每次提交的内容差异。 你也可以加上 -2 来仅显示最近两次提交：\n$ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number diff --git a/Rakefile b/Rakefile index a874b73..8f94139 100644 --- a/Rakefile +++ b/Rakefile @@ -5,7 +5,7 @@ require 'rake/gempackagetask' spec = Gem::Specification.new do |s| s.platform = Gem::Platform::RUBY s.name = \u0026quot;simplegit\u0026quot; - s.version = \u0026quot;0.1.0\u0026quot; + s.version = \u0026quot;0.1.1\u0026quot; s.author = \u0026quot;Scott Chacon\u0026quot; s.email = \u0026quot;schacon@gee-mail.com\u0026quot; s.summary = \u0026quot;A simple gem for using Git in Ruby code.\u0026quot; commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test diff --git a/lib/simplegit.rb b/lib/simplegit.rb index a0a60ae..47c6340 100644 --- a/lib/simplegit.rb +++ b/lib/simplegit.rb @@ -18,8 +18,3 @@ class SimpleGit end end - -if $0 == __FILE__ - git = SimpleGit.new - puts git.show -end \\ No newline at end of file  \u0026ndash;stat，查看每次提交的简略的统计信息\n$ git log --stat commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test lib/simplegit.rb | 5 ----- 1 file changed, 5 deletions(-) commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit README | 6 ++++++ Rakefile | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+)  \u0026ndash;pretty。 指定使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 另外还有 short，full 和 fuller 可以用。\n$ git log --pretty=oneline ca82a6dff817ec66f44342007202690a93763949 changed the version number 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test a11bef06a3f659402fe7563abf99ad00de2209e6 first commit  但最有意思的是 format，可以定制要显示的记录格式。 这样的输出对后期提取分析格外有用 — 因为你知道输出的格式不会随着Git的更新而发生改变：\n$ git log --pretty=format:\u0026quot;%h - %an, %ar : %s\u0026quot; ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit  git log \u0026ndash;pretty=format 常用的选项\n   选项 说明     %H 提交对象（commit）的完整哈希字串   %h 提交对象的简短哈希字串   %T 树对象（tree）的完整哈希字串   %t 树对象的简短哈希字串   %P 父对象（parent）的完整哈希字串   %p 父对象的简短哈希字串   %an 作者（author）的名字   %ae 作者的电子邮件地址   %ad 作者修订日期（可以用 \u0026ndash;date= 选项定制格式）   %ar 作者修订日期，按多久以前的方式显示   %cn 提交者(committer)的名字   %ce 提交者的电子邮件地址   %cd 提交日期   %cr 提交日期，按多久以前的方式显示   %s 提交说明    当 oneline 或 format 与另一个 log 选项 \u0026ndash;graph 结合使用时尤其有用。 这个选项添加了一些ASCII字符串来形象地展示你的分支、合并历史：\n$ git log --pretty=format:\u0026quot;%h %s\u0026quot; --graph * 2d3acf9 ignore errors from SIGCHLD on trap * 5e3ee11 Merge branch 'master' of git://github.com/dustin/grit |\\ | * 420eac9 Added a method for getting the current branch. * | 30e367c timeout code and tests * | 5a09431 add timeout protection to grit * | e1193f8 support for heads with slashes in them |/ * d6016bc require time for xmlschema * 11d191e Merge branch 'defunkt' into local  git log 的常用选项\n   选项 说明     -p 按补丁格式显示每个更新之间的差异。   \u0026ndash;stat 显示每次更新的文件修改统计信息。   \u0026ndash;shortstat 只显示 \u0026ndash;stat 中最后的行数修改添加移除统计。   \u0026ndash;name-only 仅在提交信息后显示已修改的文件清单。   \u0026ndash;name-status 显示新增、修改、删除的文件清单。   \u0026ndash;abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。   \u0026ndash;relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。   \u0026ndash;pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。    限制输出长度 除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。\n另外还有按照时间作限制的选项，比如 \u0026ndash;since 和 \u0026ndash;until 也很有用。 例如，下面的命令列出所有最近两周内的提交：\n$ git log --since=2.weeks  这个命令可以在多种格式下工作，比如说具体的某一天 \u0026ldquo;2008-01-15\u0026rdquo;，或者是相对地多久以前 \u0026ldquo;2 years 1 day 3 minutes ago\u0026rdquo;。\n另一个非常有用的筛选选项是 -S，可以列出那些添加或移除了某些字符串的提交。 比如说，你想找出添加或移除了某一个特定函数的引用的提交，你可以这样使用：\n$ git log -Sfunction_name  限制 git log 输出的选项\n   选项 说明     -(n) 仅显示最近的 n 条提交   \u0026ndash;since, \u0026ndash;after 仅显示指定时间之后的提交。   \u0026ndash;until, \u0026ndash;before 仅显示指定时间之前的提交。   \u0026ndash;author 仅显示指定作者相关的提交。   \u0026ndash;committer 仅显示指定提交者相关的提交。   \u0026ndash;grep 仅显示含指定关键字的提交   -S 仅显示添加或移除了某个关键字的提交   \u0026ndash;all-match 显示满足所有匹配条件的提交   \u0026ndash;(path) 仅显示某些文件或者目录的提交（选项最后指定）    例子， 查看 Git 仓库中，2008 年 10 月期间，Junio Hamano 提交的但未合并的测试文件，可以用下面的查询命令：\n$ git log --pretty=\u0026quot;%h - %s\u0026quot; --author=Junio Hamano --since=\u0026quot;2008-10-01\u0026quot; \\ --before=\u0026quot;2008-11-01\u0026quot; --no-merges -- t/ 5610e3b - Fix testcase failure when extended attributes are in use acd3b9e - Enhance hold_lock_file_for_{update,append}() API f563754 - demonstrate breakage of detached checkout with symbolic link HEAD d1a43f2 - reset --hard/read-tree --reset -u: remove unmerged new paths 51a94af - Fix \u0026quot;checkout --track -b newbranch\u0026quot; on detached HEAD b0ad11e - pull: allow \u0026quot;git pull origin $something:$current_branch\u0026quot; into an unborn branch   撤销操作 #  重新提交 #  \u0026ndash;amend 选项的提交命令尝试重新提交：\n$ git commit --amend  这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改（例如，在上次提交后马上执行了此命令），那么快照会保持不变，而你所修改的只是提交信息。 文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。\n例如，你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作：\n$ git commit -m 'initial commit' $ git add forgotten_file $ git commit --amend  最终你只会有一个提交 - 第二次提交将代替第一次提交的结果。\n 取消暂存的文件 #  $ git add * $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: CONTRIBUTING.md # modified: README #  git rest HEAD  取消暂存：\n$ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: README # # Changed but not updated: # (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) # (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) # # modified: CONTRIBUTING.md #   撤消对文件的修改 #  git checkout \u0026ndash;  ， 将它还原成上次提交时的样子：\n$ git checkout -- CONTRIBUTING.md $ git status # On branch master # Changes to be committed: # (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) # # modified: README #   远程仓库 #  远程仓库是指托管在因特网或其他网络中的你的项目的版本库。 你可以有好几个远程仓库，通常有些仓库对你只读，有些则可以读写。 与他人协作涉及管理远程仓库以及根据需要推送或拉取数据。\n管理远程仓库包括了解如何添加远程仓库、移除无效的远程仓库、管理不同的远程分支并定义它们是否被跟踪等等。\n 查看远程仓库 #  git remote ： 列出指定的每一个远程服务器的简写。 如果你已经克隆了自己的仓库，那么至少应该能看到 origin\n$ git remote origin  指定选项 -v，会显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。\n$ git remote -v origin https://github.com/Code-CC/leetcode (fetch) origin https://github.com/Code-CC/leetcode (push)   添加远程仓库 #  运行 git remote add   添加一个新的远程 Git 仓库，同时指定一个你可以轻松引用的简写：\n$ git remote origin $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin\thttps://github.com/schacon/ticgit (fetch) origin\thttps://github.com/schacon/ticgit (push) pb\thttps://github.com/paulboone/ticgit (fetch) pb\thttps://github.com/paulboone/ticgit (push)  现在你可以在命令行中使用字符串 pb 来代替整个 URL。 例如，如果你想拉取 Paul 的仓库中有但你没有的信息，可以运行 git fetch pb：\n$ git fetch pb remote: Counting objects: 43, done. remote: Compressing objects: 100% (36/36), done. remote: Total 43 (delta 10), reused 31 (delta 5) Unpacking objects: 100% (43/43), done. From https://github.com/paulboone/ticgit * [new branch] master -\u0026gt; pb/master * [new branch] ticgit -\u0026gt; pb/ticgit   从远程仓库中抓取与拉取 #  从远程仓库中获得数据，可以执行：\n$ git fetch [remote-name]  这个命令会访问远程仓库，从中拉取所有你还没有的数据。（不进行合并分支）\n$ git pull [remote-name] [buranch-name]  这个命令会自动的抓取然后合并远程分支到当前分支。\n 推送到远程仓库 #  当你想分享你的项目时，必须将其推送到上游。可以使用下面的命令：\ngit push [remote-name] [branch-name]  只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送。\n 查看远程仓库 #  git remote show [remote-name] ：查看远程仓库信息。\n$ git remote show origin * remote origin Fetch URL: https://github.com/Code-CC/leetcode Push URL: https://github.com/Code-CC/leetcode HEAD branch: master Remote branch: master tracked Local branch configured for 'git pull': master merges with remote master Local ref configured for 'git push': master pushes to master (local out of date)  它同样会列出远程仓库的 URL 与跟踪分支的信息。\n 远程仓库的移除与重命名 #  git remote rename ：修改一个远程仓库的简写名。\n$ git remote rename pb paul $ git remote origin paul  git remote rm ：移除一个远程仓库\n$ git remote rm paul $ git remote origin   标签 #  Git 可以给历史中的某一个提交打上标签，以示重要。 比较有代表性的是人们会使用这个功能来标记发布结点（v1.0 等等）。\n 列出标签 #  git tag：列出已有的标签\n$ git tag v0.1 v1.3  git tag -l ：使用特定的模式查找标签。\n$ git tag -l 'v1.8.5*' v1.8.5 v1.8.5-rc0 v1.8.5-rc1 v1.8.5-rc2 v1.8.5-rc3 v1.8.5.1 v1.8.5.2 v1.8.5.3 v1.8.5.4 v1.8.5.5   创建标签 #  Git 使用两种主要类型的标签：轻量标签（lightweight）与附注标签（annotated）。\n一个轻量标签很像一个不会改变的分支 - 它只是一个特定提交的引用。\n然而，附注标签是存储在 Git 数据库中的一个完整对象。 它们是可以被校验的；其中包含打标签者的名字、电子邮件地址、日期时间；还有一个标签信息；并且可以使用 GNU Privacy Guard （GPG）签名与验证。 通常建议创建附注标签，这样你可以拥有以上所有信息；但是如果你只是想用一个临时的标签，或者因为某些原因不想要保存那些信息，轻量标签也是可用的。\n  附注标签\ngit tag -a ：添加一个附注标签。\n$ git tag -a v1.4 -m \u0026lsquo;my version 1.4\u0026rsquo; $ git tag v0.1 v1.3 v1.4\n-m 选项指定了一条将会存储在标签中的信息。 如果没有为附注标签指定一条信息，Git 会运行编辑器要求你输入信息。\ngit show 命令可以看到标签信息与对应的提交信息：\n$ git show v1.4 tag v1.4 Tagger: Ben Straub ben@straub.cc Date: Sat May 3 20:19:12 2014 -0700\nmy version 1.4\ncommit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon schacon@gee-mail.com Date: Mon Mar 17 21:52:11 2008 -0700\n changed the version number    轻量标签\n$ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 v1.4-lw v1.5\n这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息：\n$ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon schacon@gee-mail.com Date: Mon Mar 17 21:52:11 2008 -0700\n changed the version number    后期打标签\n你也可以对过去的提交打标签。 假设提交历史是这样的：\n$ git log \u0026ndash;pretty=oneline 15027957951b64cf874c3557a0f3547bd83b3ff6 Merge branch \u0026lsquo;experiment\u0026rsquo; a6b4c97498bd301d84096da251c98a07c7723e65 beginning write support 0d52aaab4479697da7686c15f77a3d64d9165190 one more thing 6d52a271eda8725415634dd79daabbc4d9b6008e Merge branch \u0026lsquo;experiment\u0026rsquo; 0b7434d86859cc7b8c3d5e1dddfed66ff742fcbc added a commit function 4682c3261057305bdd616e23b64b0857d832627b added a todo file 166ae0c4d3f420721acbb115cc33848dfcc2121a started write support 9fceb02d0ae598e95dc970b74767f19372d61af8 updated rakefile 964f16d36dfccde844893cac5b347e7b3d44abbc commit the todo 8a5cbc430f1a9c3d00faaeffd07798508422908a updated readme\n现在，假设在 v1.2 时你忘记给项目打标签，也就是在 “updated rakefile” 提交。 你可以在之后补上标签。 要在那个提交上打标签，你需要在命令的末尾指定提交的校验和（或部分校验和）:\n$ git tag -a v1.2 9fceb02\n$ git tag v0.1 v1.2 v1.3 v1.4 v1.4-lw v1.5\n$ git show v1.2 tag v1.2 Tagger: Scott Chacon schacon@gee-mail.com Date: Mon Feb 9 15:32:16 2009 -0800\nversion 1.2 commit 9fceb02d0ae598e95dc970b74767f19372d61af8 Author: Magnus Chacon mchacon@gee-mail.com Date: Sun Apr 27 20:43:35 2008 -0700\n updated rakefile  \u0026hellip;\n   共享标签 #  默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样 - 你可以运行 git push origin [tagname]。\n$ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -\u0026gt; v1.5  如果想要一次性推送很多标签，也可以使用带有 \u0026ndash;tags 选项的 git push 命令。\n$ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -\u0026gt; v1.4 * [new tag] v1.4-lw -\u0026gt; v1.4-lw   检出标签 #  在 Git 中你并不能真的检出一个标签，因为它们并不能像分支一样来回移动。 如果你想要工作目录与仓库中特定的标签版本完全一样，可以使用 git checkout -b [branchname] [tagname] 在特定的标签上创建一个新分支：\n$ git checkout -b version2 v2.0.0 Switched to a new branch 'version2'  当然，如果在这之后又进行了一次提交，version2 分支会因为改动向前移动了，那么 version2 分支就会和 v2.0.0 标签稍微有些不同，这时就应该当心了。\n 别名 #  Git 并不会在你输入部分命令时自动推断出你想要的命令。 如果不想每次都输入完整的 Git 命令，可以通过 git config 文件来轻松地为每一个命令设置一个别名。 这里有一些例子你可以试试：\n$ git config --global alias.co checkout $ git config --global alias.br branch $ git config --global alias.ci commit $ git config --global alias.st status  这意味着，当要输入 git commit 时，只需要输入 git ci。 随着你继续不断地使用 Git，可能也会经常使用其他命令，所以创建别名时不要犹豫。\n在创建你认为应该存在的命令时这个技术会很有用。 例如，为了解决取消暂存文件的易用性问题，可以向 Git 中添加你自己的取消暂存别名：\n$ git config --global alias.unstage 'reset HEAD --'  这会使下面的两个命令等价：\n$ git unstage fileA $ git reset HEAD -- fileA  这样看起来更清楚一些。 通常也会添加一个 last 命令，像这样：\n$ git config --global alias.last 'log -1 HEAD'  这样，可以轻松地看到最后一次提交：\n$ git last commit 66938dae3329c7aebe598c2246a8e6af90d04646 Author: Josh Goebel \u0026lt;dreamer3@example.com\u0026gt; Date: Tue Aug 26 19:48:51 2008 +0800 test for current head Signed-off-by: Scott Chacon \u0026lt;schacon@example.com\u0026gt;  可以看出，Git 只是简单地将别名替换为对应的命令。 然而，你可能想要执行外部命令，而不是一个 Git 子命令。 如果是那样的话，可以在命令前面加入 ! 符号。 如果你自己要写一些与 Git 仓库协作的工具的话，那会很有用。 我们现在演示将 git visual 定义为 gitk 的别名：\n$ git config --global alias.visual '!gitk' "});index.add({'id':3,'href':'/notes/docs/technology/bigdata/Application/kafka/','title':"Kafka",'content':"Kafka #  "});index.add({'id':4,'href':'/notes/docs/technology/cloud/Container/Kubernetes/object/pod/','title':"Kubernetes Pod",'content':"Kubernetes Pod #  What #  Pod 是 Kubernetes 应用程序的基本执行单元，即它是 Kubernetes 对象模型中创建或部署的最小和最简单的单元。Pod 表示在 集群 上运行的进程。\nPod 封装了应用程序容器（或者在某些情况下封装多个容器）、存储资源、唯一网络 IP 以及控制容器应该如何运行的选项。 Pod 表示部署单元：Kubernetes 中应用程序的单个实例，它可能由单个 容器 或少量紧密耦合并共享资源的容器组成。\n Docker 是 Kubernetes Pod 中最常用的容器运行时，但 Pod 也能支持其他的 容器运行时。\nKubernetes 集群中的 Pod 可被用于以下两个主要用途：\n  运行单个容器的 Pod。\u0026ldquo;每个 Pod 一个容器\u0026quot;模型是最常见的 Kubernetes 用例；在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。\n  运行多个协同工作的容器的 Pod。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众，而另一个单独的“挂斗”（sidecar）容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。 Kubernetes 博客 上有一些其他的 Pod 用例信息。更多信息请参考：\n   分布式系统工具包：容器组合的模式\n   容器设计模式\n  每个 Pod 表示运行给定应用程序的单个实例。如果希望横向扩展应用程序（例如，运行多个实例），则应该使用多个 Pod，每个应用实例使用一个 Pod 。在 Kubernetes 中，这通常被称为 副本。通常使用一个称为控制器的抽象来创建和管理一组副本 Pod。更多信息请参见 Pod 和控制器。\n How #  Pod 被设计成支持形成内聚服务单元的多个协作过程（作为容器）。 Pod 中的容器被自动的安排到集群中的同一物理或虚拟机上，并可以一起进行调度。 容器可以共享资源和依赖、彼此通信、协调何时以及何种方式终止它们。\n注意，在单个 Pod 中将多个并置和共同管理的容器分组是一个相对高级的使用方式。 只在容器紧密耦合的特定实例中使用此模式。 例如，您可能有一个充当共享卷中文件的 Web 服务器的容器，以及一个单独的 sidecar 容器，该容器从远端更新这些文件，如下图所示：\n 有些 Pod 具有 初始容器 和 应用容器。初始容器会在启动应用容器之前运行并完成。\nPod 为其组成容器提供了两种共享资源：网络 和 存储。\n网络 #  每个 Pod 分配一个唯一的 IP 地址。 Pod 中的每个容器共享网络命名空间，包括 IP 地址和网络端口。 Pod 内的容器 可以使用 localhost 互相通信。 当 Pod 中的容器与 Pod 之外 的实体通信时，它们必须协调如何使用共享的网络资源（例如端口）。\n存储 #  一个 Pod 可以指定一组共享存储 卷。 Pod 中的所有容器都可以访问共享卷，允许这些容器共享数据。 卷还允许 Pod 中的持久数据保留下来，以防其中的容器需要重新启动。 有关 Kubernetes 如何在 Pod 中实现共享存储的更多信息，请参考 卷。\n Why #  管理 #  Pod 是形成内聚服务单元的多个协作过程模式的模型。它们提供了一个比它们的应用组成集合更高级的抽象，从而简化了应用的部署和管理。Pod 可以用作部署、水平扩展和制作副本的最小单元。在 Pod 中，系统自动处理多个容器的在并置运行（协同调度）、生命期共享（例如，终止），协同复制、资源共享和依赖项管理。\n资源共享和通信 #  Pod 使它的组成容器间能够进行数据共享和通信。\nPod 中的应用都使用相同的网络命名空间（相同 IP 和 端口空间），而且能够互相“发现”并使用 localhost 进行通信。因此，在 Pod 中的应用必须协调它们的端口使用情况。每个 Pod 在扁平的共享网络空间中具有一个 IP 地址，该空间通过网络与其他物理计算机和 Pod 进行全面通信。\nPod 中的容器获取的系统主机名与为 Pod 配置的 name 相同。 网络 部分提供了更多有关此内容的信息。\nPod 除了定义了 Pod 中运行的应用程序容器之外，Pod 还指定了一组共享存储卷。该共享存储卷能使数据在容器重新启动后继续保留，并能在 Pod 内的应用程序之间共享。\n "});index.add({'id':5,'href':'/notes/docs/technology/database/SQL/mysql/','title':"MySQL",'content':"MySQL #     Install guide\n   Cluster\n  "});index.add({'id':6,'href':'/notes/docs/technology/database/NoSQL/redis/','title':"Redis",'content':"Redis #    基础\n   集群搭建\n  "});index.add({'id':7,'href':'/notes/docs/technology/database/NoSQL/redis/cluster/','title':"Redis集群",'content':"集群 #  集群搭建 #    Redis安装\nwget http://download.redis.io/releases/redis-4.0.1.tar.gz    基础配置\n#除端口外，配置统一 #common port 6379 pidfile /cache1/redis/6379/redis_6379.pid loglevel notice logfile \u0026quot;/cache1/redis/6379/redis_6379.log\u0026quot; dir /cache1/redis/6379 protected-mode no #rdb save 7200 1000 rdbcompression yes rdbchecksum yes dbfilename dump.rdb #aof appendonly yes appendfilename \u0026quot;appendonly.aof\u0026quot; #cluster cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000    redis集群架构\n192.168.88.1:6379(master) 192.168.88.2:6379(slave) 192.168.88.2:6378(master) 192.168.88.3:6378(slave) 192.168.88.3:6377(master) 192.168.88.1:6377(slave)    启动redis\ncd $PATH redis-server redis-6379.conf \u0026amp;    集群管理器安装\n#安装ruby tar -zxf ruby-2.4.1.tar.gz cd ruby-2.4.1 ./configure make \u0026amp;\u0026amp; make install #安装gem tar -zxf rubygems-2.6.12.tgz cd rubygems-2.6.12/ ruby setup.rb --no-rdoc --no-ri #安装redisgem gem install redis    集群建立\ncd /usr/local/src/redis-4.0.1/ src/redis-trib.rb create --replicas 1 192.168.88.1:6379 192.168..88.2:6378 192.168.88.3:6377 192.168.88.2:6379 192.168.88.3:6378 192.168.88.1:6377    简单测试\nredis-cli -c -h 192.168.88.1 -p 6379 cluster nodes    集群分片\nsrc/redis-trib.rb reshard 192.168.88.1:6379    添加节点\nsrc/redis-trib.rb add-node 192.168.88.1:6376 172.16.88.1:6379 src/redis-trib.rb add-node --slave --master-id xxxx 192.168.88.1:6376 192.168.88.1:6379    从节点更改\nredis-cli -c -p 6377 cluster replicate \u0026lt;master-node-id\u0026gt;     集群优化 #    配置文件优化\n  集群配置密码\n#redis.conf配置文件 requirepass 123456 masterauth 123456 #集群管理客户端 #/usr/local/lib/ruby/gems/2.4.1/gems/redis-3.3.3/lib/redis/client.rb password =\u0026gt; \u0026quot;123456\u0026quot;    "});index.add({'id':8,'href':'/notes/docs/technology/tool/Script/','title':"Scripts",'content':"Scripts #  shell 脚本 #    tomcat系列\n   tomcat服务启动\n   tomcat版本更新\n   tomcat日志分割\n   tomcat应用发布\n   tomcat应用还原\n    zabbix系列\n   server安装\n   agent安装\n     python 脚本 #     PG日志格式更改\n   tcp端口测试\n   ssh登录测试\n   生成随机日志\n  "});index.add({'id':9,'href':'/notes/docs/technology/program/Language/shell/','title':"Shell",'content':"Shell #  基础语法 #    变量\n  函数\n   进阶 #    代码风格  "});index.add({'id':10,'href':'/notes/docs/technology/security/IDS/snort/','title':"Snort",'content':"Snort #  #  "});index.add({'id':11,'href':'/notes/docs/technology/system/Application/ssh/','title':"SSH",'content':"SSH #  概念 #  安全Shell（SSH）是一种加密网络协议，用于通过无安全网络安全地运行网络服务。\nSSH协议 #    认证\n  加密\n  完整性\n  SSH属性 #    安全远程登录(Secure Remote Login )\n  安全文件传输(Secure File Transfer)\n  安全远程命令执行(Secure Remote Command Execution)\n  密钥和代理(Keys and Agents)\n  访问控制(Access Control)\n  端口转发(Port Forwarding)\n  架构 #    基础操作 #    远程登录\nssh -l USERNAME HOST -p PORT\n  文件传输\nscp SOURCE DESTINATION\n  已知主机(known hosts)\nknown hosts可以用来防止中间人攻击。 每个SSH服务器都有一个秘密的唯一ID，称为主机密钥(host key)，用于向客户端标识自身。当首次连接的时，ssh会记录目标设备的host key到~/.ssh/known_hosts文件，当主机密钥发生改变时，在连接时将会有提示告警。\n  转义字符(The Escape Character)\n转义字符可以用于暂时中断连接，默认符号为\u0026quot;~\u0026rdquo; 也可以自行进行更改，使用-e选项，ssh -e \u0026ldquo;#\u0026rdquo; HOST\n  加密密钥认证(Authentication by Cryptographic Key) #  密码认证方式的缺陷：\n 安全的密码复杂性高，难于记忆。 通过网络传输密码还是会有被捕获的风险。  SSH支持公钥认证的方式，可以解决上述的密码问题。\n 密钥简介  key是一个数字身份，是一个独特的二进制字符串。\nSSH身份使用一对密钥，一个私有密钥和一个公有密钥。私钥由自身保管，公钥保存在需要访问的ssh服务器上。(~/.ssh/authorized_keys)文件。\nclient请求登录server server要求身份认证 client发送自身私钥证明自己身份 server使用公钥对私钥进行匹配，成功则允许登录。   ssh-keygen生成密钥对\n(ssh-keygen -t dsa|rsa) | (ssh-keygen) 会在~/.ssh/目录生成id_rsa和id_rsa.pub两个文件\n  在ssh服务器上安装公钥\n 直接编辑~/.ssh/authorized_keys(权限644),拷贝id_rsa.pub的内容到该文件 使用ssh-copy-id ssh-copy-id -i id_rsa.pub [user@]server_name     SSH深入 #    加密\n  完整性\n  认证\n  授权\n  转发\n  密码学入门 #  "});index.add({'id':12,'href':'/notes/docs/technology/network/Protocol/tcp/','title':"TCP",'content':"TCP #  "});index.add({'id':13,'href':'/notes/docs/technology/cloud/infrastructure/','title':"不可变基础设施",'content':"不可变基础设施 #  What #  定义 #   不可变基础设施(Immutable.Infrastructure)是由 Chad Fowler 于2013年提出的一个很有前瞻性的构想：在这种模式中，任何基础设施的实例（包括服务器、容 器等各种软硬件）一旦创建之后便成为一种只读状态，不可对其进行任何更改。如果 需要修改或升级某些实例，唯一的方式就是创建一批新的实例以替换。\n  优势 #   基础架构是一致且可靠的，这使测试更加简单 部署更简单，更可预测 每个部署都是版本化和自动化的，因此轻松进行环境回滚 错误，配置偏差和雪花服务器已完全缓解或消除 在所有环境中部署均保持一致 借助云服务，轻松实现自动扩展     阿里云原生课堂 #     "});index.add({'id':14,'href':'/notes/docs/other/life/','title':"人生",'content':"人生 #  "});index.add({'id':15,'href':'/notes/docs/technology/system/Linux/kernel/','title':"内核编译",'content':"内核编译 #  概念 #  内核指的是一个提供硬件抽象层、磁盘及文件系统控制、多任务等功能的系统软件。\n一般保存在/boot目录中，格式为/boot/vmlinuz-XXX\n 为什么要编译内核 #    需要新功能支持\n  原核心过于臃肿\n  与硬件搭配的稳定性\n  其他特殊需求\n   编译内核 #    下载源码包， https://www.kernel.org/\n  解压内核包，一般放在/usr/src/kernels目录下\n tar -Jxf /root/linux-3.16.39.tar.xz -C /usr/src/kernels/    进入内核目录\n cd /usr/src/kernels/linux-3.16.39    查看内核目录( 目录说明)\n ls -d ./*/ ./arch/ ./crypto/ ./drivers/ ./fs/ ./init/ ./kernel/ ./mm/ ./samples/ ./security/ ./tools/ ./virt/ ./block/ ./Documentation/ ./firmware/ ./include/ ./ipc/ ./lib/ ./net/ ./scripts/ ./sound/ ./usr/    清空源代码的其他信息\n下载下来的源码包一般情况下不确定是否已经编译过，或者还残留有生成的一起文件，为了编译时不会出现未知的错误，进行清理。\n make mrproper    核心功能挑选(生成.config文件)( 选择界面说明)\n yum install ncurses-devel -y make menuconfig    生成bzImage内核 arch/x86/boot/bzImage\n make -j 4 clean make -j 4 bzImage ll arch/x86/boot/bzImage    编译安装模块\n make -j 4 modules make modules_install    手动添加内核\n #拷贝内核文件到/boot目录底下 cp arch/x86/boot/bzImage /boot/vmlinuz-`basename /lib/modules/3.16.39/` #备份.config文件 cp .config /boot/config-`basename /lib/modules/3.16.39/` #添加可执行权限 chmod a+x /boot/vmlinuz-3.16.39 #拷贝系统内核映射文件 cp System.map /boot/System.map-`basename /lib/modules/3.16.39/` #拷贝内核模块列表 gzip -c Module.symvers \u0026gt; /boot/symvers-`basename /lib/modules/3.16.39/`.gz    配置grub\n#生成对应版本的initramfs文件 dracut -v /boot/initramfs-`basename /lib/modules/3.16.39/` 3.16.39 #更新grub.cfg配置，加入新内核记录 grub2-mkconfig -o /boot/grub2/grub.cfg    查看grub配置/boot/grub2/grub.conf\n   重启机器，选择新内核启动\n   目录说明   arch：与硬件平台有关的项目，大部分指的是CPU的类型，例如x86,x86_64,Xen虚拟支持等。\n  block：与成组设备较相关的设定数据，区块数据通常指一些大量存储媒体，还包括类似ext3等文件系统的支持是否允许等。\n  crypto：核心所支持的加密技术，如md5、des、sha512等。\n  Documentation：与核心有关的一堆说明文件，其中包括了对上面所有目录里的说明。\n  firmware：一些旧式硬件的微脚步数据。\n  fs：内核所支持的filesystems（文件系统），例如ext系列、ntfs、reisefs等。\n  include：一些可让其它过程调用的标头(header)定义数据。\n  init：一些初始化的定义功能，包括挂载和init 程序的呼叫等。\n  ipc：定义Linux操作系统内各程序进程间的通信。\n  kernel：定义核心的程序、核心状态、线程、程序的排程(schedule)、程序的讯号(signle)等。\n  lib：一些函数库。\n  mm：与内存单元有关的各项数据，包括swap与虚拟内存等。\n  net：与网络有关的各项协议数据，还有防火墙模块(net/ipv4/netfilter/*) 等。\n  security：包括selinux等在内的安全性设定。\n  sound：与音效有关的各项模块。\n  virt：与虚拟化机器有关的信息，目前核心支持的是KVM( Kernel base Vitual Machine )。\n   选择界面说明   make help： 支持“更新模式进行配置”。\n  make menuconfig： 基于curses的文本窗口界面\n  make gconfig： 基于GTK(GOME)环境窗口界面\n  make xconfig： 基于QT(KDE) 环境的窗口界面\n  make config： 老旧的命令行遍历方式逐一配置每个可配置的选项\n  make oldconfig： 透过已经存在的./.config文件内容，并使用该文件内设定值为默认值，只将新版本核心的新功能列出让用户选择，可以简化核心功能挑选过程。对与升级内核很好选择。\n  make defconfig： 基于内核为目标平台执行提供的“默认”配置进行配置\n  make allyesconfig： 所有选项均回答为”yes”\n  make allnoconfig： 所有选项均回答为”no”\n  "});index.add({'id':16,'href':'/notes/docs/technology/bigdata/Basic/','title':"大数据基础",'content':"大数据基础 #  分布式系统 #  分布式系统是独立计算机的集合，作为单个计算机对系统用户显示。 分布式系统是一种模型，其中位于联网计算机上的组件通过传递消息来通信和协调他们的动作，组件彼此交互以实现共同目标。\n 分布式计算 #  优势 #  劣势 #   分布式系统设计 #  协调服务 #    Name service\n  Locking\n  Synchronization\n  Configuration management\n  Leader election\n   "});index.add({'id':17,'href':'/notes/docs/other/life/reason/','title':"存在的意义",'content':"存在的意义 #   "});index.add({'id':18,'href':'/notes/docs/other/learn/Method/','title':"学习方法",'content':"学习方法 #   "});index.add({'id':19,'href':'/notes/docs/technology/security/Basic/','title':"安全基础",'content':"安全基础 #  密码学 #  密码学处理数字和字符串。\n哈希 #  哈希散列是一项密码学技术，它将数据转换成其他形式，并且不可恢复。\n加解密 #  加解密是一个双向过程，当且仅当加密密钥被知道时才能检索原始数据。\n对称加密 #  对称加密使用同一个密钥\n非对称加密 #  非对称加密使用公私钥，私钥自己持有，公钥给所有想加密信息发送给你的人。使用公钥加密，使用私钥解密。\n"});index.add({'id':20,'href':'/notes/docs/technology/','title':"技术相关",'content':"技术相关 #  系统 #  计算机基础 #     计算机组成\n   操作系统\n   文件系统\n  Linux系统 #     内核编译\n   启动\n   Linux目录结构\n   Linux操作指南\n  应用服务 #     SSH\n   Nginx\n   网络 #  网络基础 #  网络协议 #     TCP\n   HTTP\n   DNS\n   编程 #  编程基础 #  版本控制 #    Git  编程语言 #     Shell\n   Golang\n   Python\n  编程进阶 #    数据结构  算法  设计模式   数据库 #    数据库基础\n   PostgreSQL\n   MySQL\n   Redis\n   云原生 #   安全 #     安全基础\n   TLS\n   Firewall\n   IDS\n   Snort\n  Ossec\n  tripware\n     大数据 #     基础概念\n   Zookeeper\n   Kafka\n   智能化 #     Ansible\n   Docker\n   Kubernetes\n   Elk\n   工具 #    TCPCopy  Script   "});index.add({'id':21,'href':'/notes/docs/technology/cloud/Container/Kubernetes/map/','title':"技能图谱",'content':"Kubernetes 技能图谱 #  Container basics （容器技术基础） #   Linux Operating System Basic Linux Process Management (Linux进程管理) Cgroups Linux Namespaces Rootfs \u0026amp; Container Image Image Registry  Kubernetes architecture （Kubernetes 架构） #  Node #  Kubelet #   Runtime （容器运行时）  CRI (Container Runtime Interface) Runtime shims （容器运行时插件）  Cri-containerd （containerd） Dockershim （Docker） Cri-o （runC） Rktlet （rkt） Frakti （KataContainers）   RuntimeClass (新特性：容器运行时类)   Networking  CNI (Container Network Interface) Linux Network Namespace Network plugins （网络插件）  Flannel Calico OVS SR-IOV macvlan/ipvlan Opencontrail Weave Cilium （新插件，支持BPF，推荐）     Storage  CSI (Container Storage Interface) Persistent Volume \u0026amp; Persistent Volume Claim Volume plugins （存储插件，仅负责提供PV）  NFS Cinder GlusterFS Ceph Local path   Volume extenstion (存储扩展，负责提供完整的Storage方案)  Rook.io     Kube-proxy  Iptables 转发链与随机模式 IPVS 负载均衡    Master #   API server  Watch \u0026amp; Informer （Watch 和通知框架） Admission Plugin（权限控制插件） RBAC plugin （基于角色的访问控制插件） Custom Resource Definition (新特性，CRD，自定义API对象，重点推荐) APIServer aggregator (新特性，聚合APIServer，推荐)   Controller manager  Reconcile （控制循环与状态协调机制）   Scheduler  Scheduling algorithm （默认调度算法） Scheduler extender （调度器扩展器） Custom algorithm （自定义调度算法） Custom scheduler （自定义调度器） Scheduler Framework （新特性，可扩展调度框架，推荐） Multiple scheduler （多调度器）   Etcd  Etcd operator Etcd performance tuning    Kubernetes workloads （Kubernetes 作业管理） #   Pod ReplicaSet （容器副本） Deployment （常规作业发布）  Rolling update （自动的滚动更新） Pause/resume （可控的更新流程） Canary deploy （金丝雀发布） Rollback （版本回滚）   DaemonSet （Daemon 作业） StatefulSet （有状态任务）  Topology State Storage State   Job （一次性任务） CronJob （定时任务）  Kubernetes applications management （Kubernetes 应用配置） #   Service （服务发现）  Publish service（对外暴露 Service） Nginx/HAproxy service（自定义 Service） External Load Balancer   ConfigMap （应用配置管理） Ingress （7层服务发现） Secret （加密信息管理） Headless Service（DNS 服务发现） External Load Balancer  Kubernetes operations （Kubernetes 安装与运维） #   Installation  Kubeadm （内置部署工具，推荐） Minikube （本地部署工具） Kops （云端部署工具）   Maintenances  Garbage Collection (垃圾回收)  Container GC Image GC     Upgrades Troubleshooting  etcd admin  Key-value CRUD（键值对操作） Metrics monitoring （Metrics 监控） Cluster design（集群规划） Disaster Recovery （灾难恢复，backup 和 restore）   Iptables rules    Kubernetes extensions/add-ons （Kubernetes 扩展和插件） #   Custom Resources Definition （自定义 Kubernetes API 对象）  Customized controller （自定义 API 对象控制器） Workqueue （自定义 API 对象任务队列）   Kube-dns  SkyDNS CoreDNS   Fluentd （日志收集）  Fluent-bit   Heapster (容器集群监控） Istio（微服务治理和负载均衡） Federation v2（新特性：集群联邦v2） Helm (kubernetes application package)  Kubernetes CI/CD #   Spinnaker Skaffold (新项目，推荐)  Kubernetes PaaS #   OpenShift Knative （新项目，推荐）  "});index.add({'id':22,'href':'/notes/docs/technology/cloud/Container/map/','title':"技能图谱",'content':"技能图谱 #  容器化工具 #    Docker  LXC  RunC  Rkt  Systemd-nspawn  Garden  Vagga  VMWare Photon  gVisor  Pouch Container  Kata Containers  监控和数据收集 #    Sysdig Monitor  cAdvisor  Weave Scope  Prometheus  TICK-Stack  Docker-Alertd  Grafana  Cockpit  基础设施集成 #    Magnum  Boot2Docker  MaestroNG  CloudFoundry Containers Service Broker  编排和调度 #    Crane  Mesos  Marathon  Compose  Yarn  Kubernetes  Openshift Origin  Rancher  K3s  Nomad  SwarmKit  Nebula  Dokku  Flynn  商业平台 #    AWS Container Service  Google Container Engine  Azure Container Service  阿里云容器服务  腾讯云容器服务  华为云容器引擎  容器镜像仓库 #    Repository  Nexus  Habor  Portus  Dragonfly  服务发现和容器 #    Consul  Etcd  ZooKeeper  Eureka  Traefik  Registrator  容器日志收集处理 #    Splunk  Elastic Stack  Fluentd  Flume  Graylog  Rsyslog  容器相关的系统发行版 #    Container Linux (CoreOS)  Project Atomic  RancherOS  ClearLinux  VMWare Photon  Talos  k3os  LinuxKit  SmartOS  容器网络 #    Pipework  Flannel  Calico  Weave  Kubenet  Contiv  OpenContrail  MacVlan  Canal  Romana  Submariner  容器安全 #    Anchore Engine  Aqua Microscanner  Clair  Dagda  Twistlock  OpenSCAP  Notary  Twistlock  SELinux  AppArmor  容器数据持久化 #    Ceph  Convoy  REX-Ray  Netshare  OpenStorage  容器相关标准 #    OCI Runtime Spec  OCI Image Spec  OCI Distribution Spec  Container Network Interface  Container Storage Interface  "});index.add({'id':23,'href':'/notes/docs/technology/cloud/DevOps/map/','title':"技能图谱",'content':"DevOps #   "});index.add({'id':24,'href':'/notes/docs/technology/database/Basic/','title':"数据库基础",'content':"数据库基础 #  "});index.add({'id':25,'href':'/notes/docs/technology/program/Advanced/dataStructure/','title':"数据结构",'content':"数据结构 #    链表\n  堆栈\n  队列\n  哈希表\n  二叉排序树\n  单词查找树\n  "});index.add({'id':26,'href':'/notes/docs/technology/other/MyConfig/','title':"环境配置",'content':"打造开发环境 #  vim #     配置指南\n   基础配置\n   插件配置\n   开发配置\n   tmux #    基础配置   xshell #    颜色配置  "});index.add({'id':27,'href':'/notes/docs/technology/system/','title':"系统",'content':"系统 #  "});index.add({'id':28,'href':'/notes/docs/technology/program/Basic/','title':"编程基础",'content':"编程基础 #  编程语言 #    解释型语言\n 程序由解释器读取并执行 SoucreCode --\u0026gt; Interpreter --\u0026gt; Output    编译型语言\n 程序被编译器翻译成机器语言后再执行 SourceCode --\u0026gt; Compliler --\u0026gt; ObjectCode --\u0026gt; Executor --\u0026gt; Output     什么是程序？ #  程序是指定如何执行计算的指令序列。\n不同的编程语言具有一些共同的基础特性：\n input：从键盘，文件或者其他输入设备中获取数据。 output：在屏幕显示数据，或者将数据发送给文件或者输出设备。 math：执行基本的数学运算，比如加法和乘法。 conditional execution：检查条件并执行相应的代码。 repetition：反复执行一些操作。  编程可以视为将大型的复杂任务打破成更小和更小的子任务，直到子任务简单到足以执行上述的基本操作的过程。\n 调试(debugging) #  编程容易出错。编程错误被称为错误，并且跟踪它们的过程称为调试。\n Syntax errors：语法错误(语法是指程序的结构和关于该结构的规则)。 Runtime errors(exceptions)：运行时错误(异常)。 Semantic errors：语义错误，做的不是你想要让它做的事情。  调试是通过更改程序去发现和解决错误。\n 数据类型(type) #   interger：整数，例如1,2 string: 字符串，例如\u0026rsquo;Hello\u0026rsquo;   变量(variables) #  变量是引用值的名称，编程语言最强大的功能之一就是操纵变量的能力。\n variable：变量名，由字母开头并由字母或数字组成。最好由小写字母开头。 keyword：关键字，用于识别程序的结构，它们不能用作变量名称。例如,if,for,while   运算符(operators)和操作数(operands) #   operators：运算符，表示计算的特殊符号，例如+,-,* operands：操作数   表达式(expressions)和语句(statements) #   expression：表达式，是值、变量和运算符的组合。 statement：语句是可执行的代码单元。   注释(comments) #  在程序中添加笔记，用于解释程序正在做什么\n 流程控制(control flow) #  在程序运行时，控制个别的指令运行的顺序。\n控制结构：控制结构开始时多半都会有特定的关键字，以标明使用哪一种控制结构\n choice：选择结构  if-then-else： switch case   loop：循环结构  for while     函数(functions) #  函数是组织好的，可重复使用的，用于实现单一或相关联功能的代码段。\n function call：函数调用，一些语言一般由很多内置的函数可供调用。例如，type(32) function definition：定义函数，例如，def hello(): print(\u0026lsquo;Hello,World!') flow of execution：执行流程，程序总是从第一行开始按序执行语句，函数内部的语句并不会被执行，直到函数被调用。 parameter：参数，函数中用于供外部传入值的变量名。 why function?：  便于程序阅读 消除重复代码 便于调式功能 便于重用     模块(Modules) #   接口(interface) #   类(classes)和对象(objects) #   "});index.add({'id':29,'href':'/notes/docs/technology/network/Basic/','title':"网络基础",'content':"网络基础 #  "});index.add({'id':30,'href':'/notes/docs/technology/system/Basic/','title':"计算机基础",'content':"计算机基础 #  "});index.add({'id':31,'href':'/notes/docs/technology/system/Basic/constitute/','title':"计算机组成",'content':"计算机组成 #  计算机组成 #  计算机(computer)：一种利用电子学原理，根据一系列指令来对数据进行处理的工具。\n 硬件 #    控制器：负责对程序规定的控制信息进行分析,控制并协调输入,输出操作或内存访问。\n  运算器：负责数据的算术运算和逻辑运算即数据的加工处理。\n  存储器：实现记忆功能的部件用来存放计算程序及参与运算的各种数据。\n  输入设备：实现计算程序和原始数据的输入\n  输出设备：实现计算结果输出\n  图示：\n   软件 #    系统软件：负责管理计算机系统中各种独立的硬件，使得它们可以协调工作，提供基本的功能，并为正在运行的应用软件提供平台。\n  应用软件：为了某种特定的用途而被开发的软件。\n   计算机工作过程 #    用户打开程序\n  系统把程序代码段和数据段送入计算机的内存\n  控制器从存储器中取指令\n  控制器分析,执行指令,为取下一条指令做准备\n  取下一条指令,分析执行,如此重复操作,直至执行完程序中全部指令,便可获得全部指令\n  图示：\n  计算机系统结构 #    "});index.add({'id':32,'href':'/notes/docs/technology/cloud/DevOps/ansible/','title':"Ansible",'content':"Ansible #  安装 #    安装ansible\npip install ansible    测试\necho \u0026quot;127.0.0.1\u0026quot; \u0026gt; ~/ansible_hosts export ANSIBLE_INVENTORY=~/ansible_hosts ansible all -m ping --ask-pass    Inventory #    主机和组\nansible_hosts 文件\n[group1] host1 host2 [group2] host3 host4 ssh选项 ansible_port=5555(默认22) ansible_host=172.16.0.101 ansible_user=root(默认root) ansible_connection=ssh(默认ssh) ansible_ssh_pass= host变量 http_port=80 maxRequestsPerChild=808 group变量 [group1:vars] ansible_port=33 group包含group [group3:children] group1 group2     命令行 #  ansible \u0026lt;server_name\u0026gt; -m \u0026lt;module_name\u0026gt; -a \u0026lt;arguments\u0026gt;   配置文件 #  略\nPlaybook #  Playbook是Ansible的配置，部署和编排语言，他们可以描述您希望远程系统执行的策略，或一般IT流程中的一组步骤。\n一个playbook案例\n--- - hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running (and enable it at boot) service: name=httpd state=started enabled=yes handlers: - name: restart apache service: name=httpd state=restarted   roles #   案例 #     tomcat\n   tengine\n   zookeeper\n   kafka\n  "});index.add({'id':33,'href':'/notes/docs/technology/cloud/Container/Kubernetes/api/doc/','title':"API文档",'content':"API文档 #  API Conventions #  This document is oriented at users who want a deeper understanding of the Kubernetes API structure, and developers wanting to extend the Kubernetes API. An introduction to using resources with kubectl can be found in the object management overview.\nTable of Contents\n Types (Kinds)   Resources Objects   Metadata Spec and Status   Typical status properties    References to related objects  Lists of named subobjects preferred over maps  Primitive types  Constants  Unions    Lists and Simple kinds    Differing Representations Verbs on Resources   PATCH operations    Idempotency  Optional vs. Required  Defaulting  Late Initialization  Concurrency Control and Consistency  Serialization Format  Units  Selecting Fields  Object references HTTP Status codes   Success codes  Error codes    Response Status Kind  Events  Naming conventions  Label, selector, and annotation conventions  WebSockets and SPDY  Validation  The conventions of the Kubernetes API (and related APIs in the ecosystem) are intended to ease client development and ensure that configuration mechanisms can be implemented that work across a diverse set of use cases consistently.\nThe general style of the Kubernetes API is RESTful - clients create, update, delete, or retrieve a description of an object via the standard HTTP verbs (POST, PUT, DELETE, and GET) - and those APIs preferentially accept and return JSON. Kubernetes also exposes additional endpoints for non-standard verbs and allows alternative content types. All of the JSON accepted and returned by the server has a schema, identified by the \u0026ldquo;kind\u0026rdquo; and \u0026ldquo;apiVersion\u0026rdquo; fields. Where relevant HTTP header fields exist, they should mirror the content of JSON fields, but the information should not be represented only in the HTTP header.\nThe following terms are defined:\n  Kind the name of a particular object schema (e.g. the \u0026ldquo;Cat\u0026rdquo; and \u0026ldquo;Dog\u0026rdquo; kinds would have different attributes and properties)\n  Resource\na representation of a system entity, sent or retrieved as JSON via HTTP to the server. Resources are exposed via:\n Collections - a list of resources of the same type, which may be queryable Elements - an individual resource, addressable via a URL    API Group a set of resources that are exposed together. Along with the version is exposed in the \u0026ldquo;apiVersion\u0026rdquo; field as \u0026ldquo;GROUP/VERSION\u0026rdquo;, e.g. \u0026ldquo;policy.k8s.io/v1\u0026rdquo;.\n  Each resource typically accepts and returns data of a single kind. A kind may be accepted or returned by multiple resources that reflect specific use cases. For instance, the kind \u0026ldquo;Pod\u0026rdquo; is exposed as a \u0026ldquo;pods\u0026rdquo; resource that allows end users to create, update, and delete pods, while a separate \u0026ldquo;pod status\u0026rdquo; resource (that acts on \u0026ldquo;Pod\u0026rdquo; kind) allows automated processes to update a subset of the fields in that resource.\nResources are bound together in API groups - each group may have one or more versions that evolve independent of other API groups, and each version within the group has one or more resources. Group names are typically in domain name form - the Kubernetes project reserves use of the empty group, all single word names (\u0026ldquo;extensions\u0026rdquo;, \u0026ldquo;apps\u0026rdquo;), and any group name ending in \u0026ldquo;*.k8s.io\u0026rdquo; for its sole use. When choosing a group name, we recommend selecting a subdomain your group or organization owns, such as \u0026ldquo;widget.mycompany.com\u0026rdquo;.\nVersion strings should match DNS_LABEL format.\nResource collections should be all lowercase and plural, whereas kinds are CamelCase and singular. Group names must be lower case and be valid DNS subdomains.\nTypes (Kinds) #  Kinds are grouped into three categories:\n  Objects represent a persistent entity in the system.\nCreating an API object is a record of intent - once created, the system will work to ensure that resource exists. All API objects have common metadata.\nAn object may have multiple resources that clients can use to perform specific actions that create, update, delete, or get.\nExamples: Pod, ReplicationController, Service, Namespace, Node.\n  Lists are collections of resources of one (usually) or more (occasionally) kinds.\nThe name of a list kind must end with \u0026ldquo;List\u0026rdquo;. Lists have a limited set of common metadata. All lists use the required \u0026ldquo;items\u0026rdquo; field to contain the array of objects they return. Any kind that has the \u0026ldquo;items\u0026rdquo; field must be a list kind.\nMost objects defined in the system should have an endpoint that returns the full set of resources, as well as zero or more endpoints that return subsets of the full list. Some objects may be singletons (the current user, the system defaults) and may not have lists.\nIn addition, all lists that return objects with labels should support label filtering (see the labels documentation), and most lists should support filtering by fields.\nExamples: PodLists, ServiceLists, NodeLists.\nTODO: Describe field filtering below or in a separate doc.\n  Simple kinds are used for specific actions on objects and for non-persistent entities.\nGiven their limited scope, they have the same set of limited common metadata as lists.\nFor instance, the \u0026ldquo;Status\u0026rdquo; kind is returned when errors occur and is not persisted in the system.\nMany simple resources are \u0026ldquo;subresources\u0026rdquo;, which are rooted at API paths of specific resources. When resources wish to expose alternative actions or views that are closely coupled to a single resource, they should do so using new sub-resources. Common subresources include:\n /binding: Used to bind a resource representing a user request (e.g., Pod, PersistentVolumeClaim) to a cluster infrastructure resource (e.g., Node, PersistentVolume). /status: Used to write just the status portion of a resource. For example, the /pods endpoint only allows updates to metadata and spec, since those reflect end-user intent. An automated process should be able to modify status for users to see by sending an updated Pod kind to the server to the \u0026ldquo;/pods//status\u0026rdquo; endpoint - the alternate endpoint allows different rules to be applied to the update, and access to be appropriately restricted. /scale: Used to read and write the count of a resource in a manner that is independent of the specific resource schema.  Two additional subresources, proxy and portforward, provide access to cluster resources as described in accessing the cluster.\n  The standard REST verbs (defined below) MUST return singular JSON objects. Some API endpoints may deviate from the strict REST pattern and return resources that are not singular JSON objects, such as streams of JSON objects or unstructured text log data.\nA common set of \u0026ldquo;meta\u0026rdquo; API objects are used across all API groups and are thus considered part of the API group named meta.k8s.io. These types may evolve independent of the API group that uses them and API servers may allow them to be addressed in their generic form. Examples are ListOptions, DeleteOptions, List, Status, WatchEvent, and Scale. For historical reasons these types are part of each existing API group. Generic tools like quota, garbage collection, autoscalers, and generic clients like kubectl leverage these types to define consistent behavior across different resource types, like the interfaces in programming languages.\nThe term \u0026ldquo;kind\u0026rdquo; is reserved for these \u0026ldquo;top-level\u0026rdquo; API types. The term \u0026ldquo;type\u0026rdquo; should be used for distinguishing sub-categories within objects or subobjects.\nResources #  All JSON objects returned by an API MUST have the following fields:\n kind: a string that identifies the schema this object should have apiVersion: a string that identifies the version of the schema the object should have  These fields are required for proper decoding of the object. They may be populated by the server by default from the specified URL path, but the client likely needs to know the values in order to construct the URL path.\nObjects #  Metadata #  Every object kind MUST have the following metadata in a nested object field called \u0026ldquo;metadata\u0026rdquo;:\n namespace: a namespace is a DNS compatible label that objects are subdivided into. The default namespace is \u0026lsquo;default\u0026rsquo;. See the namespace docs for more. name: a string that uniquely identifies this object within the current namespace (see the identifiers docs). This value is used in the path when retrieving an individual object. uid: a unique in time and space value (typically an RFC 4122 generated identifier, see the identifiers docs) used to distinguish between objects with the same name that have been deleted and recreated  Every object SHOULD have the following metadata in a nested object field called \u0026ldquo;metadata\u0026rdquo;:\n resourceVersion: a string that identifies the internal version of this object that can be used by clients to determine when objects have changed. This value MUST be treated as opaque by clients and passed unmodified back to the server. Clients should not assume that the resource version has meaning across namespaces, different kinds of resources, or different servers. (See concurrency control, below, for more details.) generation: a sequence number representing a specific generation of the desired state. Set by the system and monotonically increasing, per-resource. May be compared, such as for RAW and WAW consistency. creationTimestamp: a string representing an RFC 3339 date of the date and time an object was created deletionTimestamp: a string representing an RFC 3339 date of the date and time after which this resource will be deleted. This field is set by the server when a graceful deletion is requested by the user, and is not directly settable by a client. The resource will be deleted (no longer visible from resource lists, and not reachable by name) after the time in this field except when the object has a finalizer set. In case the finalizer is set the deletion of the object is postponed at least until the finalizer is removed. Once the deletionTimestamp is set, this value may not be unset or be set further into the future, although it may be shortened or the resource may be deleted prior to this time. labels: a map of string keys and values that can be used to organize and categorize objects (see the labels docs) annotations: a map of string keys and values that can be used by external tooling to store and retrieve arbitrary metadata about this object (see the annotations docs)  Labels are intended for organizational purposes by end users (select the pods that match this label query). Annotations enable third-party automation and tooling to decorate objects with additional metadata for their own use.\nSpec and Status #  By convention, the Kubernetes API makes a distinction between the specification of the desired state of an object (a nested object field called \u0026ldquo;spec\u0026rdquo;) and the status of the object at the current time (a nested object field called \u0026ldquo;status\u0026rdquo;). The specification is a complete description of the desired state, including configuration settings provided by the user, default values expanded by the system, and properties initialized or otherwise changed after creation by other ecosystem components (e.g., schedulers, auto-scalers), and is persisted in stable storage with the API object. If the specification is deleted, the object will be purged from the system. The status summarizes the current state of the object in the system, and is usually persisted with the object by automated processes but may be generated on the fly. At some cost and perhaps some temporary degradation in behavior, the status could be reconstructed by observation if it were lost.\nWhen a new version of an object is POSTed or PUT, the \u0026ldquo;spec\u0026rdquo; is updated and available immediately. Over time the system will work to bring the \u0026ldquo;status\u0026rdquo; into line with the \u0026ldquo;spec\u0026rdquo;. The system will drive toward the most recent \u0026ldquo;spec\u0026rdquo; regardless of previous versions of that stanza. In other words, if a value is changed from 2 to 5 in one PUT and then back down to 3 in another PUT the system is not required to \u0026lsquo;touch base\u0026rsquo; at 5 before changing the \u0026ldquo;status\u0026rdquo; to 3. In other words, the system\u0026rsquo;s behavior is level-based rather than edge-based. This enables robust behavior in the presence of missed intermediate state changes.\nThe Kubernetes API also serves as the foundation for the declarative configuration schema for the system. In order to facilitate level-based operation and expression of declarative configuration, fields in the specification should have declarative rather than imperative names and semantics \u0026ndash; they represent the desired state, not actions intended to yield the desired state.\nThe PUT and POST verbs on objects MUST ignore the \u0026ldquo;status\u0026rdquo; values, to avoid accidentally overwriting the status in read-modify-write scenarios. A /status subresource MUST be provided to enable system components to update statuses of resources they manage.\nOtherwise, PUT expects the whole object to be specified. Therefore, if a field is omitted it is assumed that the client wants to clear that field\u0026rsquo;s value. The PUT verb does not accept partial updates. Modification of just part of an object may be achieved by GETting the resource, modifying part of the spec, labels, or annotations, and then PUTting it back. See concurrency control, below, regarding read-modify-write consistency when using this pattern. Some objects may expose alternative resource representations that allow mutation of the status, or performing custom actions on the object.\nAll objects that represent a physical resource whose state may vary from the user\u0026rsquo;s desired intent SHOULD have a \u0026ldquo;spec\u0026rdquo; and a \u0026ldquo;status\u0026rdquo;. Objects whose state cannot vary from the user\u0026rsquo;s desired intent MAY have only \u0026ldquo;spec\u0026rdquo;, and MAY rename \u0026ldquo;spec\u0026rdquo; to a more appropriate name.\nObjects that contain both spec and status should not contain additional top-level fields other than the standard metadata fields.\nSome objects which are not persisted in the system - such as SubjectAccessReview and other webhook style calls - may choose to add spec and status to encapsulate a \u0026ldquo;call and response\u0026rdquo; pattern. The spec is the request (often a request for information) and the status is the response. For these RPC like objects the only operation may be POST, but having a consistent schema between submission and response reduces the complexity of these clients.\nTypical status properties #  Conditions represent the latest available observations of an object\u0026rsquo;s state. They are an extension mechanism intended to be used when the details of an observation are not a priori known or would not apply to all instances of a given Kind. For observations that are well known and apply to all instances, a regular field is preferred. An example of a Condition that probably should have been a regular field is Pod\u0026rsquo;s \u0026ldquo;Ready\u0026rdquo; condition - it is managed by core controllers, it is well understood, and it applies to all Pods.\nObjects may report multiple conditions, and new types of conditions may be added in the future or by 3rd party controllers. Therefore, conditions are represented using a list/slice, where all have similar structure.\nThe FooCondition type for some resource type Foo may include a subset of the following fields, but must contain at least type and status fields:\n Type FooConditionType `json:\u0026quot;type\u0026quot; description:\u0026quot;type of Foo condition\u0026quot;` Status ConditionStatus `json:\u0026quot;status\u0026quot; description:\u0026quot;status of the condition, one of True, False, Unknown\u0026quot;` // +optional Reason *string `json:\u0026quot;reason,omitempty\u0026quot; description:\u0026quot;one-word CamelCase reason for the condition's last transition\u0026quot;` // +optional Message *string `json:\u0026quot;message,omitempty\u0026quot; description:\u0026quot;human-readable message indicating details about last transition\u0026quot;` // +optional LastHeartbeatTime *unversioned.Time `json:\u0026quot;lastHeartbeatTime,omitempty\u0026quot; description:\u0026quot;last time we got an update on a given condition\u0026quot;` // +optional LastTransitionTime *unversioned.Time `json:\u0026quot;lastTransitionTime,omitempty\u0026quot; description:\u0026quot;last time the condition transit from one status to another\u0026quot;` Additional fields may be added in the future.\nDo not use fields that you don\u0026rsquo;t need - simpler is better.\nUse of the Reason field is encouraged.\nUse the LastHeartbeatTime with great caution - frequent changes to this field can cause a large fan-out effect for some resources.\nConditions should be added to explicitly convey properties that users and components care about rather than requiring those properties to be inferred from other observations. Once defined, the meaning of a Condition can not be changed arbitrarily - it becomes part of the API, and has the same backwards- and forwards-compatibility concerns of any other part of the API.\nCondition status values may be True, False, or Unknown. The absence of a condition should be interpreted the same as Unknown. How controllers handle Unknown depends on the Condition in question.\nCondition types should indicate state in the \u0026ldquo;abnormal-true\u0026rdquo; polarity. For example, if the condition indicates when a policy is invalid, the \u0026ldquo;is valid\u0026rdquo; case is probably the norm, so the condition should be called \u0026ldquo;Invalid\u0026rdquo;.\nThe thinking around conditions has evolved over time, so there are several non-normative examples in wide use.\nIn general, condition values may change back and forth, but some condition transitions may be monotonic, depending on the resource and condition type. However, conditions are observations and not, themselves, state machines, nor do we define comprehensive state machines for objects, nor behaviors associated with state transitions. The system is level-based rather than edge-triggered, and should assume an Open World.\nAn example of an oscillating condition type is Ready (despite it running afoul of current guidance), which indicates the object was believed to be fully operational at the time it was last probed. A possible monotonic condition could be Failed. A True status for Failed would imply failure with no retry. An object that was still active would generally not have a Failed condition.\nSome resources in the v1 API contain fields called phase, and associated message, reason, and other status fields. The pattern of using phase is deprecated. Newer API types should use conditions instead. Phase was essentially a state-machine enumeration field, that contradicted system-design principles and hampered evolution, since adding new enum values breaks backward compatibility. Rather than encouraging clients to infer implicit properties from phases, we prefer to explicitly expose the individual conditions that clients need to monitor. Conditions also have the benefit that it is possible to create some conditions with uniform meaning across all resource types, while still exposing others that are unique to specific resource types. See #7856 for more details and discussion.\nIn condition types, and everywhere else they appear in the API, Reason is intended to be a one-word, CamelCase representation of the category of cause of the current status, and Message is intended to be a human-readable phrase or sentence, which may contain specific details of the individual occurrence. Reason is intended to be used in concise output, such as one-line kubectl get output, and in summarizing occurrences of causes, whereas Message is intended to be presented to users in detailed status explanations, such as kubectl describe output.\nHistorical information status (e.g., last transition time, failure counts) is only provided with reasonable effort, and is not guaranteed to not be lost.\nStatus information that may be large (especially proportional in size to collections of other resources, such as lists of references to other objects \u0026ndash; see below) and/or rapidly changing, such as resource usage, should be put into separate objects, with possibly a reference from the original object. This helps to ensure that GETs and watch remain reasonably efficient for the majority of clients, which may not need that data.\nSome resources report the observedGeneration, which is the generation most recently observed by the component responsible for acting upon changes to the desired state of the resource. This can be used, for instance, to ensure that the reported status reflects the most recent desired status.\nReferences to related objects #  References to loosely coupled sets of objects, such as pods overseen by a replication controller, are usually best referred to using a label selector. In order to ensure that GETs of individual objects remain bounded in time and space, these sets may be queried via separate API queries, but will not be expanded in the referring object\u0026rsquo;s status.\nReferences to specific objects, especially specific resource versions and/or specific fields of those objects, are specified using the ObjectReference type (or other types representing strict subsets of it). Unlike partial URLs, the ObjectReference type facilitates flexible defaulting of fields from the referring object or other contextual information.\nReferences in the status of the referee to the referrer may be permitted, when the references are one-to-one and do not need to be frequently updated, particularly in an edge-based manner.\nLists of named subobjects preferred over maps #  Discussed in #2004 and elsewhere. There are no maps of subobjects in any API objects. Instead, the convention is to use a list of subobjects containing name fields.\nFor example:\nports: - name: www containerPort: 80 vs.\nports: www: containerPort: 80 This rule maintains the invariant that all JSON/YAML keys are fields in API objects. The only exceptions are pure maps in the API (currently, labels, selectors, annotations, data), as opposed to sets of subobjects.\nPrimitive types #   Avoid floating-point values as much as possible, and never use them in spec. Floating-point values cannot be reliably round-tripped (encoded and re-decoded) without changing, and have varying precision and representations across languages and architectures. All numbers (e.g., uint32, int64) are converted to float64 by Javascript and some other languages, so any field which is expected to exceed that either in magnitude or in precision (specifically integer values \u0026gt; 53 bits) should be serialized and accepted as strings. Do not use unsigned integers, due to inconsistent support across languages and libraries. Just validate that the integer is non-negative if that\u0026rsquo;s the case. Do not use enums. Use aliases for string instead (e.g., NodeConditionType). Look at similar fields in the API (e.g., ports, durations) and follow the conventions of existing fields. All public integer fields MUST use the Go (u)int32 or Go (u)int64 types, not (u)int (which is ambiguous depending on target platform). Internal types may use (u)int. Think twice about bool fields. Many ideas start as boolean but eventually trend towards a small set of mutually exclusive options. Plan for future expansions by describing the policy options explicitly as a string type alias (e.g. TerminationMessagePolicy).  Constants #  Some fields will have a list of allowed values (enumerations). These values will be strings, and they will be in CamelCase, with an initial uppercase letter. Examples: ClusterFirst, Pending, ClientIP.\nUnions #  Sometimes, at most one of a set of fields can be set. For example, the [volumes] field of a PodSpec has 17 different volume type-specific fields, such as nfs and iscsi. All fields in the set should be Optional.\nSometimes, when a new type is created, the api designer may anticipate that a union will be needed in the future, even if only one field is allowed initially. In this case, be sure to make the field Optional In the validation, you may still return an error if the sole field is unset. Do not set a default value for that field.\nLists and Simple kinds #  Every list or simple kind SHOULD have the following metadata in a nested object field called \u0026ldquo;metadata\u0026rdquo;:\n resourceVersion: a string that identifies the common version of the objects returned by in a list. This value MUST be treated as opaque by clients and passed unmodified back to the server. A resource version is only valid within a single namespace on a single kind of resource.  Every simple kind returned by the server, and any simple kind sent to the server that must support idempotency or optimistic concurrency should return this value. Since simple resources are often used as input alternate actions that modify objects, the resource version of the simple resource should correspond to the resource version of the object.\nDiffering Representations #  An API may represent a single entity in different ways for different clients, or transform an object after certain transitions in the system occur. In these cases, one request object may have two representations available as different resources, or different kinds.\nAn example is a Service, which represents the intent of the user to group a set of pods with common behavior on common ports. When Kubernetes detects a pod matches the service selector, the IP address and port of the pod are added to an Endpoints resource for that Service. The Endpoints resource exists only if the Service exists, but exposes only the IPs and ports of the selected pods. The full service is represented by two distinct resources - under the original Service resource the user created, as well as in the Endpoints resource.\nAs another example, a \u0026ldquo;pod status\u0026rdquo; resource may accept a PUT with the \u0026ldquo;pod\u0026rdquo; kind, with different rules about what fields may be changed.\nFuture versions of Kubernetes may allow alternative encodings of objects beyond JSON.\nVerbs on Resources #  API resources should use the traditional REST pattern:\n GET / - Retrieve a list of type , e.g. GET /pods returns a list of Pods. POST / - Create a new resource from the JSON object provided by the client. GET // - Retrieves a single resource with the given name, e.g. GET /pods/first returns a Pod named \u0026lsquo;first\u0026rsquo;. Should be constant time, and the resource should be bounded in size. DELETE // - Delete the single resource with the given name. DeleteOptions may specify gracePeriodSeconds, the optional duration in seconds before the object should be deleted. Individual kinds may declare fields which provide a default grace period, and different kinds may have differing kind-wide default grace periods. A user provided grace period overrides a default grace period, including the zero grace period (\u0026ldquo;now\u0026rdquo;). PUT // - Update or create the resource with the given name with the JSON object provided by the client. PATCH // - Selectively modify the specified fields of the resource. See more information below. GET /\u0026amp;watch=true - Receive a stream of JSON objects corresponding to changes made to any resource of the given kind over time.  PATCH operations #  The API supports three different PATCH operations, determined by their corresponding Content-Type header:\n  JSON Patch,\nContent-Type: application/json-patch+json  As defined in RFC6902, a JSON Patch is a sequence of operations that are executed on the resource, e.g. {\u0026quot;op\u0026quot;: \u0026quot;add\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/a/b/c\u0026quot;, \u0026quot;value\u0026quot;: [ \u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot; ]}. For more details on how to use JSON Patch, see the RFC.    Merge Patch,\nContent-Type: application/merge-patch+json  As defined in RFC7386, a Merge Patch is essentially a partial representation of the resource. The submitted JSON is \u0026ldquo;merged\u0026rdquo; with the current resource to create a new one, then the new one is saved. For more details on how to use Merge Patch, see the RFC.    Strategic Merge Patch,\nContent-Type: application/strategic-merge-patch+json  Strategic Merge Patch is a custom implementation of Merge Patch. For a detailed explanation of how it works and why it needed to be introduced, see here.    Idempotency #  All compatible Kubernetes APIs MUST support \u0026ldquo;name idempotency\u0026rdquo; and respond with an HTTP status code 409 when a request is made to POST an object that has the same name as an existing object in the system. See the identifiers docs for details.\nNames generated by the system may be requested using metadata.generateName. GenerateName indicates that the name should be made unique by the server prior to persisting it. A non-empty value for the field indicates the name will be made unique (and the name returned to the client will be different than the name passed). The value of this field will be combined with a unique suffix on the server if the Name field has not been provided. The provided value must be valid within the rules for Name, and may be truncated by the length of the suffix required to make the value unique on the server. If this field is specified, and Name is not present, the server will NOT return a 409 if the generated name exists - instead, it will either return 201 Created or 504 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\nOptional vs. Required #  Fields must be either optional or required.\nOptional fields have the following properties:\n They have the +optional comment tag in Go. They are a pointer type in the Go definition (e.g. AwesomeFlag *SomeFlag) or have a built-in nil value (e.g. maps and slices). The API server should allow POSTing and PUTing a resource with this field unset.  In most cases, optional fields should also have the omitempty struct tag (the omitempty option specifies that the field should be omitted from the json encoding if the field has an empty value). However, If you want to have different logic for an optional field which is not provided vs. provided with empty values, do not use omitempty (e.g. https://github.com/kubernetes/kubernetes/issues/34641).\nNote that for backward compatibility, any field that has the omitempty struct tag will be considered to be optional, but this may change in the future and having the +optional comment tag is highly recommended.\nRequired fields have the opposite properties, namely:\n They do not have an +optional comment tag. They do not have an omitempty struct tag. They are not a pointer type in the Go definition (e.g. AnotherFlag SomeFlag). The API server should not allow POSTing or PUTing a resource with this field unset.  Using the +optional or the omitempty tag causes OpenAPI documentation to reflect that the field is optional.\nUsing a pointer allows distinguishing unset from the zero value for that type. There are some cases where, in principle, a pointer is not needed for an optional field since the zero value is forbidden, and thus implies unset. There are examples of this in the codebase. However:\n it can be difficult for implementors to anticipate all cases where an empty value might need to be distinguished from a zero value structs are not omitted from encoder output even where omitempty is specified, which is messy; having a pointer consistently imply optional is clearer for users of the Go language client, and any other clients that use corresponding types  Therefore, we ask that pointers always be used with optional fields that do not have a built-in nil value.\nDefaulting #  Default resource values are API version-specific, and they are applied during the conversion from API-versioned declarative configuration to internal objects representing the desired state (Spec) of the resource. Subsequent GETs of the resource will include the default values explicitly.\nIncorporating the default values into the Spec ensures that Spec depicts the full desired state so that it is easier for the system to determine how to achieve the state, and for the user to know what to anticipate.\nAPI version-specific default values are set by the API server.\nLate Initialization #  Late initialization is when resource fields are set by a system controller after an object is created/updated.\nFor example, the scheduler sets the pod.spec.nodeName field after the pod is created.\nLate-initializers should only make the following types of modifications:\n Setting previously unset fields Adding keys to maps Adding values to arrays which have mergeable semantics (patchStrategy:\u0026quot;merge\u0026quot; attribute in the type definition).  These conventions:\n allow a user (with sufficient privilege) to override any system-default behaviors by setting the fields that would otherwise have been defaulted. enables updates from users to be merged with changes made during late initialization, using strategic merge patch, as opposed to clobbering the change. allow the component which does the late-initialization to use strategic merge patch, which facilitates composition and concurrency of such components.  Although the apiserver Admission Control stage acts prior to object creation, Admission Control plugins should follow the Late Initialization conventions too, to allow their implementation to be later moved to a \u0026lsquo;controller\u0026rsquo;, or to client libraries.\nConcurrency Control and Consistency #  Kubernetes leverages the concept of resource versions to achieve optimistic concurrency. All Kubernetes resources have a \u0026ldquo;resourceVersion\u0026rdquo; field as part of their metadata. This resourceVersion is a string that identifies the internal version of an object that can be used by clients to determine when objects have changed. When a record is about to be updated, it\u0026rsquo;s version is checked against a pre-saved value, and if it doesn\u0026rsquo;t match, the update fails with a StatusConflict (HTTP status code 409).\nThe resourceVersion is changed by the server every time an object is modified. If resourceVersion is included with the PUT operation the system will verify that there have not been other successful mutations to the resource during a read/modify/write cycle, by verifying that the current value of resourceVersion matches the specified value.\nThe resourceVersion is currently backed by etcd\u0026rsquo;s modifiedIndex. However, it\u0026rsquo;s important to note that the application should not rely on the implementation details of the versioning system maintained by Kubernetes. We may change the implementation of resourceVersion in the future, such as to change it to a timestamp or per-object counter.\nThe only way for a client to know the expected value of resourceVersion is to have received it from the server in response to a prior operation, typically a GET. This value MUST be treated as opaque by clients and passed unmodified back to the server. Clients should not assume that the resource version has meaning across namespaces, different kinds of resources, or different servers. Currently, the value of resourceVersion is set to match etcd\u0026rsquo;s sequencer. You could think of it as a logical clock the API server can use to order requests. However, we expect the implementation of resourceVersion to change in the future, such as in the case we shard the state by kind and/or namespace, or port to another storage system.\nIn the case of a conflict, the correct client action at this point is to GET the resource again, apply the changes afresh, and try submitting again. This mechanism can be used to prevent races like the following:\nClient #1 Client #2 GET Foo GET Foo Set Foo.Bar = \u0026quot;one\u0026quot; Set Foo.Baz = \u0026quot;two\u0026quot; PUT Foo PUT Foo When these sequences occur in parallel, either the change to Foo.Bar or the change to Foo.Baz can be lost.\nOn the other hand, when specifying the resourceVersion, one of the PUTs will fail, since whichever write succeeds changes the resourceVersion for Foo.\nresourceVersion may be used as a precondition for other operations (e.g., GET, DELETE) in the future, such as for read-after-write consistency in the presence of caching.\n\u0026ldquo;Watch\u0026rdquo; operations specify resourceVersion using a query parameter. It is used to specify the point at which to begin watching the specified resources. This may be used to ensure that no mutations are missed between a GET of a resource (or list of resources) and a subsequent Watch, even if the current version of the resource is more recent. This is currently the main reason that list operations (GET on a collection) return resourceVersion.\nSerialization Format #  APIs may return alternative representations of any resource in response to an Accept header or under alternative endpoints, but the default serialization for input and output of API responses MUST be JSON.\nA protobuf encoding is also accepted for built-in resources. As proto is not self-describing, there is an envelope wrapper which describes the type of the contents.\nAll dates should be serialized as RFC3339 strings.\nUnits #  Units must either be explicit in the field name (e.g., timeoutSeconds), or must be specified as part of the value (e.g., resource.Quantity). Which approach is preferred is TBD, though currently we use the fooSeconds convention for durations.\nDuration fields must be represented as integer fields with units being part of the field name (e.g. leaseDurationSeconds). We don\u0026rsquo;t use Duration in the API since that would require clients to implement go-compatible parsing.\nSelecting Fields #  Some APIs may need to identify which field in a JSON object is invalid, or to reference a value to extract from a separate resource. The current recommendation is to use standard JavaScript syntax for accessing that field, assuming the JSON object was transformed into a JavaScript object, without the leading dot, such as metadata.name.\nExamples:\n Find the field \u0026ldquo;current\u0026rdquo; in the object \u0026ldquo;state\u0026rdquo; in the second item in the array \u0026ldquo;fields\u0026rdquo;: fields[1].state.current  Object references #  Object references should either be called fooName if referring to an object of kind Foo by just the name (within the current namespace, if a namespaced resource), or should be called fooRef, and should contain a subset of the fields of the ObjectReference type.\nTODO: Plugins, extensions, nested kinds, headers\nHTTP Status codes #  The server will respond with HTTP status codes that match the HTTP spec. See the section below for a breakdown of the types of status codes the server will send.\nThe following HTTP status codes may be returned by the API.\nSuccess codes #    200 StatusOK  Indicates that the request completed successfully.    201 StatusCreated  Indicates that the request to create kind completed successfully.    204 StatusNoContent  Indicates that the request completed successfully, and the response contains no body. Returned in response to HTTP OPTIONS requests.    Error codes #   307 StatusTemporaryRedirect  Indicates that the address for the requested resource has changed. Suggested client recovery behavior:  Follow the redirect.     400 StatusBadRequest  Indicates the requested is invalid. Suggested client recovery behavior:  Do not retry. Fix the request.     401 StatusUnauthorized  Indicates that the server can be reached and understood the request, but refuses to take any further action, because the client must provide authorization. If the client has provided authorization, the server is indicating the provided authorization is unsuitable or invalid. Suggested client recovery behavior:  If the user has not supplied authorization information, prompt them for the appropriate credentials. If the user has supplied authorization information, inform them their credentials were rejected and optionally prompt them again.     403 StatusForbidden  Indicates that the server can be reached and understood the request, but refuses to take any further action, because it is configured to deny access for some reason to the requested resource by the client. Suggested client recovery behavior:  Do not retry. Fix the request.     404 StatusNotFound  Indicates that the requested resource does not exist. Suggested client recovery behavior:  Do not retry. Fix the request.     405 StatusMethodNotAllowed  Indicates that the action the client attempted to perform on the resource was not supported by the code. Suggested client recovery behavior:  Do not retry. Fix the request.     409 StatusConflict  Indicates that either the resource the client attempted to create already exists or the requested update operation cannot be completed due to a conflict. Suggested client recovery behavior:  If creating a new resource:  Either change the identifier and try again, or GET and compare the fields in the pre-existing object and issue a PUT/update to modify the existing object.   If updating an existing resource:  See Conflict from the status response section below on how to retrieve more information about the nature of the conflict. GET and compare the fields in the pre-existing object, merge changes (if still valid according to preconditions), and retry with the updated request (including ResourceVersion).       410 StatusGone  Indicates that the item is no longer available at the server and no forwarding address is known. Suggested client recovery behavior:  Do not retry. Fix the request.     422 StatusUnprocessableEntity  Indicates that the requested create or update operation cannot be completed due to invalid data provided as part of the request. Suggested client recovery behavior:  Do not retry. Fix the request.     429 StatusTooManyRequests  Indicates that the either the client rate limit has been exceeded or the server has received more requests then it can process. Suggested client recovery behavior:  Read the Retry-After HTTP header from the response, and wait at least that long before retrying.     500 StatusInternalServerError  Indicates that the server can be reached and understood the request, but either an unexpected internal error occurred and the outcome of the call is unknown, or the server cannot complete the action in a reasonable time (this may be due to temporary server load or a transient communication issue with another server). Suggested client recovery behavior:  Retry with exponential backoff.     503 StatusServiceUnavailable  Indicates that required service is unavailable. Suggested client recovery behavior:  Retry with exponential backoff.     504 StatusServerTimeout  Indicates that the request could not be completed within the given time. Clients can get this response ONLY when they specified a timeout param in the request. Suggested client recovery behavior:  Increase the value of the timeout param and retry with exponential backoff.      Response Status Kind #  Kubernetes will always return the Status kind from any API endpoint when an error occurs. Clients SHOULD handle these types of objects when appropriate.\nA Status kind will be returned by the API in two cases:\n When an operation is not successful (i.e. when the server would return a non 2xx HTTP status code). When a HTTP DELETE call is successful.  The status object is encoded as JSON and provided as the body of the response. The status object contains fields for humans and machine consumers of the API to get more detailed information for the cause of the failure. The information in the status object supplements, but does not override, the HTTP status code\u0026rsquo;s meaning. When fields in the status object have the same meaning as generally defined HTTP headers and that header is returned with the response, the header should be considered as having higher priority.\nExample:\n$ curl -v -k -H \u0026quot;Authorization: Bearer WhCDvq4VPpYhrcfmF6ei7V9qlbqTubUc\u0026quot; https://10.240.122.184:443/api/v1/namespaces/default/pods/grafana \u0026gt; GET /api/v1/namespaces/default/pods/grafana HTTP/1.1 \u0026gt; User-Agent: curl/7.26.0 \u0026gt; Host: 10.240.122.184 \u0026gt; Accept: */* \u0026gt; Authorization: Bearer WhCDvq4VPpYhrcfmF6ei7V9qlbqTubUc \u0026gt; \u0026lt; HTTP/1.1 404 Not Found \u0026lt; Content-Type: application/json \u0026lt; Date: Wed, 20 May 2015 18:10:42 GMT \u0026lt; Content-Length: 232 \u0026lt; { \u0026quot;kind\u0026quot;: \u0026quot;Status\u0026quot;, \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;, \u0026quot;metadata\u0026quot;: {}, \u0026quot;status\u0026quot;: \u0026quot;Failure\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;pods \\\u0026quot;grafana\\\u0026quot; not found\u0026quot;, \u0026quot;reason\u0026quot;: \u0026quot;NotFound\u0026quot;, \u0026quot;details\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;grafana\u0026quot;, \u0026quot;kind\u0026quot;: \u0026quot;pods\u0026quot; }, \u0026quot;code\u0026quot;: 404 } status field contains one of two possible values:\n Success Failure  message may contain human-readable description of the error\nreason may contain a machine-readable, one-word, CamelCase description of why this operation is in the Failure status. If this value is empty there is no information available. The reason clarifies an HTTP status code but does not override it.\ndetails may contain extended data associated with the reason. Each reason may define its own extended details. This field is optional and the data returned is not guaranteed to conform to any schema except that defined by the reason type.\nPossible values for the reason and details fields:\n  BadRequest\n Indicates that the request itself was invalid, because the request doesn\u0026rsquo;t make any sense, for example deleting a read-only object. This is different than status reason Invalid above which indicates that the API call could possibly succeed, but the data was invalid. API calls that return BadRequest can never succeed. Http status code: 400 StatusBadRequest    Unauthorized\n  Indicates that the server can be reached and understood the request, but refuses to take any further action without the client providing appropriate authorization. If the client has provided authorization, this error indicates the provided credentials are insufficient or invalid.\n  Details (optional):\n  kind string  The kind attribute of the unauthorized resource (on some operations may differ from the requested resource).    name string  The identifier of the unauthorized resource.      HTTP status code: 401 StatusUnauthorized\n    Forbidden\n  Indicates that the server can be reached and understood the request, but refuses to take any further action, because it is configured to deny access for some reason to the requested resource by the client.\n  Details (optional):\n  kind string  The kind attribute of the forbidden resource (on some operations may differ from the requested resource).    name string  The identifier of the forbidden resource.      HTTP status code: 403 StatusForbidden\n    NotFound\n  Indicates that one or more resources required for this operation could not be found.\n  Details (optional):\n  kind string  The kind attribute of the missing resource (on some operations may differ from the requested resource).    name string  The identifier of the missing resource.      HTTP status code: 404 StatusNotFound\n    AlreadyExists\n  Indicates that the resource you are creating already exists.\n  Details (optional):\n  kind string  The kind attribute of the conflicting resource.    name string  The identifier of the conflicting resource.      HTTP status code: 409 StatusConflict\n    Conflict\n Indicates that the requested update operation cannot be completed due to a conflict. The client may need to alter the request. Each resource may define custom details that indicate the nature of the conflict. HTTP status code: 409 StatusConflict    Invalid\n  Indicates that the requested create or update operation cannot be completed due to invalid data provided as part of the request.\n  Details (optional):\n  kind string  the kind attribute of the invalid resource    name string  the identifier of the invalid resource    causes  One or more StatusCause entries indicating the data in the provided resource that was invalid. The reason, message, and field attributes will be set.      HTTP status code: 422 StatusUnprocessableEntity\n    Timeout\n Indicates that the request could not be completed within the given time. Clients may receive this response if the server has decided to rate limit the client, or if the server is overloaded and cannot process the request at this time. Http status code: 429 TooManyRequests The server should set the Retry-After HTTP header and return retryAfterSeconds in the details field of the object. A value of 0 is the default.    ServerTimeout\n  Indicates that the server can be reached and understood the request, but cannot complete the action in a reasonable time. This maybe due to temporary server load or a transient communication issue with another server.\n  Details (optional):\n  kind string  The kind attribute of the resource being acted on.    name string  The operation that is being attempted.        The server should set the Retry-After HTTP header and return retryAfterSeconds in the details field of the object. A value of 0 is the default.\n  Http status code: 504 StatusServerTimeout\n    MethodNotAllowed\n Indicates that the action the client attempted to perform on the resource was not supported by the code. For instance, attempting to delete a resource that can only be created. API calls that return MethodNotAllowed can never succeed. Http status code: 405 StatusMethodNotAllowed    InternalError\n  Indicates that an internal error occurred, it is unexpected and the outcome of the call is unknown.\n  Details (optional):\n  causes  The original error.      Http status code: 500 StatusInternalServerError code may contain the suggested HTTP return code for this status.\n    Events #  Events are complementary to status information, since they can provide some historical information about status and occurrences in addition to current or previous status. Generate events for situations users or administrators should be alerted about.\nChoose a unique, specific, short, CamelCase reason for each event category. For example, FreeDiskSpaceInvalid is a good event reason because it is likely to refer to just one situation, but Started is not a good reason because it doesn\u0026rsquo;t sufficiently indicate what started, even when combined with other event fields.\nError creating foo or Error creating foo %s would be appropriate for an event message, with the latter being preferable, since it is more informational.\nAccumulate repeated events in the client, especially for frequent events, to reduce data volume, load on the system, and noise exposed to users.\nNaming conventions #    Go field names must be CamelCase. JSON field names must be camelCase. Other than capitalization of the initial letter, the two should almost always match. No underscores nor dashes in either.\n  Field and resource names should be declarative, not imperative (DoSomething, SomethingDoer, DoneBy, DoneAt).\n  Use Node where referring to the node resource in the context of the cluster. Use Host where referring to properties of the individual physical/virtual system, such as hostname, hostPath, hostNetwork, etc.\n  FooController is a deprecated kind naming convention. Name the kind after the thing being controlled instead (e.g., Job rather than JobController).\n  The name of a field that specifies the time at which something occurs should be called somethingTime. Do not use stamp (e.g., creationTimestamp).\n  We use the\nfooSeconds convention for durations, as discussed in the\nunits subsection\n.\n fooPeriodSeconds is preferred for periodic intervals and other waiting periods (e.g., over fooIntervalSeconds). fooTimeoutSeconds is preferred for inactivity/unresponsiveness deadlines. fooDeadlineSeconds is preferred for activity completion deadlines.    Do not use abbreviations in the API, except where they are extremely commonly used, such as \u0026ldquo;id\u0026rdquo;, \u0026ldquo;args\u0026rdquo;, or \u0026ldquo;stdin\u0026rdquo;.\n  Acronyms should similarly only be used when extremely commonly known. All letters in the acronym should have the same case, using the appropriate case for the situation. For example, at the beginning of a field name, the acronym should be all lowercase, such as \u0026ldquo;httpGet\u0026rdquo;. Where used as a constant, all letters should be uppercase, such as \u0026ldquo;TCP\u0026rdquo; or \u0026ldquo;UDP\u0026rdquo;.\n  The name of a field referring to another resource of kind Foo by name should be called fooName. The name of a field referring to another resource of kind Foo by ObjectReference (or subset thereof) should be called fooRef.\n  More generally, include the units and/or type in the field name if they could be ambiguous and they are not specified by the value or value type.\n  The name of a field expressing a boolean property called \u0026lsquo;fooable\u0026rsquo; should be called Fooable, not IsFooable.\n  Namespace Names #   The name of a namespace must be a DNS_LABEL. The kube- prefix is reserved for Kubernetes system namespaces, e.g. kube-system and kube-public. See the namespace docs for more information.  Label, selector, and annotation conventions #  Labels are the domain of users. They are intended to facilitate organization and management of API resources using attributes that are meaningful to users, as opposed to meaningful to the system. Think of them as user-created mp3 or email inbox labels, as opposed to the directory structure used by a program to store its data. The former enables the user to apply an arbitrary ontology, whereas the latter is implementation-centric and inflexible. Users will use labels to select resources to operate on, display label values in CLI/UI columns, etc. Users should always retain full power and flexibility over the label schemas they apply to labels in their namespaces.\nHowever, we should support conveniences for common cases by default. For example, what we now do in ReplicationController is automatically set the RC\u0026rsquo;s selector and labels to the labels in the pod template by default, if they are not already set. That ensures that the selector will match the template, and that the RC can be managed using the same labels as the pods it creates. Note that once we generalize selectors, it won\u0026rsquo;t necessarily be possible to unambiguously generate labels that match an arbitrary selector.\nIf the user wants to apply additional labels to the pods that it doesn\u0026rsquo;t select upon, such as to facilitate adoption of pods or in the expectation that some label values will change, they can set the selector to a subset of the pod labels. Similarly, the RC\u0026rsquo;s labels could be initialized to a subset of the pod template\u0026rsquo;s labels, or could include additional/different labels.\nFor disciplined users managing resources within their own namespaces, it\u0026rsquo;s not that hard to consistently apply schemas that ensure uniqueness. One just needs to ensure that at least one value of some label key in common differs compared to all other comparable resources. We could/should provide a verification tool to check that. However, development of conventions similar to the examples in Labels make uniqueness straightforward. Furthermore, relatively narrowly used namespaces (e.g., per environment, per application) can be used to reduce the set of resources that could potentially cause overlap.\nIn cases where users could be running misc. examples with inconsistent schemas, or where tooling or components need to programmatically generate new objects to be selected, there needs to be a straightforward way to generate unique label sets. A simple way to ensure uniqueness of the set is to ensure uniqueness of a single label value, such as by using a resource name, uid, resource hash, or generation number.\nProblems with uids and hashes, however, include that they have no semantic meaning to the user, are not memorable nor readily recognizable, and are not predictable. Lack of predictability obstructs use cases such as creation of a replication controller from a pod, such as people want to do when exploring the system, bootstrapping a self-hosted cluster, or deletion and re-creation of a new RC that adopts the pods of the previous one, such as to rename it. Generation numbers are more predictable and much clearer, assuming there is a logical sequence. Fortunately, for deployments that\u0026rsquo;s the case. For jobs, use of creation timestamps is common internally. Users should always be able to turn off auto-generation, in order to permit some of the scenarios described above. Note that auto-generated labels will also become one more field that needs to be stripped out when cloning a resource, within a namespace, in a new namespace, in a new cluster, etc., and will need to be ignored around when updating a resource via patch or read-modify-write sequence.\nInclusion of a system prefix in a label key is fairly hostile to UX. A prefix is only necessary in the case that the user cannot choose the label key, in order to avoid collisions with user-defined labels. However, I firmly believe that the user should always be allowed to select the label keys to use on their resources, so it should always be possible to override default label keys.\nTherefore, resources supporting auto-generation of unique labels should have a uniqueLabelKey field, so that the user could specify the key if they wanted to, but if unspecified, it could be set by default, such as to the resource type, like job, deployment, or replicationController. The value would need to be at least spatially unique, and perhaps temporally unique in the case of job.\nAnnotations have very different intended usage from labels. They are primarily generated and consumed by tooling and system extensions, or are used by end-users to engage non-standard behavior of components. For example, an annotation might be used to indicate that an instance of a resource expects additional handling by non-kubernetes controllers. Annotations may carry arbitrary payloads, including JSON documents. Like labels, annotation keys can be prefixed with a governing domain (e.g. example.com/key-name). Unprefixed keys (e.g. key-name) are reserved for end-users. Third-party components must use prefixed keys. Key prefixes under the \u0026ldquo;kubernetes.io\u0026rdquo; and \u0026ldquo;k8s.io\u0026rdquo; domains are reserved for use by the kubernetes project and must not be used by third-parties.\nIn early versions of Kubernetes, some in-development features represented new API fields as annotations, generally with the form something.alpha.kubernetes.io/name or something.beta.kubernetes.io/name (depending on our confidence in it). This pattern is deprecated. Some such annotations may still exist, but no new annotations may be defined. New API fields are now developed as regular fields.\nOther advice regarding use of labels, annotations, taints, and other generic map keys by Kubernetes components and tools:\n Key names should be all lowercase, with words separated by dashes instead of camelCase  For instance, prefer foo.kubernetes.io/foo-bar over foo.kubernetes.io/fooBar, prefer desired-replicas over DesiredReplicas   Unprefixed keys are reserved for end-users. All other labels and annotations must be prefixed. Key prefixes under \u0026ldquo;kubernetes.io\u0026rdquo; and \u0026ldquo;k8s.io\u0026rdquo; are reserved for the Kubernetes project.  Such keys are effectively part of the kubernetes API and may be subject to deprecation and compatibility policies.   Key names, including prefixes, should be precise enough that a user could plausibly understand where it came from and what it is for. Key prefixes should carry as much context as possible.  For instance, prefer subsystem.kubernetes.io/parameter over kubernetes.io/subsystem-parameter   Use annotations to store API extensions that the controller responsible for the resource doesn\u0026rsquo;t need to know about, experimental fields that aren\u0026rsquo;t intended to be generally used API fields, etc. Beware that annotations aren\u0026rsquo;t automatically handled by the API conversion machinery.  WebSockets and SPDY #  Some of the API operations exposed by Kubernetes involve transfer of binary streams between the client and a container, including attach, exec, portforward, and logging. The API therefore exposes certain operations over upgradeable HTTP connections ( described in RFC 2817) via the WebSocket and SPDY protocols. These actions are exposed as subresources with their associated verbs (exec, log, attach, and portforward) and are requested via a GET (to support JavaScript in a browser) and POST (semantically accurate).\nThere are two primary protocols in use today:\n  Streamed channels\nWhen dealing with multiple independent binary streams of data such as the remote execution of a shell command (writing to STDIN, reading from STDOUT and STDERR) or forwarding multiple ports the streams can be multiplexed onto a single TCP connection. Kubernetes supports a SPDY based framing protocol that leverages SPDY channels and a WebSocket framing protocol that multiplexes multiple channels onto the same stream by prefixing each binary chunk with a byte indicating its channel. The WebSocket protocol supports an optional subprotocol that handles base64-encoded bytes from the client and returns base64-encoded bytes from the server and character based channel prefixes (\u0026lsquo;0\u0026rsquo;, \u0026lsquo;1\u0026rsquo;, \u0026lsquo;2\u0026rsquo;) for ease of use from JavaScript in a browser.\n  Streaming response\nThe default log output for a channel of streaming data is an HTTP Chunked Transfer-Encoding, which can return an arbitrary stream of binary data from the server. Browser-based JavaScript is limited in its ability to access the raw data from a chunked response, especially when very large amounts of logs are returned, and in future API calls it may be desirable to transfer large files. The streaming API endpoints support an optional WebSocket upgrade that provides a unidirectional channel from the server to the client and chunks data as binary WebSocket frames. An optional WebSocket subprotocol is exposed that base64 encodes the stream before returning it to the client.\n  Clients should use the SPDY protocols if their clients have native support, or WebSockets as a fallback. Note that WebSockets is susceptible to Head-of-Line blocking and so clients must read and process each message sequentially. In the future, an HTTP/2 implementation will be exposed that deprecates SPDY.\nValidation #  API objects are validated upon receipt by the apiserver. Validation errors are flagged and returned to the caller in a Failure status with reason set to Invalid. In order to facilitate consistent error messages, we ask that validation logic adheres to the following guidelines whenever possible (though exceptional cases will exist).\n Be as precise as possible. Telling users what they CAN do is more useful than telling them what they CANNOT do. When asserting a requirement in the positive, use \u0026ldquo;must\u0026rdquo;. Examples: \u0026ldquo;must be greater than 0\u0026rdquo;, \u0026ldquo;must match regex \u0026lsquo;[a-z]+\u0026rsquo;\u0026rdquo;. Words like \u0026ldquo;should\u0026rdquo; imply that the assertion is optional, and must be avoided. When asserting a formatting requirement in the negative, use \u0026ldquo;must not\u0026rdquo;. Example: \u0026ldquo;must not contain \u0026lsquo;..'\u0026rdquo;. Words like \u0026ldquo;should not\u0026rdquo; imply that the assertion is optional, and must be avoided. When asserting a behavioral requirement in the negative, use \u0026ldquo;may not\u0026rdquo;. Examples: \u0026ldquo;may not be specified when otherField is empty\u0026rdquo;, \u0026ldquo;only name may be specified\u0026rdquo;. When referencing a literal string value, indicate the literal in single-quotes. Example: \u0026ldquo;must not contain \u0026lsquo;..'\u0026rdquo;. When referencing another field name, indicate the name in back-quotes. Example: \u0026ldquo;must be greater than request\u0026rdquo;. When specifying inequalities, use words rather than symbols. Examples: \u0026ldquo;must be less than 256\u0026rdquo;, \u0026ldquo;must be greater than or equal to 0\u0026rdquo;. Do not use words like \u0026ldquo;larger than\u0026rdquo;, \u0026ldquo;bigger than\u0026rdquo;, \u0026ldquo;more than\u0026rdquo;, \u0026ldquo;higher than\u0026rdquo;, etc. When specifying numeric ranges, use inclusive ranges when possible.  "});index.add({'id':34,'href':'/notes/docs/technology/cloud/Container/Docker/','title':"Docker",'content':"Docker #  What #   Docker是一个用于开发，交付和运行应用程序的开放平台。 Docker使您能够将应用程序与基础架构分开，从而可以快速交付软件。 借助Docker，您可以以与管理应用程序相同的方式来管理基础架构。\n  Docker平台 #  Docker提供了在松散隔离的环境（称为容器）中打包和运行应用程序的功能。隔离和安全性使您可以在给定主机上同时运行多个容器。容器重量轻，因为它们不需要管理程序的额外负担，而是直接在主机的内核中运行。这意味着与使用虚拟机相比，可以在给定的硬件组合上运行更多的容器。您甚至可以在实际上是虚拟机的主机中运行Docker容器！\nDocker提供了工具和平台来管理容器的生命周期：\n 使用容器开发应用程序及其支持组件。 容器成为分发和测试您的应用程序的单元。 准备就绪后，可以将应用程序作为容器或协调服务部署到生产环境中。无论您的生产环境是本地数据中心，云提供商还是二者的混合体，其工作原理都相同。   Docker Engine #  Docker Engine是具有这些主要组件的client-server应用程序：\n Docker daemon是一个长时间运行的守护进程 REST API指定程序可以用来与守护程序进行通信并指示其操作的接口 command line interface (CLI) 客户端  CLI使用Docker REST API通过脚本或直接CLI命令来控制Docker守护程序或与Docker守护程序进行交互。许多其他Docker应用程序都使用基础API和CLI。\nDocker daemon 创建和管理Docker对象，例如映像，容器，网络和卷。\n  How #  架构 #    底层技术 #  Namespaces #  Namespace实现对全局系统资源的一种封装隔离\nControl Groups #  CGroup是为了对一组进程进行统一的资源监控和限制\nUnion file systems #  Union file system 实现将不同分支中的文件和目录重叠以形成单个文件系统。\nContainer format #  Docker Engine将Namespace，CGroup和UnionFS组合到一个称为container format的包装器中。 默认容器格式为libcontainer。 将来，Docker可能会通过与BSD Jails或Solaris Zone等技术集成来支持其他容器格式。\n"});index.add({'id':35,'href':'/notes/docs/technology/program/Language/golang/','title':"Golang",'content':"Golang #  "});index.add({'id':36,'href':'/notes/docs/technology/network/Protocol/http/','title':"HTTP",'content':"HTTP #  HTTP，HyperText Transfer Protocol，超文本传输协议，是一种应用层协议，被广泛应用于互联网。\n "});index.add({'id':37,'href':'/notes/docs/technology/cloud/Container/Kubernetes/arch/','title':"Kubernetes 架构",'content':"架构 #  组件 #    Control Plane #  控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。\n控制平面组件可以在集群中的任何节点上运行。然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。\nkube-apiserver #  主节点上负责提供 Kubernetes API 服务的组件；它是 Kubernetes 控制面的前端。\nkube-apiserver 在设计上考虑了水平扩缩的需要。 换言之，通过部署多个实例可以实现扩缩。 参见 构造高可用集群。\netcd #  etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。\n您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。要了解 etcd 更深层次的信息，请参考 etcd 文档。\nkube-scheduler #  主节点上的组件，该组件监视那些新创建的未指定运行节点的 Pod，并选择节点让 Pod 在上面运行。\n调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。\nkube-controller-manager #  在主节点上运行 控制器的组件。\n从逻辑上讲，每个 控制器都是一个单独的进程，但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。\n这些控制器包括:\n 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应。 副本控制器（Replication Controller）: 负责为系统中的每个副本控制器对象维护正确数量的 Pod。 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)。 服务帐户和令牌控制器（Service Account \u0026amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌.  云控制器管理器-(cloud-controller-manager) #   cloud-controller-manager 运行与基础云提供商交互的控制器。cloud-controller-manager 二进制文件是 Kubernetes 1.6 版本中引入的 alpha 功能。\ncloud-controller-manager 仅运行云提供商特定的控制器循环。您必须在 kube-controller-manager 中禁用这些控制器循环，您可以通过在启动 kube-controller-manager 时将 --cloud-provider 参数设置为 external 来禁用控制器循环。\ncloud-controller-manager 允许云供应商的代码和 Kubernetes 代码彼此独立地发展。在以前的版本中，核心的 Kubernetes 代码依赖于特定云提供商的代码来实现功能。在将来的版本中，云供应商专有的代码应由云供应商自己维护，并与运行 Kubernetes 的云控制器管理器相关联。\n以下控制器具有云提供商依赖性:\n 节点控制器（Node Controller）: 用于检查云提供商以确定节点是否在云中停止响应后被删除 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器 数据卷控制器（Volume Controller）: 用于创建、附加和装载卷、并与云提供商进行交互以编排卷   Node #  节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。\nkubelet #  一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。\nkubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。kubelet 不会管理不是由 Kubernetes 创建的容器。\nkube-proxy #   kube-proxy 是集群中每个节点上运行的网络代理,实现 Kubernetes Service 概念的一部分。\nkube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。\n如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则，kube-proxy 仅转发流量本身。\n容器运行环境(Container Runtime) #  容器运行环境是负责运行容器的软件。\nKubernetes 支持多个容器运行环境: Docker、 containerd、 cri-o、 rktlet 以及任何实现 Kubernetes CRI (容器运行环境接口)。\n 插件(Addons) #  插件使用 Kubernetes 资源 ( DaemonSet, Deployment等) 实现集群功能。因为这些提供集群级别的功能，所以插件的命名空间资源属于 kube-system 命名空间。\n所选的插件如下所述：有关可用插件的扩展列表，请参见 插件 (Addons)。\nDNS #  尽管并非严格要求其他附加组件，但所有示例都依赖 集群 DNS，因此所有 Kubernetes 集群都应具有 DNS。\n除了您环境中的其他 DNS 服务器之外，集群 DNS 还是一个 DNS 服务器，它为 Kubernetes 服务提供 DNS 记录。\nCluster DNS 是一个 DNS 服务器，和您部署环境中的其他 DNS 服务器一起工作，为 Kubernetes 服务提供DNS记录。\nKubernetes 启动的容器自动将 DNS 服务器包含在 DNS 搜索中。\n用户界面(Dashboard) #   Dashboard 是 Kubernetes 集群的通用基于 Web 的 UI。它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。\n容器资源监控 #   容器资源监控将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。\n集群层面日志 #   集群层面日志 机制负责将容器的日志数据保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。\n 工作流程 #    "});index.add({'id':38,'href':'/notes/docs/technology/system/Linux/directory/','title':"Linux目录结构",'content':"Linux目录结构 #    /boot\n系统启动相关的文件，如内核、initrd，以及grub(bootloader)\n  /dev\n设备文件\n块设备：随机访问，数据块\n字符设备：线性访问，按字符为单位\n设备号：主设备号(major)和次设备号(minor)\n  /etc\n配置文件\n  /home\n用户的家目录，每一个用户的家目录通常默认为/home/USERNAME\n  /root\n管理员的家目录\n  /lib\n库文件\n静态库，.a\n动态库，.dll，.so（shared object）\n  /lib/modules\n内核模块文件\n  /media\n挂载点目录，移动设备\n  /mnt\n挂载点目录，额外的临时文件系统\n  /opt\n可选目录，第三方程序的安装目录\n  /proc\n伪文件系统，内核映射文件\n  /sys\n伪文件系统，跟硬件设备相关的属性映射文件\n  /tmp\n临时文件，/var/tmp\n  /var\n可变化的文件\n  /bin\n可执行文件，用户命令\n  /sbin\n可执行文件，管理命令\n  /usr\nshared，read-only\n/usr/bin\n/usr/sbin\n/usr/lib\n  /usr/local\n第三方软件\n/usr/local/bin\n/usr/local/sbin\n/usr/local/lib\n   "});index.add({'id':39,'href':'/notes/docs/technology/system/Linux/','title':"Linux系统",'content':"Linux系统 #  "});index.add({'id':40,'href':'/notes/docs/technology/system/Application/nginx/','title':"Nginx",'content':"Nginx #  概念 #  Nginx是一个开源免费的web服务器，同时可以作为反向代理、负载均衡和HTTP缓存的软件。\nNginx架构 #  "});index.add({'id':41,'href':'/notes/docs/technology/database/SQL/postgres/','title':"PostgreSQL",'content':"PostgreSQL #  "});index.add({'id':42,'href':'/notes/docs/technology/database/SQL/','title':"SQL",'content':"SQL #  "});index.add({'id':43,'href':'/notes/docs/technology/tool/TcpCopy/','title':"TcpCopy",'content':"TCPCopy #  TCPCopy是一个流量复制工具。\n 使用场景 #    压力测试\n  模拟实际场景\n  回归测试\n  性能对照\n   架构 #    TCPCopy包含两部分：\n  tcpcopy\n安装在线上服务器上，用于抓取线上的请求包\n  intercept\n安装在辅助服务器上，做一些辅助作业\n   安装使用 #  设备：\nonline server：线上机器(流量导出的机器)\ntarget server：测试机器(流量导入的机器)\nassistant server：辅助机器\n  在target server上添加路由\n $ route add -net CLINET_NET gw ASSISTANG_IP    在assistant server上安装intercept服务\n下载地址： https://github.com/session-replay-tools/intercept/releases\n安装：\n $ cd intercept $ ./configure --prefix=/usr/local/intercept $ make \u0026amp;\u0026amp; make insall  启动：\n $ /usr/local/intercept/sbin/intercept -i eth0 -F tcp and src host TARGET_IP and src port TARGET_PORT -d    在online server安装tcpcopy服务\n下载地址： https://github.com/session-replay-tools/tcpcopy/releases\n安装：\n $ cd tcpcopy $ ./configure --prefix=/usr/local/tcpcopy $ make \u0026amp;\u0026amp; make install  启动\n $ /usr/local/tcpcopy/sbin/tcpcopy -x ONLINE_IP:PORT-TARGET_IP:PORT -s ASSISTAND_IP -c CLIENT_IP -d     "});index.add({'id':44,'href':'/notes/docs/technology/bigdata/Application/zookeeper/','title':"Zookeeper",'content':"Zookeeper #  ZooKeeper是用于维护配置信息，命名，提供分布式同步和提供组服务的集中式服务。\n    架构\n   部署\n   优化\n   "});index.add({'id':45,'href':'/notes/docs/technology/system/Linux/start/','title':"启动",'content':"启动过程 #  整个过程基本可以分为POST–\u0026gt;BIOS–\u0026gt;MBR(GRUB)–\u0026gt;Kernel–\u0026gt;Init–\u0026gt;Runlevel。\n  详解 #    BIOS\nBIOS(Basic Input/Output System)，基本输入输出系统，该系统存储于主板的ROM芯片上。开机时，会最先读取该系统，然后会有一个加电自检过程，若没有异常就开始加载BIOS程序到内存当中。BIOS主要的一个功能就是存储了磁盘的启动顺序，BIOS会按照启动顺序去查找第一个磁盘头的MBR信息，并加载和执行MBR中的Bootloader程序，若第一个磁盘不存在MBR，则会继续查找第二个磁盘，一旦BootLoader程序被检测并加载内存中，BIOS就将控制权交接给了BootLoader程序。\n  MBR\nMBR(Master Boot Record)，主引导记录，MBR存储于磁盘的头部，大小为512bytes，其中，446bytes用于存储BootLoader程序，64bytes用于存储分区表信息，最后2bytes用于MBR的有效性检查。\n  GRUB\nGRUB(Grand Unified Bootloader)，多系统启动程序，其执行过程可分为三个步骤：\n  Stage1\n这个其实就是MBR，它的主要工作就是查找并加载第二段Bootloader程序(stage2)，但系统在没启动时，MBR根本找不到文件系统，也就找不到stage2所存放的位置，因此，就有了stage1_5\n  Stage1_5\n该步骤就是为了识别文件系统\n  Stage2\nGRUB程序会根据/boot/grub/grub.conf文件查找Kernel的信息，然后开始加载Kernel程序，当Kernel程序被检测并在加载到内存中，GRUB就将控制权交接给了Kernel程序。\nPS：实际上这个步骤/boot还没被挂载，GRUB直接识别grub所在磁盘的文件系统，所以实际上应该是/grub/grub.conf文件，该配置文件的信息如下：\ngrub.conf:\n #boot=/dev/sda default=0 #设定默认启动的title的编号，从0开始 timeout=5 #等待用户选择的超时时间 splashimage=(hd0,0)/boot/grub/splash.xpm.gz #GRUB的背景图片 hiddenmenu #隐藏菜单 title CentOS (2.6.18-194.el5PAE) #内核标题 root (hd0,0) #内核文件所在的设备 kernel /vmlinuz-2.6.18-194.el5PAE ro root=LABEL=/ #内核文件路径以及传递给内核的参数 initrd /initrd-2.6.18-194.el5PAE.img #ramdisk文件路径      Kernel\nKernel，内核，Kernel是Linux系统最主要的程序，实际上，Kernel的文件很小，只保留了最基本的模块，并以压缩的文件形式存储在硬盘中，当GRUB将Kernel读进内存，内存开始解压缩内核文件。讲内核启动，应该先讲下initrd这个文件，\ninitrd(Initial RAM Disk)，它在stage2这个步骤就被拷贝到了内存中，这个文件是在安装系统时产生的，是一个临时的根文件系统(rootfs)。因为Kernel为了精简，只保留了最基本的模块，因此，Kernel上并没有各种硬件的驱动程序，也就无法识rootfs所在的设备，故产生了initrd这个文件，该文件装载了必要的驱动模块，当Kernel启动时，可以从initrd文件中装载驱动模块，直到挂载真正的rootfs，然后将initrd从内存中移除。\nKernel会以只读方式挂载根文件系统，当根文件系统被挂载后，开始装载第一个进程(用户空间的进程)，执行/sbin/init，之后就将控制权交接给了init程序。\n  Init\ninit，初始化，顾名思义，该程序就是进行OS初始化操作，实际上是根据/etc/inittab(定义了系统默认运行级别)设定的动作进行脚本的执行，第一个被执行的脚本为/etc/rc.d/rc.sysinit，这个是真正的OS初始化脚本，其任务如下：\n  激活udev和selinux;\n  根据/etc/sysctl.conf文件，来设定内核参数;\n  设定系统时钟;\n  装载硬盘映射;\n  启用交换分区;\n  设置主机名;\n  根文件系统检测，并以读写方式重新挂载根文件系统;\n  激活RAID和LVM设备;\n  启用磁盘配额;\n  根据/etc/fstab，检查并挂载其他文件系统;\n  清理过期的锁和PID文件\n  执行完后，根据配置的启动级别，执行对应目录底下的脚本，最后执行/etc/rc.d/rc.local这个脚本，至此，系统启动完成。   Runlevel\nrunlevel，运行级别，不同的级别会启动的服务不一样，init会根据定义的级别去执行相应目录下的脚本，Linux的启动级别分为以下几种：\n0：关机模式\n1：单一用户模式(直接以管理员身份进入)\n2：多用户模式（无网络）\n3：多用户模式（命令行）\n4：保留\n5：多用户模式（图形界面）\n6：重启\n在不同的运行级别下，/etc/rc.d/rc这个脚本会分别执行不同目录下的脚本：\nRunlevel 0 – /etc/rc.d/rc0.d/\nRunlevel 1 – /etc/rc.d/rc1.d/\nRunlevel 2 – /etc/rc.d/rc2.d/\nRunlevel 3 – /etc/rc.d/rc3.d/\nRunlevel 4 – /etc/rc.d/rc4.d/\nRunlevel 5 – /etc/rc.d/rc5.d/\nRunlevel 6 – /etc/rc.d/rc6.d/\n这些目录下的脚本只有K和S开头的文件，K开头的文件为开机需要执行关闭的服务，S开头的文件为开机需要执行开启的服务。\n  "});index.add({'id':46,'href':'/notes/docs/technology/cloud/Container/','title':"容器技术",'content':"容器技术 #  What #  定义 #   容器提供了一种逻辑打包机制，以这种机制打包的应用可以脱离其实际运行的环境。利用这种脱离，不管目标环境是私有数据中心、公有云，还是开发者的个人笔记本电脑，您都可以轻松、一致地部署基于容器的应用。容器化使开发者和 IT 运营团队的关注点泾渭分明 - 开发者专注于应用逻辑和依赖项，而 IT 运营团队可以专注于部署和管理，不必为应用细节分心，例如具体的软件版本和应用特有的配置。\n  VM vs Container #    Why #  与虚拟机的硬件堆栈虚拟化不同，容器在操作系统级别进行虚拟化，且可以直接在操作系统内核上运行多个容器。也就是说，容器更轻巧：它们共享操作系统内核，启动速度更快，且与启动整个操作系统相比其占用的内存微乎其微。\n  一致的环境\n  在任何地方运行\n  隔离\n容器会在操作系统级别虚拟化 CPU、内存、存储和网络资源，为开发者提供在逻辑上与其他应用相隔离的沙盒化操作系统接口。\n   How #  基础 #  Namespaces #  Namespace是对全局系统资源的一种封装隔离，使得处于不同namespace的进程拥有独立的全局系统资源，改变一个namespace中的系统资源只会影响当前namespace里的进程，对其他namespace中的进程没有影响。\n目前，Linux内核里面实现了7种不同类型的namespace。\n名称 宏定义 隔离内容 Cgroup CLONE_NEWCGROUP Cgroup root directory (since Linux 4.6) IPC CLONE_NEWIPC System V IPC, POSIX message queues (since Linux 2.6.19) Network CLONE_NEWNET Network devices, stacks, ports, etc. (since Linux 2.6.24) Mount CLONE_NEWNS Mount points (since Linux 2.4.19) PID CLONE_NEWPID Process IDs (since Linux 2.6.24) User CLONE_NEWUSER User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8) UTS CLONE_NEWUTS Hostname and NIS domain name (since Linux 2.6.19) Control groups #  cgroup和namespace类似，也是将进程进行分组，但它的目的和namespace不一样，namespace是为了隔离进程组之间的资源，而cgroup是为了对一组进程进行统一的资源监控和限制。\ncgroup主要包括下面两部分：\n  subsystem\n一个subsystem就是一个内核模块，他被关联到一颗cgroup树之后，就会在树的每个节点（进程组）上做具体的操作。subsystem经常被称作\u0026quot;resource controller\u0026rdquo;，因为它主要被用来调度或者限制每个进程组的资源，但是这个说法不完全准确，因为有时我们将进程分组只是为了做一些监控，观察一下他们的状态，比如perf_event subsystem。到目前为止，Linux支持12种subsystem，比如限制CPU的使用时间，限制使用的内存，统计CPU的使用情况，冻结和恢复一组进程等。\n  hierarchy\n一个hierarchy可以理解为一棵cgroup树，树的每个节点就是一个进程组，每棵树都会与零到多个subsystem关联。在一颗树里面，会包含Linux系统中的所有进程，但每个进程只能属于一个节点（进程组）。系统中可以有很多颗cgroup树，每棵树都和不同的subsystem关联，一个进程可以属于多颗树，即一个进程可以属于多个进程组，只是这些进程组和不同的subsystem关联。目前Linux支持12种subsystem，如果不考虑不与任何subsystem关联的情况（systemd就属于这种情况），Linux里面最多可以建12颗cgroup树，每棵树关联一个subsystem，当然也可以只建一棵树，然后让这棵树关联所有的subsystem。当一颗cgroup树不和任何subsystem关联的时候，意味着这棵树只是将进程进行分组，至于要在分组的基础上做些什么，将由应用程序自己决定，systemd就是一个这样的例子。\n  Union file systems #  容器中使用的文件系统是可堆叠的，这意味着可以将不同分支中的文件和目录重叠以形成单个文件系统。该系统有助于避免在每次部署新容器时重复数据。Docker使用此技术实现镜像的功能 文档\n overlay2 aufs   案例 #  容器技术实现 #    Docker   容器编排与调度 #    Kubernetes  "});index.add({'id':47,'href':'/notes/docs/technology/bigdata/Application/','title':"应用",'content':"应用 #  "});index.add({'id':48,'href':'/notes/docs/technology/system/Basic/fileSystem/','title':"文件系统",'content':"文件系统 #  文件系统是一套实现了数据的存储、分级组织、访问和获取等操作的抽象数据类型（Abstract data type）。\n概念 #  文件系统是一种用于向用户提供底层数据访问的机制。它将设备中的空间划分为特定大小的块（或者称为簇），一般每块512字节。数据存储在这些块中，大小被修正为占用整数个块。由文件系统软件来负责将这些块组织为文件和目录，并记录哪些块被分配给了哪个文件，以及哪些块没有被使用。\n EXT2文件系统 #  EXT2文件系统是Linux底下最常用的文件系统。其结构如下：\n  Boot Sector\n启动扇区，这个启动扇区可以安装启动管理程序， 这是个非常重要的设计，因为如此一来我们就能够将不同的启动管理程序安装到个别的文件系统最前端，而不用覆盖整颗硬盘唯一的MBR.\n  Block Group\n  Super Block\n记录整个filesystem相关信息\n  Group Descriptions\n描述每个 block group 的开始与结束的 block 号码，以及说明每个区段 (superblock, bitmap, inodemap, data block) 分别介于哪一个 block 号码之间\n  Block Bitmap\n记录使用和未使用的block号码\n  Inode Bitmap\n记录使用和未使用的inode号码\n  Inode Table\n  Data Blocks\n数据块，实际存储数据的地方\n      Inode Table #  inode是ext2文件系统的基本构建块，每个文件和目录都有唯一一个inode。其机构如下：\n  Mode\n存取模式信息(read/write/excute)\n  Owner info\n拥有者与群组信息\n  Size\n文件的容量\n  Timestamps\n  创建或状态改变的时间(ctime)\n  最近一次的读取时间(atime)\n  最近修改的时间(mtime)\n    Direct Blocks\n12个直接指向block号码\n  Indirect Blocks\n间接指向，记录block号码的记录区\n  Double Indirect\n双间接指向\n  Triple Indirect\n三间接指向\n    Super Block #  Super Block是记录整个filesystem相关信息的地方，包括以下：\n  Magic Number\n  Revision Level\n  Mount Count and Maximum Mount Count\n  Block Group Number\n  Block Size\n  Blocks per Group\n  Free Blocks\n  Free Inodes\n  First Inode\n   目录和文件 #    目录\n当我们在 Linux 下的 ext2 文件系统创建一个目录时， ext2 会分配一个 inode 与至少一块 block 给该目录。其中，inode 记录该目录的相关权限与属性，并可记录分配到的那块 block 号码； 而 block 则是记录在这个目录下的文件名与该文件名占用的 inode 号码数据。\n  文件\n我们在 Linux 下的 ext2 创建一个一般文件时， ext2 会分配一个 inode 与相对于该文件大小的 block 数量给该文件。\n  "});index.add({'id':49,'href':'/notes/docs/other/learn/','title':"方法论",'content':"方法论 #  "});index.add({'id':50,'href':'/notes/docs/technology/cloud/Container/Docker/arch/','title':"架构",'content':"架构 #  组件 #    Docker daemon #  Docker daemon (dockerd) 监听Docker API请求并管理Docker对象，例如图像，容器，网络和卷。 守护程序还可以与其他守护程序通信以管理Docker服务。\nDocker client #  Docker client (docker) 是许多Docker用户与Docker交互的主要方式。 当您使用诸如docker run之类的命令时，客户端会将这些命令发送至dockerd，后者将其执行。 docker命令使用Docker API。 Docker客户端可以与多个守护程序通信。\nDocker registries #  Docker registry存储Docker映像。 Docker Hub是任何人都可以使用的公共注册表，并且Docker配置为默认在Docker Hub上查找映像。 您甚至可以运行自己的私人注册表。\n当使用 docker pull or docker run 命令时, 将从配置的registry中拉去镜像，当使用 docker push 命令时，镜像将被推送到配置的registry中 。\nDocker objects #  使用Docker时，您正在创建和使用映像，容器，网络，卷，插件和其他对象。 本节是其中一些对象的简要概述。\nIMAGES #  Image是一个只读模板，其中包含创建Docker容器的说明。 通常，一个图像基于另一个图像，并带有一些附加的自定义。 例如，您可以基于“ ubuntu”映像构建映像，但安装Apache Web服务器和您的应用程序以及运行应用程序所需的配置详细信息。\n您可以创建自己的图像，也可以仅使用其他人创建并在注册表中发布的图像。 要构建自己的映像，您可以使用简单的语法创建Dockerfile，以定义创建映像和运行映像所需的步骤。 Dockerfile中的每条指令都会在映像中创建一个层。 当您更改Dockerfile并重建映像时，仅重建那些已更改的层。 与其他虚拟化技术相比，这是使映像如此轻巧，小型和快速的部分原因。\nCONTAINERS #  Container是image的可运行实例。 您可以使用Docker API或CLI创建，启动，停止，移动或删除容器。 您可以将容器连接到一个或多个网络，将存储连接到它，甚至根据其当前状态创建一个新映像。\n默认情况下，容器与其他容器及其主机之间的隔离度相对较高。 您可以控制容器的网络，存储或其他基础子系统与其他容器或主机之间的隔离程度。\n容器由其映像以及在创建或启动时为其提供的任何配置选项定义。 删除容器后，未存储在永久性存储中的状态更改将消失。\nSERVICES #  Service使您可以在多个Docker守护程序之间扩展容器，这些守护程序都可以与多个managers和workers 一起作为swarm协同工作。 群的每个成员都是Docker守护程序，所有守护程序都使用Docker API进行通信。 服务允许您定义所需的状态，例如在任何给定时间必须可用的服务副本数。 默认情况下，该服务在所有工作节点之间是负载平衡的。 对于消费者而言，Docker服务似乎是一个单独的应用程序。 Docker Engine在Docker 1.12及更高版本中支持集群模式。\n "});index.add({'id':51,'href':'/notes/docs/technology/program/Revision/','title':"版本控制",'content':"版本控制 #  什么是“版本控制”？ #  版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n如果你是位图形或网页设计师，可能会需要保存某一幅图片或页面布局文件的所有修订版本（这或许是你非常渴望拥有的功能），采用版本控制系统（VCS）是个明智的选择。 有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。 使用版本控制系统通常还意味着，就算你乱来一气把整个项目中的文件改的改删的删，你也照样可以轻松恢复到原先的样子。 但额外增加的工作量却微乎其微。\n 分类 #    本地版本控制系统\n许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。\n为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。\n 其中最流行的一种叫做 RCS，现今许多计算机系统上都还看得到它的踪影。 甚至在流行的 Mac OS X 系统上安装了开发者工具包之后，也可以使用 rcs 命令。 它的工作原理是在硬盘上保存补丁集（补丁是指文件修订前后的变化）；通过应用所有的补丁，可以重新计算出各个版本的文件内容。\n  集中化的版本控制系统\n接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。 这类系统，诸如 CVS、 Subversion 以及 Perforce 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 多年以来，这已成为版本控制系统的标准做法。\n 这种做法带来了许多好处，特别是相较于老式的本地 VCS 来说。 现在，每个人都可以在一定程度上看到项目中的其他人正在做些什么。 而管理员也可以轻松掌控每个开发者的权限，并且管理一个 CVCS 要远比在各个客户端上维护本地数据库来得轻松容易。\n事分两面，有好有坏。 这么做最显而易见的缺点是中央服务器的单点故障。 如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。 如果中心数据库所在的磁盘发生损坏，又没有做恰当备份，毫无疑问你将丢失所有数据——包括项目的整个变更历史，只剩下人们在各自机器上保留的单独快照。 本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。\n  分布式版本控制系统\n于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 在这类系统中，像 Git、Mercurial、Bazaar 以及 Darcs 等，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。 这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。 因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。\n 更进一步，许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分别和不同工作小组的人相互协作。 你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以前的集中式系统中是无法实现的。\n  "});index.add({'id':52,'href':'/notes/docs/technology/program/Advanced/algorithm/','title':"算法",'content':"算法 #   冒泡排序  对于一个无序的序列，每次对比两个相邻数的大小，若第i个数大于第i+1个数，两个数进行位置互换。每组排序可以选出一个最大的数，然后继续从第一个数开始进行对比，直到完成排序\n#伪代码 int num[] for(int i=0; i \u0026lt; num.length-1; i++){ for(int j=0; j \u0026lt; num.length-i-1; j++){ if( num[j] \u0026gt; num[j+1] ){ int temp = num[j] num[j+1] = num[j] num[j] = temp } } }   选择排序  对于一个无序的序列，从第一个数开始，每次跟接下去的数对比，若第1个数小于第i个数，两个数位置互换，每次选出最小的数，然后开始对比第二个数，直到完成排序。\n#伪代码 int num[] for(int i=0; i \u0026lt; num.length-1; i++){ for(int j=i+1; j \u0026lt; num.length-1; j++){ if( num[i] \u0026gt; num[j] ){ int temp = num[i] num[i] = num[j] num[j] = temp } } }   归并排序  对于一个无序的序列，将序列用递归的方式划分成左右两个序列，然后依次排序合并序列。\n#伪代码 func sorted(int num[]){ if(num.length\u0026lt;=1){ return num[0] } leftnum = xxx rightnum = xxx sorted(leftnum[]) sorted(rightnum[]) merge(leftnum,rightnum) }  "});index.add({'id':53,'href':'/notes/docs/technology/network/','title':"网络",'content':"网络 #  "});index.add({'id':54,'href':'/notes/docs/technology/network/Protocol/','title':"网络协议",'content':"网络协议 #  "});index.add({'id':55,'href':'/notes/docs/technology/other/Solution/','title':"问题集锦",'content':"问题集锦 #     时间同步相关\n   ssh连接相关\n   PGSQL相关\n  "});index.add({'id':56,'href':'/notes/docs/technology/security/Firewall/','title':"防火墙",'content':"防火墙 #  工作在主机或网络边缘，对进出的报文按事先定义的规则进行检查，并且由匹配到的规则进行处理的一组硬件或软件，甚至可能是二者的结合。\n Linux防火墙 #     iptables\n   firewalld\n  "});index.add({'id':57,'href':'/notes/docs/other/','title':"非技术相关",'content':"非技术相关 #  "});index.add({'id':58,'href':'/notes/docs/technology/network/Protocol/dns/','title':"DNS",'content':"DNS #  "});index.add({'id':59,'href':'/notes/docs/technology/cloud/DevOps/elk/','title':"ELK",'content':"ELK Stack #  ELK是一个实现可靠，安全地从任何来源，任何格式和 实时搜索，分析和可视化的工具\n 架构 #  ELK Stack主要由四个组件组成：\n  Filebeat: 从客户端收集日志并传送给Logstash\n  Logstash: 用于处理传入日志并传送给ElasticSearch\n  ElasticSearch: 存储日志并供Kibana查询\n  Kibana: 用于搜索和可视化日志的Web界面\n    使用 #     安装\n  日志解析\n   "});index.add({'id':60,'href':'/notes/docs/technology/cloud/Container/Kubernetes/','title':"Kubernetes",'content':"Kubernetes #  What #   Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。\n  Why #  部署变化 #   传统部署时代： 早期，组织在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况，结果可能导致其他应用程序的性能下降。一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展，并且组织维护许多物理服务器的成本很高。\n虚拟化部署时代： 作为解决方案，引入了虚拟化功能，它允许您在单个物理服务器的 CPU 上运行多个虚拟机（VM）。虚拟化功能允许应用程序在 VM 之间隔离，并提供安全级别，因为一个应用程序的信息不能被另一应用程序自由地访问。\n因为虚拟化可以轻松地添加或更新应用程序、降低硬件成本等等，所以虚拟化可以更好地利用物理服务器中的资源，并可以实现更好的可伸缩性。\n每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。\n容器部署时代： 容器类似于 VM，但是它们具有轻量级的隔离属性，可以在应用程序之间共享操作系统（OS）。因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。由于它们与基础架构分离，因此可以跨云和 OS 分发进行移植。\n容器因具有许多优势而变得流行起来。下面列出了容器的一些好处：\n 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚(由于镜像不可变性)，提供可靠且频繁的容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像，从而将应用程序与基础架构分离。 可观察性不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 云和操作系统分发的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。   Kubernetes能做什么 #  容器是打包和运行应用程序的好方式。在生产环境中，您需要管理运行应用程序的容器，并确保不会停机。例如，如果一个容器发生故障，则需要启动另一个容器。如果系统处理此行为，会不会更容易？\n这就是 Kubernetes 的救援方法！Kubernetes 为您提供了一个可弹性运行分布式系统的框架。Kubernetes 会满足您的扩展要求、故障转移、部署模式等。\nKubernetes 提供：\n  服务发现和负载均衡 Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果到容器的流量很大，Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。\n  存储编排 Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。\n  自动部署和回滚 您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 来为您的部署创建新容器，删除现有容器并将它们的所有资源用于新容器。\n  自动二进制打包 Kubernetes 允许您指定每个容器所需 CPU 和内存（RAM）。当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。\n  自我修复 Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。\n  密钥与配置管理 Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。您可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。\n   How #  Kubernetes架构 #    官方文档 #  "});index.add({'id':61,'href':'/notes/docs/technology/cloud/Container/Kubernetes/api/','title':"Kubernetes API",'content':"Kubernetes API #   API协议文档描述了主系统和API概念。\n API参考文档描述了API整体规范。\n 访问文档讨论了通过远程访问API的相关问题。\nKubernetes API是系统描述性配置的基础。 Kubectl 命令行工具被用于创建、更新、删除、获取API对象。\nKubernetes 通过API资源存储自己序列化状态(现在存储在 etcd)。\nKubernetes 被分成多个组件，各部分通过API相互交互。\nAPI 变更 #  根据经验，任何成功的系统都需要随着新的用例出现或现有用例发生变化的情况下，进行相应的进化与调整。因此，我们希望Kubernetes API也可以保持持续的进化和调整。同时，在较长一段时间内，我们也希望与现有客户端版本保持良好的向下兼容性。一般情况下，增加新的API资源和资源字段不会导致向下兼容性问题发生；但如果是需要删除一个已有的资源或者字段，那么必须通过 API废弃流程来进行。\n参考 API变更文档，了解兼容性变更的要素以及如何变更API的流程。\nOpenAPI 和 API Swagger 定义 #  完整的 API 详细文档使用 OpenAPI生成.\n随着 Kubernetes 1.10 版本的正式启用，Kubernetes API 服务通过 /openapi/v2 接口提供 OpenAPI 规范。 通过设置 HTTP 标头的规定了请求的结构。\n   Header Possible Values     Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for */* or not passing this header)   Accept-Encoding gzip (not passing this header is acceptable)    在1.14版本之前，区分结构的接口通过(/swagger.json, /swagger-2.0.0.json, /swagger-2.0.0.pb-v1, /swagger-2.0.0.pb-v1.gz) 提供不同格式的 OpenAPI 规范。但是这些接口已经被废弃，并且已经在 Kubernetes 1.14 中被删除。\n获取 OpenAPI 规范的例子:\n   1.10 之前 从 1.10 开始     GET /swagger.json GET /openapi/v2 Accept: application/json   GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf   GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip    Kubernetes实现了另一种基于Protobuf的序列化格式，该格式主要用于集群内通信，并在 设计方案中进行了说明，每个模式的IDL文件位于定义API对象的Go软件包中。 在 1.14 版本之前， Kubernetes apiserver 也提供 API 服务用于返回 Swagger v1.2 Kubernetes API 规范通过 /swaggerapi 接口. 但是这个接口已经被废弃，并且在 Kubernetes 1.14 中已经被移除。\nAPI 版本 #  为了使删除字段或者重构资源表示更加容易，Kubernetes 支持 多个API版本。每一个版本都在不同API路径下，例如 /api/v1 或者 /apis/extensions/v1beta1。\n我们选择在API级别进行版本化，而不是在资源或字段级别进行版本化，以确保API提供清晰，一致的系统资源和行为视图，并控制对已废止的API和/或实验性API的访问。 JSON和Protobuf序列化模式遵循架构更改的相同准则 - 下面的所有描述都同时适用于这两种格式。\n请注意，API版本控制和软件版本控制只有间接相关性。 API和发行版本建议 描述了API版本与软件版本之间的关系。\n不同的API版本名称意味着不同级别的软件稳定性和支持程度。 每个级别的标准在 API变更文档中有更详细的描述。 内容主要概括如下：\n Alpha 测试版本：  版本名称包含了 alpha (例如：v1alpha1)。 可能是有缺陷的。启用该功能可能会带来隐含的问题，默认情况是关闭的。 支持的功能可能在没有通知的情况下随时删除。 API的更改可能会带来兼容性问题，但是在后续的软件发布中不会有任何通知。 由于bugs风险的增加和缺乏长期的支持，推荐在短暂的集群测试中使用。   Beta 测试版本：  版本名称包含了 beta (例如: v2beta3)。 代码已经测试过。启用该功能被认为是安全的，功能默认已启用。 所有已支持的功能不会被删除，细节可能会发生变化。 对象的模式和/或语义可能会在后续的beta测试版或稳定版中以不兼容的方式进行更改。 发生这种情况时，我们将提供迁移到下一个版本的说明。 这可能需要删除、编辑和重新创建API对象。执行编辑操作时需要谨慎行事，这可能需要停用依赖该功能的应用程序。 建议仅用于非业务关键型用途，因为后续版本中可能存在不兼容的更改。 如果您有多个可以独立升级的集群，则可以放宽此限制。 请尝试我们的 beta 版本功能并且给出反馈！一旦他们退出 beta 测试版，我们可能不会做出更多的改变。   稳定版本：  版本名称是 vX，其中 X 是整数。 功能的稳定版本将出现在许多后续版本的发行软件中。    API 组 #  为了更容易地扩展Kubernetes API，我们实现了 API组。 API组在REST路径和序列化对象的 apiVersion 字段中指定。\n目前有几个API组正在使用中：\n 核心组（通常被称为遗留组）位于REST路径 /api/v1 并使用 apiVersion：v1。 指定的组位于REST路径 /apis/$GROUP_NAME/$VERSION，并使用 apiVersion：$GROUP_NAME/$VERSION （例如 apiVersion：batch/v1）。 在 Kubernetes API参考中可以看到支持的API组的完整列表。  社区支持使用以下两种方式来提供自定义资源对API进行扩展 自定义资源：\n  CustomResourceDefinition 适用于具有非常基本的CRUD需求的用户。 需要全套Kubernetes API语义的用户可以实现自己的apiserver， 并使用 聚合器 为客户提供无缝的服务。  启用 API 组 #  某些资源和API组默认情况下处于启用状态。 可以通过在apiserver上设置 --runtime-config 来启用或禁用它们。 --runtime-config 接受逗号分隔的值。 例如：要禁用batch/v1，请设置 --runtime-config=batch/v1=false，以启用batch/v2alpha1，请设置--runtime-config=batch/v2alpha1。 该标志接受描述apiserver的运行时配置的逗号分隔的一组键值对。\n 说明： 启用或禁用组或资源需要重新启动apiserver和控制器管理器来使得 --runtime-config 更改生效。\n 启用 extensions/v1beta1 组中资源 #  在 extensions/v1beta1 API 组中，DaemonSets，Deployments，StatefulSet, NetworkPolicies, PodSecurityPolicies 和 ReplicaSets 是默认禁用的。 例如：要启用 deployments 和 daemonsets，请设置 --runtime-config=extensions/v1beta1/deployments=true,extensions/v1beta1/daemonsets=true。\n 说明： 出于遗留原因，仅在 extensions / v1beta1 API 组中支持各个资源的启用/禁用。\n "});index.add({'id':62,'href':'/notes/docs/technology/database/NoSQL/','title':"NoSQL",'content':"NoSQL #  "});index.add({'id':63,'href':'/notes/docs/technology/program/Language/python/','title':"Python",'content':"Python #  基础语法 #    数据类型\n  流控\n  函数\n  模块\n   常用库 #   CookBook #     数据和算法\n   字符串和文本\n   框架 #     Flask\n   Scrapy\n   Django\n  "});index.add({'id':64,'href':'/notes/docs/technology/security/IDS/','title':"入侵检测",'content':"IDS #  入侵检测系统\n HIDS #  OSSEC\nNIDS #  snort\nFiresystem #  tripware\n"});index.add({'id':65,'href':'/notes/docs/technology/system/Application/','title':"应用",'content':"应用 #  "});index.add({'id':66,'href':'/notes/docs/technology/system/Basic/operatingSystem/','title':"操作系统",'content':"操作系统 #  操作系统(operating system)：是管理计算机硬件与软件资源的计算机程序，同时也是计算机系统的内核与基石。操作系统需要处理如管理与配置内存、决定系统资源供需的优先次序、控制输入与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互的操作界面。\n 结构 #    驱动程序：最底层的、直接控制和监视各类硬件的部分，它们的职责是隐藏硬件的具体细节，并向其他部分提供一个抽象的、通用的接口。\n  内核：操作系统之最内核部分，通常运行在最高特权级，负责提供基础性、结构性的功能。\n  函数库(接口库)：是一系列特殊的程序库，它们职责在于把系统所提供的基本服务包装成应用程序所能够使用的编程接口（API），是最靠近应用程序的部分。\n  外围：所谓外围，是指操作系统中除以上三类以外的所有其他部分，通常是用于提供特定高级服务的部件。\n  图示：\n  Linux系统架构： #    功能 #  操作系统位于底层硬件与用户之间，是两者沟通的桥梁。用户可以通过操作系统的用户界面，输入命令。操作系统则对命令进行解释，驱动硬件设备，实现用户要求。以现代标准而言，一个标准PC的操作系统应该提供以下的功能：\n  进程管理（Processing management）\n  内存管理（Memory management）\n  文件系统（File system）\n  网络通信（Networking）\n  安全机制（Security）\n  用户界面（User interface）\n  驱动程序（Device drivers）\n  "});index.add({'id':67,'href':'/notes/docs/technology/cloud/ServiceMesh/','title':"服务网格",'content':"服务网格 #  "});index.add({'id':68,'href':'/notes/docs/technology/program/','title':"编程",'content':"编程 #  "});index.add({'id':69,'href':'/notes/docs/technology/program/Language/','title':"编程语言",'content':"编程语言 #  "});index.add({'id':70,'href':'/notes/docs/technology/program/Advanced/design/','title':"设计模式",'content':"设计模式 #  设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。\n 分类 #  创建型模式 #  创建型模式(Creational Pattern)对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。为了使软件的结构更加清晰，外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则。\n创建型模式隐藏了类的实例的创建细节，通过隐藏对象如何被创建和组合在一起达到使整个系统独立的目的。\n   简单工厂模式\n   工厂方法模式\n   抽象工厂模式\n   建造者模式\n   原型模式\n   单例模式\n   结构型模式 #   行为型模式 #  "});index.add({'id':71,'href':'/notes/docs/technology/other/Interview/','title':"面试相关",'content':"面试相关 #  面试准备 #     技术知识点\n  非技术相关()\n  面试经历总结 #     经典问题\n   杭州面试\n  "});index.add({'id':72,'href':'/notes/docs/technology/cloud/Container/Kubernetes/object/','title':"Kubernetes 对象",'content':"Kubernetes 对象 #  在 Kubernetes 系统中，Kubernetes 对象 是持久化的实体。Kubernetes 使用这些实体去表示整个集群的状态。特别地，它们描述了如下信息：\n 哪些容器化应用在运行（以及在哪个 Node 上） 可以被应用使用的资源 关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略  Kubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。通过创建对象，本质上是在告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的，这就是 Kubernetes 集群的 期望状态（Desired State）。\n操作 Kubernetes 对象 —— 无论是创建、修改，或者删除 —— 需要使用 Kubernetes API。比如，当使用 kubectl 命令行接口时，CLI 会执行必要的 Kubernetes API 调用，也可以在程序中使用 客户端库 直接调用 Kubernetes API。\n 对象Spec与Status #  每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置：对象 spec 和 对象 status 。 spec 是必需的，它描述了对象的 期望状态（Desired State） —— 希望对象所具有的特征。 status 描述了对象的 实际状态（Actual State） ，它是由 Kubernetes 系统提供和更新的。在任何时刻，Kubernetes 控制面一直努力地管理着对象的实际状态以与期望状态相匹配。\n 描述 Kubernetes 对象 #  当创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态，以及关于对象的一些基本信息（例如名称）。 当使用 Kubernetes API 创建对象时（或者直接创建，或者基于kubectl），API 请求必须在请求体中包含 JSON 格式的信息。 大多数情况下，需要在 .yaml 文件中为 kubectl 提供这些信息。 kubectl 在发起 API 请求时，将这些信息转换成 JSON 格式。\n这里有一个 .yaml 示例文件，展示了 Kubernetes Deployment 的必需字段和对象规约：\napiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 使用类似于上面的 .yaml 文件来创建 Deployment，一种方式是使用 kubectl 命令行接口（CLI）中的 kubectl apply 命令， 将 .yaml 文件作为参数。下面是一个示例：\nkubectl apply -f https://k8s.io/examples/application/deployment.yaml --record 输出类似如下这样：\ndeployment.apps/nginx-deployment created 必需字段 #  在想要创建的 Kubernetes 对象对应的 .yaml 文件中，需要配置如下的字段：\n apiVersion - 创建该对象所使用的 Kubernetes API 的版本 kind - 想要创建的对象的类型 metadata - 帮助识别对象唯一性的数据，包括一个 name 字符串、UID 和可选的 namespace  您也需要提供对象的 spec 字段。对象 spec 的精确格式对每个 Kubernetes 对象来说是不同的，包含了特定于该对象的嵌套字段。 Kubernetes API 参考能够帮助我们找到任何我们想创建的对象的 spec 格式。\n"});index.add({'id':73,'href':'/notes/docs/technology/cloud/Microservice/','title':"微服务",'content':"微服务 #  "});index.add({'id':74,'href':'/notes/docs/technology/system/Linux/guideBook/','title':"操作指南",'content':"玩转Linux #  CPU相关 #  内存相关 #  磁盘相关 #  系统相关 #  网络相关 #  权限相关 #  文件相关 #  文本相关 #  IPMI #  RAID #    "});index.add({'id':75,'href':'/notes/docs/technology/database/','title':"数据库",'content':"数据库 #  "});index.add({'id':76,'href':'/notes/docs/technology/program/Advanced/','title':"编程进阶",'content':"编程进阶 #  "});index.add({'id':77,'href':'/notes/docs/technology/other/BookNotes/','title':"读书笔记",'content':"读书笔记 #     操作系统思考\n   CS50\n   codecademy\n  "});index.add({'id':78,'href':'/notes/docs/technology/cloud/Container/Kubernetes/network/','title':"Kubernetes 网络",'content':"Kubernetes 网络 #  集群网络系统是 Kubernetes 的核心部分，但是想要准确了解它的工作原理可是个不小的挑战。下面列出的是网络系统的的四个主要问题：\n 高度耦合的容器间通信：这个已经被 pods 和 localhost 通信解决了。 Pod 间通信：这个是本文档的重点要讲述的。 Pod 和 Service 间通信：这个已经在 services 里讲述过了。 外部和 Service 间通信：这个也已经在 services 讲述过了。  Kubernetes 的宗旨就是在应用之间共享机器。通常来说，共享机器需要两个应用之间不能使用相同的端口，但是在多个应用开发者之间去大规模地协调端口是件很困难的事情，尤其是还要让用户暴露在他们控制范围之外的集群级别的问题上。\n动态分配端口也会给系统带来很多复杂度 - 每个应用都需要设置一个端口的参数，而 API 服务器还需要知道如何将动态端口数值插入到配置模块中，服务也需要知道如何找到对方等等。与其去解决这些问题，Kubernetes 选择了其他不同的方法。\nKubernetes 网络模型 #  每一个 Pod 都有它自己的IP地址，这就意味着你不需要显式地在每个 Pod 之间创建链接，你几乎不需要处理容器端口到主机端口之间的映射。这将创建一个干净的、向后兼容的模型，在这个模型里，从端口分配、命名、服务发现、负载均衡、应用配置和迁移的角度来看，Pod 可以被视作虚拟机或者物理主机。\nKubernetes 对所有网络设施的实施，都需要满足以下的基本要求（除非有设置一些特定的网络分段策略）：\n 节点上的 pods 可以不通过 NAT 和其他任何节点上的 pods 通信 节点上的代理（比如：系统守护进程、kubelet） 可以和节点上的所有pods通信  备注：仅针对那些支持 Pods 在主机网络中运行的平台(比如：Linux) ：\n 那些运行在节点的主机网络里的 pods 可以不通过 NAT 和所有节点上的 pods 通信  这个模型不仅不复杂，而且还和 Kubernetes 的实现廉价的从虚拟机向容器迁移的初衷相兼容，如果你的工作开始是在虚拟机中运行的，你的虚拟机有一个 IP ，这样就可以和其他的虚拟机进行通信，这是基本相同的模型。\nKubernetes 的 IP 地址存在于 Pod 范围内 - 容器分享他们的网络命名空间 - 包括他们的 IP 地址。这就意味着 Pod 内的容器都可以通过 localhost 到达各个端口。这也意味着 Pod 内的容器都需要相互协调端口的使用，但是这和虚拟机中的进程似乎没有什么不同，这也被称为“一个 pod 一个 IP” 模型。\n如何实现这一点是正在使用的容器运行时的特定信息。\n也可以在 node 本身通过端口去请求你的 Pod （称之为主机端口），但这是一个很特殊的操作。转发方式如何实现也是容器运行时的细节。Pod 自己并不知道这些主机端口是否存在。\n如何实现 Kubernetes 的网络模型 #  有很多种方式可以实现这种网络模型，本文档并不是对各种实现技术的详细研究，但是希望可以作为对各种技术的详细介绍，并且成为你研究的起点。\n接下来的网络技术是按照首字母排序，并无其他任何含义。\nACI #   Cisco Application Centric Infrastructure 提供了一个集成覆盖和底层 SDN 解决方案来支持容器、虚拟机和其他裸机服务器。 ACI 为ACI提供了容器网络集成。点击 这里查看概述\nAntrea #   Antrea 项目是一个开源的，旨在成为 Kubernetes 原生的网络解决方案。它利用 Open vSwitch 作为网络数据平面。Open vSwitch 是一个高性能可编程的虚拟交换机，支持 Linux 和 Windows 平台。Open vSwitch 使 Antrea 能够以高性能和高效的方式实现 Kubernetes 的网络策略。借助 Open vSwitch 可编程的特性， Antrea 能够在 Open vSwitch 之上实现广泛的网络，安全功能和服务。\nApstra 中的 AOS #   AOS 是一个基于意图的网络系统，可以通过一个简单的集成平台创建和管理复杂的数据中心环境。AOS 利用高度可扩展的分布式设计来消除网络中断，同时将成本降至最低。\nAOS 参考设计当前支持三层连接的主机，这些主机消除了旧的两层连接的交换问题。这些三层连接的主机可以是 Linux（Debian、Ubuntu、CentOS）系统，它们直接在机架式交换机（TOR）的顶部创建 BGP 邻居关系。AOS 自动执行路由邻接，然后提供对 Kubernetes 部署中常见的路由运行状况注入（RHI）的精细控制。\nAOS 具有一组丰富的 REST API 端点，这些端点使 Kubernetes 能够根据应用程序需求快速更改网络策略。进一步的增强功能将用于网络设计的 AOS Graph 模型与工作负载供应集成在一起，从而为私有云和公共云提供端到端管理系统。\nAOS 支持使用包括 Cisco、Arista、Dell、Mellanox、HPE 在内的制造商提供的通用供应商设备，以及大量白盒系统和开放网络操作系统，例如 Microsoft SONiC、Dell OPX 和 Cumulus Linux 。\n想要更详细地了解 AOS 系统是如何工作的可以点击这里： http://www.apstra.com/products/how-it-works/\nKubernetes 的 AWS VPC CNI #   AWS VPC CNI 为 Kubernetes 集群提供了集成的 AWS 虚拟私有云（VPC）网络。该 CNI 插件提供了高吞吐量和可用性，低延迟以及最小的网络抖动。此外，用户可以使用现有的 AWS VPC 网络和安全最佳实践来构建 Kubernetes 集群。这包括使用 VPC 流日志，VPC 路由策略和安全组进行网络流量隔离的功能。\n使用该 CNI 插件，可使 Kubernetes Pods 在 Pod 中拥有与在 VPC 网络上相同的 IP 地址。CNI 将 AWS 弹性网络接口（ENI）分配给每个 Kubernetes 节点，并将每个 ENI 的辅助 IP 范围用于该节点上的 Pod 。CNI 包含用于 ENI 和 IP 地址的预分配的控件，以便加快 Pod 的启动时间，并且能够支持多达2000个节点的大型集群。\n此外，CNI可以与 用于执行网络策略的 Calico一起运行。 AWS VPC CNI项目是开源的，查看 GitHub 上的文档。\nKubernetes 的 Azure CNI #   Azure CNI 是一个 开源插件，将 Kubernetes Pods 和 Azure 虚拟网络（也称为 VNet）集成在一起，可提供与 VN 相当的网络性能。Pod 可以通过 Express Route 或者 站点到站点的 VPN 来连接到对等的 VNet ，也可以从这些网络来直接访问 Pod。Pod 可以访问受服务端点或者受保护链接的 Azure 服务，比如存储和 SQL。你可以使用 VNet 安全策略和路由来筛选 Pod 流量。该插件通过利用在 Kubernetes 节点的网络接口上预分配的辅助 IP 池将 VNet 分配给 Pod 。\nAzure CNI 可以在 Azure Kubernetes Service (AKS) 中获得。\nBig Switch Networks 的 Big Cloud Fabric #   Big Cloud Fabric 是一个基于云原生的网络架构，旨在在私有云或者本地环境中运行 Kubernetes。它使用统一的物理和虚拟 SDN，Big Cloud Fabric 解决了固有的容器网络问题，比如负载均衡、可见性、故障排除、安全策略和容器流量监控。\n在 Big Cloud Fabric 的虚拟 Pod 多租户架构的帮助下，容器编排系统（比如 Kubernetes、RedHat OpenShift、Mesosphere DC/OS 和 Docker Swarm）将于VM本地编排系统（比如 VMware、OpenStack 和 Nutanix）进行本地集成。客户将能够安全地互联任意数量的这些集群，并且在需要时启用他们之间的租户间通信。\n在最新的 Magic Quadrant 上，BCF 被 Gartner 认为是非常有远见的。而 BCF 的一条关于 Kubernetes 的本地部署（其中包括 Kubernetes、DC/OS 和在不同地理区域的多个 DC 上运行的 VMware）也在 这里被引用。\nCilium #   Cilium 是一个开源软件，用于提供并透明保护应用容器间的网络连接。Cilium 支持 L7/HTTP ，可以在 L3-L7 上通过使用与网络分离的基于身份的安全模型寻址来实施网络策略，并且可以与其他 CNI 插件结合使用。\n华为的 CNI-Genie #   CNI-Genie 是一个 CNI 插件，可以让 Kubernetes 在运行时允许不同的 Kubernetes 的网络模型的 实现同时被访问。这包括以 CNI 插件运行的任何实现，比如 Flannel、 Calico、 Romana、 Weave-net。\nCNI-Genie 还支持 将多个 IP 地址分配给 Pod，每个都来自不同的 CNI 插件。\ncni-ipvlan-vpc-k8s #   cni-ipvlan-vpc-k8s 包含了一组 CNI 和 IPAM 插件来提供一个简单的、本地主机、低延迟、高吞吐量以及通过使用 Amazon 弹性网络接口（ENI）并使用 Linux 内核的 IPv2 驱动程序以 L2 模式将 AWS 管理的 IP 绑定到 Pod 中，在 Amazon Virtual Private Cloud（VPC）环境中为 Kubernetes 兼容的网络堆栈。\n这些插件旨在直接在 VPC 中进行配置和部署，Kubelets 先启动，然后根据需要进行自我配置和扩展它们的 IP 使用率，而无需经常建议复杂的管理覆盖网络， BGP ，禁用源/目标检查，或调整 VPC 路由表以向每个主机提供每个实例子网的复杂性（每个 VPC 限制为50-100个条目）。简而言之， cni-ipvlan-vpc-k8s 大大降低了在 AWS 中大规模部署 Kubernetes 所需的网络复杂性。\nContiv #   Contiv 为各种使用情况提供了一个可配置网络（使用了 BGP 的本地 l3 ，使用 vxlan 的覆盖，经典 l2 或 Cisco-SDN/ACI）。 Contiv 是完全开源的。\nContrail / Tungsten Fabric #   Contrail 是基于 Tungsten Fabric 的，真正开放的，多云网络虚拟化和策略管理平台。Contrail 和 Tungsten Fabric 与各种编排系统集成在一起，例如 Kubernetes，OpenShift，OpenStack 和 Mesos，并为虚拟机、容器或 Pods 以及裸机工作负载提供了不同的隔离模式。\nDANM #   DANM 是一个针对在 Kubernetes 集群中运行的电信工作负载的网络解决方案。它由以下几个组件构成：\n* 能够配置具有高级功能的 IPVLAN 接口的 CNI 插件 * 一个内置的 IPAM 模块，能够管理多个、群集内的、不连续的 L3 网络，并按请求提供动态、静态或无 IP 分配方案 * CNI 元插件能够通过自己的 CNI 或通过将任务授权给其他任何流行的 CNI 解决方案（例如 SRI-OV 或 Flannel）来实现将多个网络接口连接到容器 * Kubernetes 控制器能够集中管理所有 Kubernetes 主机的 VxLAN 和 VLAN 接口 * 另一个 Kubernetes 控制器扩展了 Kubernetes 的基于服务的服务发现概念，以在 Pod 的所有网络接口上工作 通过这个工具集，DANM 可以提供多个分离的网络接口，可以为 pods 使用不同的网络后端和高级 IPAM 功能。\nFlannel #   Flannel 是一个非常简单的能够满足 Kubernetes 所需要的重叠网络。已经有许多人报告了使用 Flannel 和 Kubernetes 的成功案例。\nGoogle Compute Engine (GCE) #  对于 Google Compute Engine 的集群配置脚本， advanced routing 用于为每个虚机分配一个子网（默认是 /24 - 254个 IP），绑定到该子网的任何流量都将通过 GCE 网络结构直接路由到虚机。这是除了分配给虚机的“主要” IP 地址之外的一个补充，该 IP 地址经过 NAT 转换以用于访问外网。linux网桥（称为“cbr0”）被配置为存在于该子网中，并被传递到 docker 的 \u0026ndash;bridge 参数上。\nDocker 会以这样的参数启动：\nDOCKER_OPTS=\u0026#34;--bridge=cbr0 --iptables=false --ip-masq=false\u0026#34; 这个网桥是由 Kubelet（由 \u0026ndash;network-plugin=kubenet 参数控制）根据节点的 .spec.podCIDR 参数创建的。\nDocker 将会从 cbr-cidr 块分配 IP 。容器之间可以通过 cbr0 网桥相互访问，也可以访问节点。这些 IP 都可以在 GCE 的网络中被路由。\n而 GCE 本身并不知道这些 IP，所以不会对访问外网的流量进行 NAT，为了实现此目的，使用了 iptables 规则来伪装（又称为 SNAT，使数据包看起来好像是来自“节点”本身），将通信绑定到 GCE 项目网络（10.0.0.0/8）之外的 IP。\niptables -t nat -A POSTROUTING ! -d 10.0.0.0/8 -o eth0 -j MASQUERADE 最后，在内核中启用了 IP 转发（因此内核将处理桥接容器的数据包）：\nsysctl net.ipv4.ip_forward=1 所有这些的结果是所有 Pods 都可以互相访问，并且可以将流量发送到互联网。\nJaguar #   Jaguar 是一个基于 OpenDaylight 的 Kubernetes 网络开源解决方案。Jaguar 使用 vxlan 提供覆盖网络，而 Jaguar CNIPlugin 为每个 Pod 提供一个 IP 地址。\nk-vswitch #   k-vswitch 是一个基于 Open vSwitch 的简易 Kubernetes 网络插件。它利用 Open vSwitch 中现有的功能来提供强大的网络插件，该插件易于操作，高效且安全。\nKnitter #   Knitter 是一个支持 Kubernetes 中实现多个网络系统的解决方案。它提供了租户管理和网络管理的功能。除了多个网络平面外，Knitter 还包括一组端到端的 NFV 容器网络解决方案，例如为应用程序保留 IP 地址，IP 地址迁移等。\nKube-OVN #   Kube-OVN 是一个基于 OVN 的用于企业的 Kubernetes 网络架构。借助于 OVN/OVS ，它提供了一些高级覆盖网络功能，例如子网、QoS、静态 IP 分配、流量镜像、网关、基于开放流的网络策略和服务代理。\nKube-router #   Kube-router 是 Kubernetes 的专用网络解决方案，旨在提供高性能和易操作性。 Kube-router 提供了一个基于 Linux LVS/IPVS 的服务代理，一个基于 Linux 内核转发的无覆盖 Pod-to-Pod 网络解决方案，和基于 iptables/ipset 的网络策略执行器。\nL2 networks and linux bridging #  如果你具有一个“哑”的L2网络，例如“裸机”环境中的简单交换机，则应该能够执行与上述 GCE 设置类似的操作。请注意，这些说明仅是非常简单的尝试过-似乎可行，但尚未经过全面测试。如果您使用此技术并完善了流程，请告诉我们。\n根据 Lars Kellogg-Stedman 的这份非常不错的“Linux 网桥设备” 使用说明来进行操作。\nMultus (a Multi Network plugin) #   Multus 是一个多 CNI 插件，使用 Kubernetes 中基于 CRD 的网络对象来支持实现 Kubernetes 多网络系统。\nMultus 支持所有[参考插件]（https://github.com/containernetworking/plugins）（比如： Flannel、 DHCP、 Macvlan ），来实现 CNI 规范和第三方插件（比如： Calico、 Weave、 Cilium、 Contiv）。除此之外， Multus 还支持 SRIOV、 DPDK、 OVS-DPDK \u0026amp; VPP 的工作负载，以及 Kubernetes 中基于云的本机应用程序和基于 NFV 的应用程序。\nNSX-T #   VMware NSX-T 是一个网络虚拟化的安全平台。 NSX-T 可以为多云及多系统管理程序环境提供网络虚拟化，并专注于具有异构端点和技术堆栈的新兴应用程序框架和体系结构。除了 vSphere 管理程序之外，这些环境还包括其他虚拟机管理程序，例如 KVM，容器和裸机。\n NSX-T Container Plug-in (NCP) 提供了 NSX-T 与容器协调器（例如 Kubernetes）之间的结合， 以及 NSX-T 与基于容器的 CaaS/PaaS 平台（例如 Pivotal Container Service（PKS） 和 OpenShift ）之间的集成。\nNuage Networks VCS (Virtualized Cloud Services) #   Nuage 提供了一个高度可扩展的基于策略的软件定义网络（SDN）平台，Nuage 使用开源的 Open vSwitch 作为数据平面，以及基于开放标准构建具有丰富功能的 SDN 控制器。\nNuage 平台使用覆盖层在 Kubernetes Pod 和非 Kubernetes 环境（VM 和裸机服务器）之间提供基于策略的无缝联网。Nuage 的策略抽象模型在设计时就考虑到了应用程序，并且可以轻松声明应用程序的细粒度策略。该平台的实时分析引擎可为 Kubernetes 应用程序提供可见性和安全性监控。\nOpenVSwitch #   OpenVSwitch 是一个较为成熟的解决方案，但同时也增加了构建覆盖网络的复杂性，这也得到了几个网络系统的“大商店”的拥护。\nOVN (开放式虚拟网络) #  OVN 是一个由 Open vSwitch 社区开发的开源的网络虚拟化解决方案。它允许创建逻辑交换器，逻辑路由，状态 ACL，负载均衡等等来建立不同的虚拟网络拓扑。该项目有一个特定的Kubernetes插件和文档 ovn-kubernetes。\nProject Calico #   Project Calico 是一个开源的容器网络提供者和网络策略引擎。\nCalico 提供了高度可扩展的网络和网络解决方案，使用基于与 Internet 相同的 IP 网络原理来连接 Kubernetes Pod，适用于 Linux （开放源代码）和 Windows（专有-可从 Tigera 获得。可以无需封装或覆盖即可部署 Calico，以提供高性能，高可扩的数据中心网络。Calico 还通过其分布式防火墙为 Kubernetes Pod 提供了基于意图的细粒度网络安全策略。\nCalico 还可以和其他的网络解决方案（比如 Flannel、 canal 或本机 GCE、AWS、Azure 等）一起以策略实施模式运行。\nRomana #   Romana 是一个开源网络和安全自动化解决方案。它可以让你在没有覆盖网络的情况下部署 Kubernetes。Romana 支持 Kubernetes 网络策略，来提供跨网络命名空间的隔离。\nWeaveworks 的 Weave Net #   Weave Net 是 Kubernetes 及其托管应用程序的弹性和易于使用的网络系统。Weave Net 可以作为 CNI plug-in 运行或者独立运行。在这两种运行方式里，都不需要任何配置或额外的代码即可运行，并且在两种情况下，网络都为每个 Pod 提供一个 IP 地址-这是 Kubernetes 的标准配置。\n接下来 #  网络模型的早期设计、运行原理以及未来的一些计划，都在 networking design document 文档里进行了更详细的描述。\n"});index.add({'id':79,'href':'/notes/docs/technology/cloud/API/','title':"声明式API",'content':"声明式API #  "});index.add({'id':80,'href':'/notes/docs/technology/other/Translate/','title':"技术文章翻译",'content':"翻译技术文章 #  "});index.add({'id':81,'href':'/notes/docs/technology/architecture/','title':"架构",'content':"架构 #  "});index.add({'id':82,'href':'/notes/docs/technology/cloud/DevOps/','title':"DevOps",'content':"DevOps #  What #  wiki\n DevOps（开发 Development 与运维 Operations 的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。\n 亚马逊\n DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes. This speed enables organizations to better serve their customers and compete more effectively in the market.\n 微软\n DevOps is the union of people, process, and products to enable continuous delivery of value to our end users. The contraction of “Dev” and “Ops” refers to replacing siloed Development and Operations to create multidisciplinary teams that now work together with shared and efficient practices and tools. Essential DevOps practices include agile planning, continuous integration, continuous delivery, and monitoring of applications.\n 红帽\n DevOps describes approaches to speeding up the processes by which an idea (like a new software feature, a request for enhancement, or a bug fix) goes from development to deployment in a production environment where it can provide value to the user. These approaches require that development teams and operations teams communicate frequently and approach their work with empathy for their teammates. Scalability and flexible provisioning are also necessary. With DevOps, those that need power the most, get it—through self service and automation. Developers, usually coding in a standard development environment, work closely with IT operations to speed software builds, tests, and releases—without sacrificing reliability.\n    How #  DevOps的首要目标是创建一个支持持续集成和持续交付的开发环境。\n实际上，DevOps的四个关键原则将其注入到框架中：\n Continuous integration (持续集成) Continuous delivery (持续交付) Continuous testing(持续测试) Continuous monitoring(持续监控)   "});index.add({'id':83,'href':'/notes/docs/technology/cloud/Container/Kubernetes/security/','title':"Kubernetes 安全",'content':"Kubernetes 安全 #  "});index.add({'id':84,'href':'/notes/docs/technology/cloud/','title':"云原生",'content':"云原生 #  What #  CNCF定义 #   Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.\nThese techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.\n Pivotal定义 #   Cloud native is an approach to building and running applications that exploits the advantages of the cloud computing delivery model. Cloud native is about how applications are created and deployed, not where\nOrganizations require a platform for building and operating cloud native applications and services that automates and integrates the concepts of DevOps, continuous delivery, microservices, and containers\n  阿里云原生课堂 #  定义 #   云原生是一条使用户能低心智负担的、敏捷的、以可扩展、可复制的方式， 最大化的利用”云“的能力、发挥”云“的价值的最佳路径\n  发展历程 #    技术范畴 #  云应用定义与开发流程 #   应用定义与镜像制作 CI/CD 消息和 Streaming 数据库  云应用编排与管理 #   应用编排与调度 服务发现与治理 远程调用 API 网关 Service Mesh  监控与可观测性 #   监控 日志 Tracing 混沌工程  云原生底层技术 #   容器运行时 云原生存储技术 云原生网络技术  云原生工具集 #   流程自动化与配置管理 容器镜像仓库 云原生安全技术 云端密码管理  Serverless #   FaaS BaaS Serverless 计费   理论基础 #    不可变基础设施\n目前实现：容器镜像\n  云应用编排理论\n目前实现：容器设计模式\n   关键技术点 #   "});index.add({'id':85,'href':'/notes/docs/technology/cloud/Container/Kubernetes/install/','title':"Kubernetes 安装配置",'content':"安装 #  kubeadm快速部署kubernetes #  环境搭建 #    环境准备\n#放开防火墙限制 systemctl stop firewalld systemctl disable firewalld #更改内核参数 echo 1 \u0026gt; /proc/sys/net/bridge/bridge-nf-call-ip6tables echo 1 \u0026gt; /proc/sys/net/bridge/bridge-nf-call-iptables #禁用SELINUX setenforce 0    Docker安装\n参考 Docker安装\n#开启iptables filter表中FOWARD链(Docker1.3开始已被禁用) iptables -P FORWARD ACCEPT #/etc/docker/daemon.json增加配置 { \u0026quot;exec-opts\u0026quot;: [\u0026quot;native.cgroupdriver=systemd\u0026quot;] } #重启Docker systemctl restart docker.service    Kubeadm安装\n#添加repo配置 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF #安装kubeadm,kubelet,kubectl yum install -y kubelet kubeadm kubectl systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet     Master node 初始化 #    init\nkubeadm init --pod-network-cidr=10.244.0.0/16 #记录join值 kubeadm join --token \u0026lt;token\u0026gt; \u0026lt;master-ip\u0026gt;:\u0026lt;master-port\u0026gt; #配置KUBECONFIG环境参数 export KUBECONFIG=/etc/kubernetes/admin.conf    Pod Network安装\nmkdir -p ~/k8s/ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.yml wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl create -f kube-flannel-rbac.yml kubectl apply -f kube-flannel.yml     Node 加入 Master #  kubeadm join --token \u0026lt;token\u0026gt; \u0026lt;master-ip\u0026gt;:\u0026lt;master-port\u0026gt;   kubectl操作 #  #获取组件状态 kubectl get cs #查看pod状态 kubectl get pod --all-namespaces -o wide #部署应用   手动部署kubernetes高可用集群 #  环境准备 #  软件 #    etcd\n  docker\n  kubernetes\n  kubelet\n  kube-proxy\n  kube-apiserver\n  kube-controller-manager\n  kube-scheduler\n     软件准备 #     Docker安装\n  软件下载\nwget https://storage.googleapis.com/kubernetes-release/release/v1.6.9/kubernetes.tar.gz tar -zxvf kubernetes.tar.gz ./kubernetes/cluster/get-kube-binaries.sh wget https://github.com/coreos/etcd/releases/download/v3.2.6/etcd-v3.2.6-linux-amd64.tar.gz     etcd高可用集群搭建 #  安装cfssl #  go get -u github.com/cloudflare/cfssl/cmd/...  将在$GOPATH/bin下安装cfssl, cfssjosn, mkbundle等工具\nCA证书和私钥 #  创建ca-config.json:\n{ \u0026quot;signing\u0026quot;: { \u0026quot;default\u0026quot;: { \u0026quot;expiry\u0026quot;: \u0026quot;87600h\u0026quot; }, \u0026quot;profiles\u0026quot;: { \u0026quot;frognew\u0026quot;: { \u0026quot;usages\u0026quot;: [ \u0026quot;signing\u0026quot;, \u0026quot;key encipherment\u0026quot;, \u0026quot;server auth\u0026quot;, \u0026quot;client auth\u0026quot; ], \u0026quot;expiry\u0026quot;: \u0026quot;87600h\u0026quot; } } } }  创建CA证书签名请求配置ca-csr.json:\n{ \u0026quot;CN\u0026quot;: \u0026quot;frognew\u0026quot;, \u0026quot;key\u0026quot;: { \u0026quot;algo\u0026quot;: \u0026quot;rsa\u0026quot;, \u0026quot;size\u0026quot;: 2048 }, \u0026quot;names\u0026quot;: [ { \u0026quot;C\u0026quot;: \u0026quot;CN\u0026quot;, \u0026quot;ST\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;L\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;O\u0026quot;: \u0026quot;frognew\u0026quot;, \u0026quot;OU\u0026quot;: \u0026quot;cloudnative\u0026quot; } ] }  使用cfssl生成CA证书和私钥：\ncfssl gencert -initca ca-csr.json | cfssljson -bare ca  ca-key.pem和ca.pem需要保存，后边会用到\netcd证书和私钥 #  创建etcd证书签名请求配置etcd-csr.json:\n{ \u0026quot;CN\u0026quot;: \u0026quot;cctest\u0026quot;, \u0026quot;hosts\u0026quot;: [ \u0026quot;127.0.0.1\u0026quot;, \u0026quot;192.168.19.11\u0026quot;, \u0026quot;192.168.19.12\u0026quot;, \u0026quot;192.168.19.13\u0026quot;, \u0026quot;node1\u0026quot;, \u0026quot;node2\u0026quot;, \u0026quot;node3\u0026quot; ], \u0026quot;key\u0026quot;: { \u0026quot;algo\u0026quot;: \u0026quot;rsa\u0026quot;, \u0026quot;size\u0026quot;: 2048 }, \u0026quot;names\u0026quot;: [ { \u0026quot;C\u0026quot;: \u0026quot;CN\u0026quot;, \u0026quot;ST\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;L\u0026quot;: \u0026quot;BeiJing\u0026quot;, \u0026quot;O\u0026quot;: \u0026quot;cctest\u0026quot;, \u0026quot;OU\u0026quot;: \u0026quot;cloudnative\u0026quot; } ] }  生成etcd的证书和私钥\ncfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=frognew etcd-csr.json | cfssljson -bare etcd  etcd安装 #  将ca.pem, etcd-key.pem, etcd.pem拷贝到各节点的/etc/etcd/ssl目录中\ncp ca.pem /etc/etcd/ssl cp etcd*.pem /etc/etcd/ssl  解压缩etcd-v3.2.6-linux-amd64.tar.gz，拷贝可执行文件\ntar -zxvf etcd-v3.2.6-linux-amd64.tar.gz cp etcd-v3.2.6-linux-amd64/etcd* /usr/bin/  创建etcd的systemd unit文件\nexport ETCD_NAME=node1 export INTERNAL_IP=192.168.19.11 cat \u0026gt; /usr/lib/systemd/system/etcd.service \u0026lt;\u0026lt;EOF [Unit] Description=etcd server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify WorkingDirectory=/var/lib/etcd/ EnvironmentFile=-/etc/etcd/etcd.conf ExecStart=/usr/bin/etcd \\ --name ${ETCD_NAME} \\ --cert-file=/etc/etcd/ssl/etcd.pem \\ --key-file=/etc/etcd/ssl/etcd-key.pem \\ --peer-cert-file=/etc/etcd/ssl/etcd.pem \\ --peer-key-file=/etc/etcd/ssl/etcd-key.pem \\ --trusted-ca-file=/etc/etcd/ssl/ca.pem \\ --peer-trusted-ca-file=/etc/etcd/ssl/ca.pem \\ --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\ --listen-peer-urls https://${INTERNAL_IP}:2380 \\ --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\ --advertise-client-urls https://${INTERNAL_IP}:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster node1=https://192.168.19.11:2380,node2=https://192.168.19.12:2380,node3=https://192.168.19.13:2380 \\ --initial-cluster-state new \\ --data-dir=/var/lib/etcd Restart=on-failure RestartSec=5 LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF  启动etcd #  各节点启动etcd服务\nsystemctl daemon-reload systemctl enable etcd systemctl start etcd systemctl status etcd  集群检查：\netcdctl \\ --ca-file=/etc/etcd/ssl/ca.pem \\ --cert-file=/etc/etcd/ssl/etcd.pem \\ --key-file=/etc/etcd/ssl/etcd-key.pem \\ --endpoints=https://node1:2379,https://node2:2379,https://node3:2379 \\ cluster-health   Kubernetes Master 集群搭建 #  "});index.add({'id':86,'href':'/notes/docs/technology/bigdata/','title':"大数据",'content':"大数据 #  "});index.add({'id':87,'href':'/notes/docs/technology/cloud/Container/Kubernetes/use/','title':"Kubernetes 使用",'content':"Kubernetes 使用 #  "});index.add({'id':88,'href':'/notes/docs/technology/security/','title':"安全",'content':"安全 #  "});index.add({'id':89,'href':'/notes/docs/technology/tool/','title':"工具",'content':"工具 #  "});index.add({'id':90,'href':'/notes/docs/technology/network/Protocol/http/tls/','title':"SSL协议",'content':"SSL协议 #  SSL是一种安全协议，目的是为互联网通信提供安全及数据完整性保障。\n   SSL介绍\n   工作机制\n   工具使用\n   SSL介绍 一个简单的工作流程: #    浏览器请求一个安全页面(https://)。\n  Web服务器返回公钥及其证书。\n  浏览器检查该证书是否由可信任的机构颁发，并且是与站点相关的有效证书。\n  浏览器使用公钥加密随即对称加密密钥，和通过随即加密密钥加密的http数据一同发送给Web服务器。\n  Web服务器通过私钥解密随即对称加密密钥，并使用它解密http数据。\n  Web服务器返回通过随即对称加密密钥加密的请求html文本和http数据。\n  浏览器通过随即对称加密密钥解密html文本和http数据并展示信息。\n   公私钥: #  非对称加密，使用私钥/公钥对加密，数据可以被一个密钥加密，但只能被另一个密钥对解密。该密钥对自己保留一个私钥，并将公钥分配给每个人。\nMessage --\u0026gt; [Public Key] --\u0026gt; Encrypted Message --\u0026gt; [Private Key] --\u0026gt; Message   证书: #  证书加载在浏览器或者其他客户端党当中，证书包含了证书所有者的信息。一个例子:\nCertificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: md5WithRSAEncryption Issuer: C=FJ, ST=Fiji, L=Suva, O=SOPAC, OU=ICT, CN=SOPAC Root CA/Email=administrator@sopac.org Validity Not Before: Nov 20 05:47:44 2001 GMT Not After : Nov 20 05:47:44 2002 GMT Subject: C=FJ, ST=Fiji, L=Suva, O=SOPAC, OU=ICT, CN=www.sopac.org/Email=administrator@sopac.org Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (1024 bit) Modulus (1024 bit): 00:ba:54:2c:ab:88:74:aa:6b:35:a5:a9:c1:d0:5a: 9b:fb:6b:b5:71:bc:ef:d3:ab:15:cc:5b:75:73:36: b8:01:d1:59:3f:c1:88:c0:33:91:04:f1:bf:1a:b4: 7a:c8:39:c2:89:1f:87:0f:91:19:81:09:46:0c:86: 08:d8:75:c4:6f:5a:98:4a:f9:f8:f7:38:24:fc:bd: 94:24:37:ab:f1:1c:d8:91:ee:fb:1b:9f:88:ba:25: da:f6:21:7f:04:32:35:17:3d:36:1c:fb:b7:32:9e: 42:af:77:b6:25:1c:59:69:af:be:00:a1:f8:b0:1a: 6c:14:e2:ae:62:e7:6b:30:e9 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: FE:04:46:ED:A0:15:BE:C1:4B:59:03:F8:2D:0D:ED:2A:E0:ED:F9:2F X509v3 Authority Key Identifier: keyid:E6:12:7C:3D:A1:02:E5:BA:1F:DA:9E:37:BE:E3:45:3E:9B:AE:E5:A6 DirName:/C=FJ/ST=Fiji/L=Suva/O=SOPAC/OU=ICT/CN=SOPAC Root CA/Email=administrator@sopac.org serial:00 Signature Algorithm: md5WithRSAEncryption 34:8d:fb:65:0b:85:5b:e2:44:09:f0:55:31:3b:29:2b:f4:fd: aa:5f:db:b8:11:1a:c6:ab:33:67:59:c1:04:de:34:df:08:57: 2e:c6:60:dc:f7:d4:e2:f1:73:97:57:23:50:02:63:fc:78:96: 34:b3:ca:c4:1b:c5:4c:c8:16:69:bb:9c:4a:7e:00:19:48:62: e2:51:ab:3a:fa:fd:88:cd:e0:9d:ef:67:50:da:fe:4b:13:c5: 0c:8c:fc:ad:6e:b5:ee:40:e3:fd:34:10:9f:ad:34:bd:db:06: ed:09:3d:f2:a6:81:22:63:16:dc:ae:33:0c:70:fd:0a:6c:af: bc:5a -----BEGIN CERTIFICATE----- MIIDoTCCAwqgAwIBAgIBATANBgkqhkiG9w0BAQQFADCBiTELMAkGA1UEBhMCRkox DTALBgNVBAgTBEZpamkxDTALBgNVBAcTBFN1dmExDjAMBgNVBAoTBVNPUEFDMQww CgYDVQQLEwNJQ1QxFjAUBgNVBAMTDVNPUEFDIFJvb3QgQ0ExJjAkBgkqhkiG9w0B CQEWF2FkbWluaXN0cmF0b3JAc29wYWMub3JnMB4XDTAxMTEyMDA1NDc0NFoXDTAy MTEyMDA1NDc0NFowgYkxCzAJBgNVBAYTAkZKMQ0wCwYDVQQIEwRGaWppMQ0wCwYD VQQHEwRTdXZhMQ4wDAYDVQQKEwVTT1BBQzEMMAoGA1UECxMDSUNUMRYwFAYDVQQD Ew13d3cuc29wYWMub3JnMSYwJAYJKoZIhvcNAQkBFhdhZG1pbmlzdHJhdG9yQHNv cGFjLm9yZzCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAulQsq4h0qms1panB 0Fqb+2u1cbzv06sVzFt1cza4AdFZP8GIwDORBPG/GrR6yDnCiR+HD5EZgQlGDIYI 2HXEb1qYSvn49zgk/L2UJDer8RzYke77G5+IuiXa9iF/BDI1Fz02HPu3Mp5Cr3e2 JRxZaa++AKH4sBpsFOKuYudrMOkCAwEAAaOCARUwggERMAkGA1UdEwQCMAAwLAYJ YIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVkIENlcnRpZmljYXRlMB0GA1Ud DgQWBBT+BEbtoBW+wUtZA/gtDe0q4O35LzCBtgYDVR0jBIGuMIGrgBTmEnw9oQLl uh/anje+40U+m67lpqGBj6SBjDCBiTELMAkGA1UEBhMCRkoxDTALBgNVBAgTBEZp amkxDTALBgNVBAcTBFN1dmExDjAMBgNVBAoTBVNPUEFDMQwwCgYDVQQLEwNJQ1Qx FjAUBgNVBAMTDVNPUEFDIFJvb3QgQ0ExJjAkBgkqhkiG9w0BCQEWF2FkbWluaXN0 cmF0b3JAc29wYWMub3JnggEAMA0GCSqGSIb3DQEBBAUAA4GBADSN+2ULhVviRAnw VTE7KSv0/apf27gRGsarM2dZwQTeNN8IVy7GYNz31OLxc5dXI1ACY/x4ljSzysQb xUzIFmm7nEp+ABlIYuJRqzr6/YjN4J3vZ1Da/ksTxQyM/K1ute5A4/00EJ+tNL3b Bu0JPfKmgSJjFtyuMwxw/Qpsr7xa -----END CERTIFICATE-----  该证书包含对发行人的引用，该证书的所有者的公钥，该证书的有效期和证书的签名，以确保该证书没有被篡改。\n 对称密钥: #  对称加密，使用相同密钥进行加密和解密。对称加密在处理速度上比非对称加密快，但安全性低。综合考虑，使用公私钥加解密对称密钥，在每次事务都选择不同的对称密钥是更安全和高效的方案。\nSymetric Key --\u0026gt; [Public Key] --\u0026gt; Encrypted Symetric Key --\u0026gt; [Private Key] --\u0026gt; Symetric Key   加密算法: #  加密算法有对称和非对称方法，使用不同长度的密钥。\n Hash #  哈希是由消息中的哈希函数给出的数字。 这是一个单向函数，这意味着不可能得到原始消息知道哈希。 然而，即使消息中最轻微的修改，哈希也会发生巨大变化。 因此，在保持其原始散列的同时修改消息是非常困难的。它也被成为消息摘要。哈希函数用于密码机制，用于证明应用程序是原始的（MD5总和），确保任何消息未被篡改。\n 签名 #  签署信息意味着验证您已经确定了邮件的真实性。要签署消息，需要创建其Hash，然后使用私钥加密Hash，然后添加加密Hash和签名的证书与消息。 收件人将重新创建消息hash，使用签名的证书中存储的公钥解密加密Hash，检查两个Hash是否相等，最后检查证书。\n PassPhrase #  PassPhrase就像一个密码，除了它更长。\n PKI #  Public Key Infrastructure（PKI）是软件管理系统和数据库系统，允许签署证书，保留撤销证书清单，分发公钥。\n CSRs #  要从CA获取SSL证书，就要生成一个certificate signing request (CSR)。CSR由密钥对的公钥和一些附加信息组成。这两个组件在签名时都会插入证书。\n生成CSR需要填入的信息：\n--- Country Name (2 letter code) [AU]:US State or Province Name (full name) [Some-State]:New York Locality Name (eg, city) []:Brooklyn Organization Name (eg, company) [Internet Widgits Pty Ltd]:Example Brooklyn Company Organizational Unit Name (eg, section) []:Technology Division Common Name (e.g. server FQDN or YOUR name) []:examplebrooklyn.com Email Address []:   工作机制 TLS协议由两部分组成，包括（TLS Record Layer,TLS handshake protocol）\n  Record Layer:\n为每条信息提供一个header和在尾部生成一个从Message Authentication Code (MAC) 得到的hash值，其中header由5 bytes组成，分别是协议说明(1bytes),协议版本(2bytes)和长度(2bytes)，跟在header后面的协议信息长度不得超过16384bytes。\n  Handshake Protocol:\nTLS握手:\n    OpenSSl工具 OpenSSL是一个通用的命令行工具，可用于与公钥基础设施（PKI）和HTTPS（TLS over HTTP）相关的各种任务。\n生成CSRs #  #生成一个私钥和一个CSR openssl req -newkey rsa:2048 -nodes -keyout domain.key -out domain.csr #使用已存在的私钥生成CSR openssl req -key domain.key -new -out domain.csr   生成SSL证书 #  #生成一个私钥和自签名证书 openssl req -newkey ras:2048 -keyout domain.key -x509 -days 365 -out domain.crt #使用已存在的私钥生成自签名证书 openssl req -key domain.key -x509 -days 365 -out domain.crt #使用已存在的私钥和CSR生成自签名证书 openssl x509 -signkey domain.key -in domain.csr -req -days 365 -out domain.crt   查看证书 #  #查看CSR信息 openssl req -text -noout -verify -in domain.csr #查看证书信息 openssl x509 -text -noout -in domain.crt #验证证书是呦CA签署的 openssl verify -verbose -CAFile ca.crt domain.crt   生成私钥 #  #创建私钥文件 openssl genrsa -des3 -out domain.key 2048 #查看私钥信息 openssl rsa -check -in domain.key   证书格式转换 #  #PEM转DER openssl x509 -in domain.crt -outform der -out domain.der #DER转PEM openssl x509 -inform der -in domain.der -out domain.crt #PEM转PKCS7 openssl crl2pkcs7 -nocrl -certfile domain.crt -certfile ca-chain.crt -out domain.p7b #PKCS7转PEM openssl pkcs7 -in domain.p7b -print_certs -out domain.crt #PEM转PKCS12 openssl pkcs12 -inkey domain.key -in domain.crt -export -out domain.pfx #PKCS12转PEM openssl pkcs12 -in domain.pfx -nodes -out domain.combined.crt "});index.add({'id':91,'href':'/notes/docs/technology/other/','title':"其他",'content':"其他 #  "});index.add({'id':92,'href':'/notes/docs/technology/bigdata/Application/kafka/architecture/','title':"Architecture",'content':"kafka架构 #  "});index.add({'id':93,'href':'/notes/docs/technology/bigdata/Application/kafka/deploy/','title':"Deploy",'content':""});index.add({'id':94,'href':'/notes/docs/technology/bigdata/Application/kafka/optimization/','title':"Optimization",'content':""});index.add({'id':95,'href':'/notes/docs/technology/bigdata/Application/zookeeper/architecture/','title':"Architecture",'content':"Zookeeper架构 #  "});index.add({'id':96,'href':'/notes/docs/technology/bigdata/Application/zookeeper/deploy/','title':"Deploy",'content':"Zookeeper部署 #  单机环境搭建 #    下载安装包\n wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz tar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 zookeeper    修改配置文件\n #vim zookeeper/conf/zoo.cfg tickTime=2000 initLimit=5 syncLimit=2 dataDir=/cache1/zookeeper/data #数据目录 clientPort=2181 #服务端口    配置日志保存目录\n #修改zookeeper/conf/log4j.properties文件 zookeeper.root.logger=INFO, ROLLINGFILE zookeeper.log.dir=/cache1/zookeeper/logs zookeeper.log.file=zookeeper.log #修改zookeeper/bin/zkEnv.sh if [ \u0026quot;x${ZOO_LOG_DIR}\u0026quot; = \u0026quot;x\u0026quot; ] then ZOO_LOG_DIR=\u0026quot;/cache1/zookeeper/logs/\u0026quot; fi if [ \u0026quot;x${ZOO_LOG4J_PROP}\u0026quot; = \u0026quot;x\u0026quot; ] then ZOO_LOG4J_PROP=\u0026quot;INFO,ROLLINGFILE\u0026quot; fi    启动服务\n cd zookeeper/bin \u0026amp;\u0026amp; ./zkServer.sh start     集群环境搭建 #    机器准备\n #3台设备 192.168.1.21 192.168.1.22 192.168.1.33    系统环境准备\n #/etc/hosts文件增加以下内容 192.168.1.21 zoo1 192.168.1.22 zoo2 192.168.1.33 zoo3    下载安装包\n wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz tar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 zookeeper    修改配置文件\n #vim zookeeper/conf/zoo.cfg tickTime=2000 initLimit=5 syncLimit=2 dataDir=/cache1/zookeeper/data #数据目录 clientPort=2181 #服务端口 server.1=zoo1:2888:3888 #server.x的x与myid文件的值匹配 server.2=zoo2:2888:3888 #zoo1表示hostname server.3=zoo3:2888:3888 #2888是followers用来连接leader，3888用于leader的选举    各机器创建myid文件\n #zoo1 echo 1 \u0026gt; /cache1/zookeeper/data/myid #zoo2 echo 2 \u0026gt; /cache1/zookeeper/data/myid #zoo3 echo 3 \u0026gt; /cache1/zookeeper/data/myid    各机器启动服务\n cd zookeeper/bin \u0026amp;\u0026amp; ./zkServer.sh start    "});index.add({'id':97,'href':'/notes/docs/technology/bigdata/Application/zookeeper/optimization/','title':"Optimization",'content':"Zookeeper优化 #  "});index.add({'id':98,'href':'/notes/docs/technology/cloud/DevOps/elk/elkinstall/','title':"Elkinstall",'content':"ELK安装 #  环境准备 #    CentOS 7\n  Java 8\n   ELK安装 #    配置ELK的repo文件\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch #vim /etc/yum.repo.d/elk.repo [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md    ElasticSearch\n#install yum install elasticsearch /bin/systemctl daemon-reload /bin/systemctl enable elasticsearch.service systemctl start elasticsearch.service #Test curl http://localhost:9200/    Kibana\n#install yum install kibana /bin/systemctl daemon-reload /bin/systemctl enable kibana.service #vim /etc/kibana/kibana.yml server.host: 0.0.0.0    LogStash\n#install yum install logstash /bin/systemctl start logstash.service    Filebeat\n#install yum -y install filebeat     配置 #    配置hosts\n#vim /etc/hosts 192.168.19.26 elk.cctest.com    生成SSL证书\ncd /etc/pki/tls openssl req -subj '/CN=elk.cctest.com/' -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt    logstash配置\n#vim /etc/logstash/conf.d/02-beats-input.conf input { beats { port =\u0026gt; 5044 ssl =\u0026gt; true ssl_certificate =\u0026gt; \u0026quot;/etc/pki/tls/certs/logstash-forwarder.crt\u0026quot; ssl_key =\u0026gt; \u0026quot;/etc/pki/tls/private/logstash-forwarder.key\u0026quot; } } #vim /etc/logstash/conf.d/10-log-filter.conf filter { grok { match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{COMBINEDAPACHELOG}\u0026quot; } } geoip { source =\u0026gt; \u0026quot;clientip\u0026quot; } } #vim /etc/logstash/conf.d/30-elasticsearch-output.conf output { elasticsearch { hosts =\u0026gt; [\u0026quot;localhost:9200\u0026quot;] } } #重启logstash /bin/systemctl restart logstash.service    filebeat配置\n#vim /etc/filebeat/filebeat.yml filebeat.prospectors: - type: log enabled: true paths: - /var/log/messages* filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 3 output.logstash: hosts: [\u0026quot;elk.cctest.com:5044\u0026quot;] ssl.certificate_authorities: [\u0026quot;/etc/pki/tls/certs/logstash-forwarder.crt\u0026quot;] # systemctl start filebeat    浏览器打开kibana\nhttp://localhost:5601/     "});index.add({'id':99,'href':'/notes/docs/technology/database/SQL/mysql/cluster/','title':"Cluster",'content':"MySQL Cluster #  Master-Slave #  Master配置 #  /etc/my.cnf 增加配置\n[mysqld] server-id=1 log-bin=/cache1/mysql/log/mysql-bin.log #忽略系统库 binlog-ignore-db=mysql binlog-ignore-db=information_schema binlog-ignore-db=performance_schema  Replication 帐号创建\nmysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY 'slave@2017';  导出数据到从库\nmysql\u0026gt; USE newdatabase; mysql\u0026gt; FLUSH TABLES WITH READ LOCK; mysql\u0026gt; SHOW MASTER STATUS; +------------------+----------+--------------+---------------------------------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+---------------------------------------------+-------------------+ | mysql-bin.000002 | 754 | | mysql,information_schema,performance_schema | | +------------------+----------+--------------+---------------------------------------------+-------------------+ 1 row in set (0.00 sec) shell\u0026gt; mysqldump -u root -p --opt newdatabase \u0026gt; newdatabase.sql mysql\u0026gt; UNLOCK TABLES;  Slave配置 #  /etc/my.cnf增加配置\n[mysqld] server-id=2 log-bin=/cache1/mysql/log/mysql-bin.log #忽略系统库 binlog-ignore-db=mysql binlog-ignore-db=information_schema binlog-ignore-db=performance_schema  导入数据\nmysql\u0026gt; CREATE DATABASE newdatabase; shell\u0026gt; mysql -u root -p newdatabase \u0026lt; /path/to/newdatabase.sql  配置主服务器\nmysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master_host_name',MASTER_USER='repl',MASTER_PASSWORD='slave@2017',MASTER_LOG_FILE='mysql-bin.000002',MASTER_LOG_POS=754; mysql\u0026gt; START SLAVE; mysql\u0026gt; SHOW SLAVE STATUS\\G;  从库切换成主库\nmysql\u0026gt; SHOW PROCESSLIST; mysql\u0026gt; RESET MASTER;   Master-Master #  Master1，Master2配置 #  /etc/my.cnf 增加配置\n[mysqld] server-id=1 (Master2配置成2) log-bin=/cache1/mysql/log/mysql-bin.log #忽略系统库 binlog-ignore-db=mysql binlog-ignore-db=information_schema binlog-ignore-db=performance_schema  Replication 帐号创建\nmysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY 'slave@2017';  Master1查看本机Master状态 #  mysql\u0026gt; SHOW MASTER STATUS; +------------------+----------+--------------+---------------------------------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+---------------------------------------------+-------------------+ | mysql-bin.000002 | 754 | | mysql,information_schema,performance_schema | | +------------------+----------+--------------+---------------------------------------------+-------------------+ 1 row in set (0.00 sec)  Master2查看本机Master状态 #  mysql\u0026gt; show master status; +------------------+----------+--------------+---------------------------------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+---------------------------------------------+-------------------+ | mysql-bin.000001 | 915 | | mysql,information_schema,performance_schema | | +------------------+----------+--------------+---------------------------------------------+-------------------+ 1 row in set (0.00 sec)  Master1配置成Master2的从库 #  mysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master2',MASTER_USER='repl',MASTER_PASSWORD='slave@2017',MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=915; mysql\u0026gt; START SLAVE; mysql\u0026gt; SHOW SLAVE STATUS\\G;  Master2配置成Master1的从库 #  mysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master_host_name',MASTER_USER='repl',MASTER_PASSWORD='slave@2017',MASTER_LOG_FILE='mysql-bin.000002',MASTER_LOG_POS=754; mysql\u0026gt; START SLAVE; mysql\u0026gt; SHOW SLAVE STATUS\\G;   "});index.add({'id':100,'href':'/notes/docs/technology/database/SQL/mysql/install/','title':"Install",'content':"Mysql 安装 #  源码编译安装 #  准备 #    CMake(build framework)\nyum -y install cmake    GNU make(make program)\nyum -y install make    GCC(ANSI C++ complier)\nyum -y install gcc gcc-c++    Boost C++ libraries\n  ncurses library\nyum -y install ncurses ncurses-devel    Perl(run test scripts)\nyum -y install perl     安装 #    创建用户组\nshell\u0026gt; groupadd mysql shell\u0026gt; useradd -r -g mysql -s /bin/false mysql    编译安装\nshell\u0026gt; tar -zxvf mysql-VERSION.tar.gz shell\u0026gt; cd mysql-VERSION shell\u0026gt; mkdir bld shell\u0026gt; cd bld shell\u0026gt; cmake .. -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/usr/local/src -DCMAKE_INSTALL_PREFIX=/cache1/mysql -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci shell\u0026gt; make shell\u0026gt; make install    数据初始化\n  /etc/my.cnf文件配置\n[client] port=3306 socket=/tmp/mysql.sock [mysqld] bind-address=0.0.0.0 port=3306 socket=/tmp/mysql.sock datadir=/cache1/mysql/data symbolic-links=0 log-error=/cache1/mysql/log/mysqld.log pid-file=/cache1/mysql/log/mysqld.pid  数据初始化\nshell\u0026gt; cd /cache1/mysql shell\u0026gt; mkdir data log shell\u0026gt; chown -R mysql:mysql data shell\u0026gt; chown -R mysql:mysql log shell\u0026gt; bin/mysqld --initialize --user=mysql shell\u0026gt; cp support-files/mysql.service /etc/init.d/mysqld shell\u0026gt; /etc/init.d/mysqld start shell\u0026gt; mysql -uroot -p mysql\u0026gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'new_password'; mysql\u0026gt; SET PASSWORD = PASSWORD('your_new_password'); mysql\u0026gt; SELECT User, Host, HEX(authentication_string) FROM mysql.user;  "});index.add({'id':101,'href':'/notes/docs/technology/hidden/','title':"Hidden",'content':"This page is hidden in menu #  Quondam non pater est dignior ille Eurotas #  Latent te facies #  Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\n Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona #  O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); }  Fronde cetera dextrae sequens pennis voce muneris #  Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "});index.add({'id':102,'href':'/notes/docs/technology/other/BookNotes/codecademy/','title':"Codecademy",'content':"codecademy在线学习 #  HTML和CSS学习 #  HTML #  html基本机构 #  \u0026lt;!DOCTYPE html\u0026gt; //向浏览器声明类型 \u0026lt;html\u0026gt; //所有的html代码都要包含在该元素内 \u0026lt;head\u0026gt; //关于网页的信息，如标题 \u0026lt;title\u0026gt;First Web Page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; //可见的html代码内容都放在该元素内 \u0026lt;p\u0026gt;Hello,World!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  可见内容 #    标题\nheading\n \u0026lt;h1\u0026gt;head\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt; \u0026lt;h3\u0026gt; \u0026lt;h4\u0026gt; \u0026lt;h5\u0026gt; \u0026lt;h6\u0026gt;    段落\nparagraph\n \u0026lt;p\u0026gt;content\u0026lt;/p\u0026gt;    无序列表\nunodered list, list item\n \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;sub\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;    有序列表\nordered list, list item\n \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;sub\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt;    链接\n链接, href属性，属性提供更多元素内容的有关信息,在元素的开头标签中，由名称和值组成\n \u0026lt;a href=\u0026quot;https://example.com\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;content\u0026lt;/a\u0026gt;  链接属性: target属性指定链接要在新的浏览器打开.\n  图片\nimage\n \u0026lt;img src=\u0026quot;https://example.com/example.jpg\u0026quot; alt=\u0026quot;example\u0026quot; /\u0026gt; alt属性: 描述图像信息    换行\nline breaks\n aaa?\u0026lt;br/\u0026gt;bbb    注释\n   CSS #  CSS是网页开发人员用来在网页上设计HTML内容的语言.\n在html文件中编写css代码\n在head元素中加入style元素\n \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; h2 { font-family: Arial; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt;  在css文件中编写css代码 在html文件链接css文件，放在html文件开头 使用link元素 * href属性 css文件地址 * type属性 描述文件类型 * rel属性 描述css和html文件的关系\n link href=\u0026quot;https://www.codecademy.com/stylesheets/style.css\u0026quot; type=\u0026quot;text/css\u0026quot; rel=\u0026quot;stylesheet\u0026quot;\u0026gt;  color #    foregroud\n前景色是元素出现的颜色，color属性表示前景色 \\\n  background\nbackground-color表示背景色。\n  named colors\n 147 named colors\ncolor: named colors\n  RGB colors\nRGB(Red,Green,Blue) color: rgb(123,20.233)\n  Hex colors\ncolor: #09AA34\n  HSL colors\nHSL(Hue, Saturation, Lightness) color: hsl(182, 20%, 50%)\n  font #    font-family\n更改字体系列，font-family: \u0026ldquo;Courier New\u0026rdquo;;\n  fallback fonts\n当指定的字体不存在时，使用系统预先安装的字体，font-family: fonts-name, serif;\n  font-size\n更改字体大小，font-size: 18px; 三种大小单位：px, em, %;\n  line height\n更改行高，font-height: 1.5em;\n  word spacing\n字间距，word-spacing: 0.3em;\n  letter spacing\n字母间距：letter-spacing: 0.3em;\n  font weight\n更改字体粗细，font-weight: bold;\n  font style\n字体风格，font-style: italic;\n  text transformation\n内容转型: text-transform: uppercase;\n  text alignment\n文本对齐: text-align: right;\n   "});index.add({'id':103,'href':'/notes/docs/technology/other/BookNotes/CS50/','title':"C S50",'content':"CS50学习笔记 #  "});index.add({'id':104,'href':'/notes/docs/technology/other/BookNotes/finacial/','title':"Finacial",'content':"Finanical #  Goal Setting #  Understand How Goals Are Used #    What is a goal?\n  Long term vs Intermediate vs Short term\n  Is a financial goal any different than other goals?\n  SMART Goals #    Specific\n  Measurable\n  Attainable\n  Realistic\n  Time\n  Finanical Goals #    Saving\n  Housing\n  Insurance\n  Retirement\n   Budgeting #  What is a budget #    What is a budget\n A budget is a spending plan Dollars designated for specific areas    Where do the numbers come from?\n Cash flow statement A budget can be changed Review your cash flow statement to find excess or unusual amounts    Types of Budgets #    Written\n  Envelope\n  Mental\n  Develop the Budget #    Take a look at the cash flow statement\n  List all income\n  List the expenses by category\n  Compare income to expenses\n  Fixed or Variable? #    Fixed expenses\n  Variable expenses\n  Adjust variable expenses to keep expenses less than your income\n  Or adjust income to make income cover expenses\n   Credit #  What is credit ? #    What is credit?\n  Consumer credit\n  cost of credit\n  What is the Credit bureau? #   The credit bureau collects and shares your credit information  Credit Score #    Five factors that are considered\n  Payment history\n  Debt\n  Length of credit history\n  Types of credit\n  Inquiries\n    Type of Credit #    Credit card\n  Convenience users vs borrower\n  Bank card or merchant card\n    Unsecured loan\n Depending on your credit, this may or may not be available    Secured loan\n The lender has collateral ,therefore less risk.    Mortgage\n Less risk, but larger amount.    Obtaining the Credit #    Credit card\n Apply for a credit card.    Unsecured loan\n Talk to your financial institution.    Secured loan\n Talk to your financial institution or the company selling the product    Mortgage\n Apply through your financial institution.    Evaluating Credit Worthiness #    Capacity\n  Character\n  Collateral\n  Capital\n  Conditions\n   Insurance #  What is insurance ? #    What is insurance?\n Insurance is all about risk management Insurance is available to prevent financial loss The insurance company assumes the risk for you The individual pays the company a premium    Where do the numbers come from?\n The likelihood of an individual experiencing a loss The potential cost of each loss Based on the concept of large numbers    Risk management terms #    Risk\n An unpredictable chance of loss or injury    Hazard\n Anything that increases the likelihood a loss    Peril\n Anything that causes a loss    Liability\n The legal responsibility for someone else\u0026rsquo;s loss    Areas of Insurance #    Property\n Automobile Home Personal possessions    Liability\n  Health\n  Life\n   Investing #  Common Types of Investments #    Money Market Securities\n  Stock\n  Bonds\n  Mutual Funds\n  Return on Investment #    Dividend or interest\n  Increase(or decrease) in value\n  Risk #    Inflation\n  Interest rate\n  Business failure\n  Market\n  Common Mistakes #    Unrealistic goals\n  Lose sight of the goal\n  Borrowing to invest\n  Taking additional risk to cover previous losses\n  Accepting advice from \u0026ldquo;the expert\u0026rdquo;\n   #  "});index.add({'id':105,'href':'/notes/docs/technology/other/BookNotes/thinkOS/','title':"Think O S",'content':"操作系统思考 #  编译 #   编译语言和解释语言    编译语言\n程序被翻译成机器语言，之后由硬件执行。\n  解释语言\n程序被软件解释器读取并执行。\n  静态类型和动态类型    动态类型\n无需定义变量类型，直到运行时才直到变量类型，解释语言通常支持动态类型。\n  静态类型\n需定义变量类型，编译语言通常限制为静态类型。\n优点：\n  编译时检查，可以更快找到错误。\n  节省空间\n动态语言，变量的名称在程序运行时存储在内存中，并且它们通常可由程序访问。 编译语言，变量的名称只存在编译时，而不是运行时。 编译器为每个变量选择一个位置，并记录这些位置作为所编译程序的一部分。变量的位置被称为“地址”。在运行期间，每个变量的值都存储在它的地址处，但变量的名称完全不会存储。      编译过程    预处理\nC是包含\u0026quot;预处理指令\u0026quot;的几种语言之一，它生效于编译之前。例如，#include 指令使其他文件的源代码插入到指令所在的位置\n  解析\n编译器读取源代码，并构建程序的内部表示，称为\u0026quot;抽象语法树(AST)\u0026quot;。这一阶段的错误检查通常为语法错误。\n  静态检查\n编译器会检查变量和值得类型是否正确，函数调用是否带有正确数量和类型的参数，以及其他。这一阶段的错误检测通常为一些\u0026quot;静态语义\u0026quot;的错误\n  代码生成\n编译器读取程序的内部表示，并生成机器码或字节码\n  链接\n如果程序使用了定义在库中的值或函数，编译器需要找到合适的库并包含所需要的代码。\n  优化\n在这个过程的几个时间点上，编译器可以修改程序来生成运行更快或占用更少空间的代码。\n  目标代码  编译后的程序，目标代码并不是可执行代码，但是它可以链接到可执行文件中。\n汇编代码  编译后的程序，它通常为机器代码的可读形式。\n 预处理\n  理解错误\n   进程 #   抽象和虚拟化    抽象\n抽象是复杂事物的简单表示。\n  虚拟化\n一类非常重要的抽象就是虚拟化，它是创建可取的幻象的过程。\n  隔离  工程最重要的原则之一就是隔离(lsolation)。\n操作系统最重要的目标之一，就是将每个进程和其他进程隔离，使程序员不必考虑每个可能的交互情况。提供这种隔离的软件对象叫做进程(Porcess)。\n进程是表示运行中程序的软件对象。通常一个对象包含数据，并且提供用于操作数据的方法。\n进程正是包含以下数据的对象：\n 程序文本，通常是机器语言的指令序列。 程序相关的数据，包括静态数据（编译时分配）和动态数据，后者包括运行时的栈和堆。 任何等等中的IO状态。 程序的硬件状态，包括存储在寄存器中的数据，状态信息，以及程序计数器，它表示当前执行了哪个指令。  操作系统提供了隔离进程的基本功能：\n 多任务：大多数操作系统有能力在几乎任何时候中断一个进程，保存它的硬件状态，并且在以后恢复它。 虚拟内存：大多数操作系统会创建幻象，每个进程看似拥有独立内存片并且孤立于其他进程。 设备抽象：运行于同一台计算机的进程共享磁盘、网络接口、显卡和其他硬件。   虚拟内存 #   虚拟内存 #   简明信息理论  比特是二进制的数字，也是信息单位。 n个比特可以表示2 ** b个值，一个字节是8个比特，所以它可以存储256个值。\n内存(Memory)和存储器(Storage)  当进程处于运行期间，它的多数数据都放在内存中。内存中的数据容易丢失。单位为GiB代表\u0026quot;gibibyte\u0026rdquo;，相当于2 ** 30字节\n如果进程会读写文件，这些文件通常放在存储器中。存储器的数据可用于长时间存储。单位为GB代表\u0026quot;gigabyte\u0026rdquo;，相当于10 ** 30字节\n地址空间  内存中的每个字节都由一个\u0026quot;物理地址\u0026quot;整数所指定，物理地址的集合叫做物理\u0026quot;地址空间\u0026rdquo;。范围通常为0到N-1，N是内存大小。\n操作系统提供\u0026quot;虚拟内存\u0026rdquo;，程序处理虚拟地址，范围为0到M-1，M是有效虚拟地址的大小。虚拟地址空间的大小取决于操作系统和硬件。\n  32位系统\n虚拟地址是32位的，虚拟地址空间的大小是2 ** 32个字节，或者4GiB\n  64位系统\n虚拟地址是64位的，虚拟地址空间的大小是2 ** 64个字节，或者是4 * 1024 ** 6个字节，16EiB\n  当一个程序读写内存中的值时，它使用虚拟地址。硬件在操作系统的帮助下，在访问主存之前将物理地址翻译成虚拟地址。翻译过程在进程层级上完成，所以两个进程访问相同的虚拟地址，他们所映射的物理地址可能不同。\n虚拟内存是操作系统隔离进程的一种重要途径。\n内存段  一个运行中进程的数据组织为4个段：\n text段：包含程序文本，即程序所组成的机器语言指令。靠近内存\u0026quot;底部\u0026rdquo;，即接近0的地址 static段：包含由编译器所分配的变量，包含全局变量和使用static声明的局部变量。通常刚好在text段上面 stack段：包含运行时栈，它由栈帧组成。每个帧包含函数参数、本地变量以及其他。靠近内存顶部，即接近虚拟地址空间的最大地址。在扩张过程中，它向低地址的方向增长。 heap段：包含运行时分配的内存块，通常通过调用C标准库函数malloc来分配。通常在static段的上面，在扩张过程中，它向高地址的方向增长。  静态局部变量  栈上的局部变量有时称为\u0026quot;自动变量\u0026rdquo;，它们当函数创建时自动被分配，并且当函数返回时自动被释放。\nC中有另一种局部变量，叫做\u0026quot;静态变量\u0026rdquo;，它分配在static段上。它在程序启动时初始化，并且在函数调用之间保存它的值。\n地址翻译  虚拟地址(VA)翻译成物理地址(GA)\n大多数处理器提供了内存管理单元(MMU)，位于CPU和主存之间。MMU在VA和PA之间执行快速的翻译。\n 当程序读写变量时，CPU会得到VA。 MMU将VA分成两部分，称为页码和偏移。\u0026ldquo;页\u0026quot;是一个内存块，页的大小取决于操作系统和硬件，通常为1~4KiB MMU在\u0026quot;页表\u0026quot;里查找页码，然后获取相应的物理页码。之后将物理页码和偏移组合得到PA。 PA传递给主存，用于读写指定地址。   文件和文件系统 #  “文件系统”将每个文件的名称映射到它的内容。是一种键值对的数据库。 “文件”是一组字节序列。\n文件名通常是字符串，并且通常是分层的。这个字符串指定了顶级目录的路径，通过一系列子目录，到达特定的文件。\n文件是基于字节的，而持久化存储器是基于块的。操作系统将C标准库中基于字节的文件操作翻译成基于块的存储设备操作。\n 文件的读取和写入过程：    读取\n 程序使用文件名寻找顶级目录，子目录以及n级目录 找到名为xxx的文件，并且\u0026quot;打开\u0026quot;它以便读取。实际上是创建了一个数据结构料表示将要读取的文件。数据结构还跟踪了文件读取了多少字节，称为“文件位置”。 操作系统检查下个字节是否已经在内存中。如果是的话，读取下一个字节，向前移动文件位置，并返回结果。 如果不在内存中，操作系统产生IO请求来获取下一个块。 IO操作完成时，新的数据快回存储在内存中。 当进程关闭文件时，操作系统完成或取消任何等待中的操作，移除内存中的数据，并且释放OpenFileTableEntry    写入\n 程序使用文件名寻找文件。如果文件不存在，就会创建新的文件，并向父目录添加条目 操作系统创建OpenFileTableEntry，表示这个文件已打开等待写入，并将文件位置设置为0. 程序尝试写入文件的第一个字节。如果文件存在，操作系统需要将第一个块加载到内存中。否则它会在内存中分配新的块，并且在磁盘上请求新的块。 在内存中的块被修改后，可能不会立即复制回磁盘。通常，写到文件中的数据是“被缓冲的”，意思是它存储在内存中，只在至少有一个块需要写入时才写回磁盘。 文件关闭时，任何缓冲的数据都会写到磁盘，并且OpenFileTableEntry会被释放。    C标准库提供了文件系统的抽象，将文件名称映射到字节流。这个抽象建立在实际以块组织的存储设备之上。\n磁盘性能  操作系统和硬件提供了一些特性用于弥补主存和持久化存储器的性能间隔。\n 块的传输 预取 缓冲  磁盘元数据  块可以放在磁盘上的任意位置，使用各种数据结构来跟踪这些块。\n在UNIX文件系统中，这些数据结构叫做inode，它代表“索引节点”(index node)。也叫做“元数据”(数据的数据)\n块的分配  操作系统既要跟踪哪些块属于哪个文件，也需要跟踪哪些块可供使用。\n块分配系统的目标：\n 速度：块的分配和释放应该很快。 最小的空间开销 最少的碎片 最大的连续性   内存管理 #  动态内存分配函数：\n malloc， 接受表示字节单位的大小的整数，返回指向新分配的、(至少)为指定大小的内存块的指针。如果不满足，返回NULL指针 calloc， 和malloc一样，还会清空新分配的空间。 free， 它接受指向之前分配的内存块的指针，并会释放它 realloc，接受指向之前分配的内存块的指针，和一个新的大小    内存错误\n 访问任何没有分配的内存块 释放某个内存块之后再访问它 释放一个没有分配的内存块 释放多次相同的内存块 使用没有分配或者已经释放的内存块调用realloc    内存泄漏\n分配了一块内存，并且没有释放它，导致内存总量无限增长\n  实现\n   缓存 #   程序如何运行  操作系统创建新的进程来运行程序，之后\u0026quot;加载器\u0026quot;将代码从存储器复制到主存中，并且通过调用main来启动程序。\n在程序运行时，大部分数据存储在主存中，一些数据存储在寄存器中，它是CPU上的小型存储单元，包括：\n 程序计数器(PC)，含有程序下一条指令(在内存中)的地址 指令寄存器(IR)，含有当前执行的指令的机器码。 栈指针(SP)，含有当前函数栈帧的指针，其中包含函数参数和局部变量。 程序当前使用的存放数据的通用寄存器。 状态寄存器，含有当前计算的信息。  在程序运行时，CPU执行下列步骤，叫做\u0026quot;指令周期\u0026rdquo;：\n 取指(Fetch)：从内存中获取下一条指令，存储在指令寄存器中。 译码(Decode)：控制单元将指令译码，并向CPU的其他部分发送信号。 执行(Execute)：收到来自控制单元的信号后会执行合适的计算。  缓存性能  \u0026ldquo;缓存\u0026quot;是CPU上小型、快速的存储空间。\n当CPU从内存中读取数据时，它将一份副本存到缓存中。如果再次读取相同的数据，CPU就直接读取缓存。\n存储器层次结构     设备 访问时间 通常大小     寄存器 0.5 ns 256 B   缓存 1 ns 2 MiB   DRAM 10 ns 4 GiB   SSD 10 us 100 GiB   HDD 5 ms 500 GiB     缓存策略\n  页面调度\n  操作系统可以将页面在存储器和内存之间移动。这种机制叫做\u0026quot;页面调度\u0026rdquo;。\n工作流程:\n 进程A调用malloc来分配页面。如果堆中没有所请求大小的空闲空间，malloc会调用sbrk向操作系统请求更多内存。 如果物理内存中有空闲页，操作系统会将其加载到进程A的页表，创建新的虚拟内存范围。 如果没有空闲页面，调度系统会选择一个属于进程B的\u0026quot;牺牲页面\u0026rdquo;。它将页面内容从内存复制到磁盘，之后修改进程B的页表来表示这个页面\u0026quot;被换出\u0026rdquo; 一旦进程B的数据被写入，页面会重新分配给进程A。为了防止进程A读取进程B的数据，页面应被清空。 此时sbrk的调用可以返回，向malloc提供堆区额外的空间。之后malloc分配所请求的内存并返回。进程A可以继续执行。 当进程A执行完毕，或中断后，调度器可能会让进程B继续执行。当它访问到被换出的页面时，内存管理器单元注意到这个页面是\u0026quot;无效\u0026quot;的，并且会触发中断。 当操作系统处理中断时，它会看到页面被换出了，于是它将页面从磁盘传送到内存。 一旦页面被换入之后，进程B可以继续执行。  页面调度可以极大提升物理内存的利用水平，允许更多进程在更少的空间内执行。原因：\n 大多数进程不会用完所分配内存。这些页面被换出而不会引发任何问题。 如果程序泄漏了内存，它可能会丢掉所分配的空间。通过将这些页面换出，可以有效填补泄漏。 当进程闲置时，这些进程可以被换出 当多进程运行同一个程序时，进程可以共享相同的text段，避免在物理内存中保留过多副本。   多任务 #  CPU包含多个核心，也就是说可以运行多个进程。并且，每个核心都具有\u0026quot;多任务\u0026quot;的能力。也就是说它可以从一个进程快速切换到另一个进程，创造出同时运行许多进程的幻象。\n在操作系统中，多任务由内核实现。其本质就是处理中断。“中断”是一个事件，它会停止通常的指令周期，并且使执行流跳到称为“中断处理器”的特殊代码区域内。\n当一个设备向CPU发送信号时，会发生硬件中断。软件中断由运行中的程序所产生。\n当程序需要访问硬件设备时，会进行“系统调用”，它就像函数调用，除了并非跳到函数的起始位置，而是执行一条特殊的指令来触发中断，使执行流跳到内核中。内核读取系统调用的参数，执行所请求的操作，之后使被中断进程恢复运行。\n 硬件状态   当中断发生时，硬件将程序计数器保存到一个特殊的寄存器中，并且跳到合适的中断处理器。 中断处理器将程序计数器和位寄存器，以及任何打算使用的数据寄存器的内容储存到内存中。 中断处理器运行处理中断所需的代码。 之后它复原所保存寄存器的内容。最后，复原被中断进程的程序计数器，这会跳回到被中断的进程。  上下文切换  中断处理器非常快，因为它们不需要保存整个硬件状态。它们只需要保存打算使用的寄存器。\n但是当中断发生时，内核并不总会恢复被中断的进程。它可以选择切换到其它进程，这种机制叫做“上下文切换”。\n进程的生命周期  当进程被创建时，操作系统会为进程分配包含进程信息的数据结构，称为“进程控制块”（PCB）。在其它方面，PCB跟踪进程的状态，这包括：\n 运行（Running），如果进程正在运行于某个核心上。 就绪（Ready），如果进程可以但没有运行，通常由于就绪进程数量大于内核的数量。 阻塞（Blocked），如果进程由于正在等待未来的事件，例如网络通信或磁盘读取，而不能运行。 终止（Done）：如果进程运行完毕，但是带有没有读取的退出状态信息。  下面是一些可导致进程状态转换的事件：\n 一个进程在运行中的程序执行类似于fork的系统调用时诞生。在系统调用的末尾，新的进程通常就绪。之后调度器可能恢复原有的进程（“父进程”），或者启动新的进程（“子进程”）。 当一个进程由调度器启动或恢复时，它的状态从就绪变为运行。 当一个进程被中断，并且调度器没有选择使它恢复，它的状态从运行变成就绪。 如果一个进程执行不能立即完成的系统调用，例如磁盘请求，它会变为阻塞，并且调度器会选择另一个进程。 当类似于磁盘请求的操作完成时，会产生中断。中断处理器弄清楚哪个进程正在等待请求，并将它的状态从阻塞变为就绪。 当一个进程调用exit时，中断处理器在PCB中储存退出代码，并将进程的状态变为终止。  调度  大多数情况下，只有一小部分进程是就绪或者运行的。当中断发生时，调度器会决定那个进程应启动或恢复。\n大多数调度器使用一些基于优先级的调度形式，其中每个进程都有可以调上或调下的优先级。当调度器运行时，它会选择最高优先级的就绪进程。\n下面是决定进程优先级的一些因素：\n 具有较高优先级的进程通常运行较快。 如果一个进程在时间片结束之前发出请求并被阻塞，就可能是IO密集型程序或交互型程序，优先级应该升高。 如果一个进程在整个时间片中都运行，就可能是长时间运行的计算密集型程序，优先级应该降低。 如果一个任务长时间被阻塞，之后变为就绪，它应该提升为最高优先级，便于响应所等待的东西。 如果进程A在等待进程B的过程中被阻塞，例如，如果它们由管道连接，进程B的优先级应升高。 系统调用nice允许进程降低（但不能升高）自己的优先级，并允许程序员向调度器传递显式的信息。  实时调度  调度满足截止期限的任务叫做“实时调度”。对于一些应用，类似于Linux的通用操作系统可以被修改来处理实时调度。这些修改可能包括：\n 为控制任务的优先级提供更丰富的API。 修改调度器来确保最高优先级的进程在固定时间内运行。 重新组织中断处理器来保证最大完成时间。 修改锁和其它同步机制（下一章会讲到），允许高优先级的任务预先占用低优先级的任务。 选择保证最大完成时间的动态内存分配实现。   "});index.add({'id':106,'href':'/notes/docs/technology/other/Interview/classic/','title':"Classic",'content':"经典问题 #  1. 当输入google.com时，发生了什么？ #  1.1 URL解析 #  当输入的URL不合法时，浏览器会将输入的字符传给默认搜索引擎，\n浏览器通过URL能知道以下信息：\nprotocol: http host: google.com resource: / 1.2 HTST #  1、浏览器检查自身的HTST列表，确认是否包含该主机。 2、若HTST存在该主机，使用https代替http，否则使用http。 1.3 DNS解析 #  1、浏览器检查自身的DNS缓存 2、查找本地hosts文件 3、发起DNS解析查询 4、查询 本地|ISP DNS服务器 5、本地|ISP DNS服务器像高层服务器发起递归查询直到查到该域名的解析IP 1.4 TCP连接建立 #  1、client端发送SYN请求到server端，声明自己的ISN为aaa (CLOSED--\u0026gt;SYN-SENT) 2、server端接收SYN包，声明自己的ISN为bbb，ACK信息为aaa+1，返回给client端 (LISTEN--\u0026gt;SYN-RECEIVED) 3、client端返回ACK为bbb+1为server端 (SYN-SENT--\u0026gt;ESTABLISHED) 4、数据交互 1.5 TLS连接建立 #  1.6 HTTP #   "});index.add({'id':107,'href':'/notes/docs/technology/other/Interview/hangzhou/','title':"Hangzhou",'content':"面试经历 #  club factory #   如何部署 如何监控 部署怎么实现 docker的优势和劣势  "});index.add({'id':108,'href':'/notes/docs/technology/other/Interview/technology/','title':"Technology",'content':"技术知识点 #  硬件 #  1. 机器型号 #  dmidecode | awk -F\u0026#39;:\u0026#39; \u0026#39;/Product Name/{print $2}\u0026#39; 2. CPU信息 #  #获取逻辑CPU数 awk -F':' '/name/{print $2}' /proc/cpuinfo | wc -l #获取CPU型号 awk -F':' '/name/{print $2}' /proc/cpuinfo | uniq #获取物理cpu数 grep \u0026quot;physical id\u0026quot; /proc/cpuinfo | sort | uniq | wc -l 3. 内存信息 #  #获取内存大小 free -h #内存物理信息 dmidecode -t memory 4. 磁盘信息 #   5. 计算机组成 #  1. 控制器 2. 运算器 3. 存储器 4. 输入设备 5. 输出设备 系统 #   网络 #  1. TCP协议 #  1.1三次握手 #  1、server端开启端口监听。(CLOSED--\u0026gt;LISTEN) 2、client端发送SYN信息给server端。(CLOSED--\u0026gt;SYN-SENT) 3、server端接收SYN信息，返回ACK信息和SYN信息给client端。(LISTEN--\u0026gt;SYN-RECEIVED) 4、client端接收ACK和SYN信息，并返回一个ACK信息给server端.(SYN-SENT--\u0026gt;ESTABLISHED) 5、server端接收ACK信息。(SYN-RECEIVED--\u0026gt;ESTABLISHED) 6、连接建立  1.2四次挥手 #  1、client端主动发起关闭请求，发送FIN信息给server端(ESTABLISHED--\u0026gt;FIN-WAIT-1) 2、server端接收FIN信息，并返回一个ACK信息，等待应用确认关闭连接(ESTABLISHED--\u0026gt;CLOSE-WAIT) 3、client端接收ACK信息，等待server端的FIN信息(FIN-WAIT-1--\u0026gt;FIN-WAIT-2) 4、server端确认关闭，发送FIN信息给client端(CLOSE-WAIT--\u0026gt;LAST-ACK) 5、client端接收FIN信息，返回一个ACK信息。(FIN-WAIT-2--\u0026gt;TIME-WAIT) 6、server端接收ACK信息，关闭连接。(LASK-ACK--\u0026gt;CLOSED) 7、client端超时关闭连接。(TIME-WAIT--\u0026gt;CLOSED) 8、连接关闭 2. DNS #  1、查找本机缓存 2、查找本地hosts 3、查找路由器缓存 4、查找本地/ISP DNS服务器 5、查找根服务器 6、递归查询直到查到域名解析IP 7、本地DNS服务器缓存，返回给本机 3. HTTP #   WEB #  1. CDN #  1. client请求www.cctest.com 2. www.cctest.com CNAME 到 cctest.cdncache.com 3. CDN内部根据源IP得到离源IP最近的Cache服务器IP，并返回给client 4. client向Cache服务器发起请求 5. 请求内容存在，直接返回给client 6. 请求内容不存在，Cache服务器向RealServer请求内容 7. Cache服务器缓存RealServer的内容，并将内容返回给client 2.Lvs #  四层负载均衡\n1. client向LVS发起请求 2. LVS根据路由模式和调度算法分配realserver 3. client向realserver发起请求 路由模式:\n  NAT\n1. client request load balance 2. load balance 选择一台 realserver 3. 更改packet的dest ip port 为realserver的ip port 4. realserver接收并返回请求 5. load balance 更改packet的source ip port 为 loadbalance的ip port   DR\n1. client request load balance 2. load balance 选择一台 realserver 3. 更改目的mac地址，转发到realserver 4. realserver接受请求，返回给client   TUN\n1. client request load balance 2. load balance 选择一台 realserver 3. 通过tunnel将请求转发给realserver 4. realserver接受请求，返回给client   调度算法：\n1. rr 2. wrr 3. lc 4. wlc 5. lblc 6. lblcr 7. dh 8. sh 9. sed 10. nq 3.Nginx #  WEB服务器，七层负载，反向代理\n4.Tomcat #   大数据 #   编程 #  "});index.add({'id':109,'href':'/notes/docs/technology/other/MyConfig/vim/vimconf/','title':"Vimconf",'content':"Vim配置指南 #  Don\u0026rsquo;t put any lines in your vimrc that you don\u0026rsquo;t understand. #      Colors\n   Spaces And Tabs\n   UI Config\n   Searching\n   Folding\n   Custom Movements\n   Custom Leader\n   CtrlP Settings\n   Launch Config\n   Tmux Config\n   Autogroups\n   Backups\n   Custom Functions\n   Organization\n   Wrapping It Up\n   Colors colorscheme badwolf \u0026quot; 设置色彩方案 systax enable \u0026quot; 开启语法处理   Spaces \u0026 Tabs set tabstop=4 \u0026quot; 设置每个TAB的视觉空格数 set softtabstop=4 \u0026quot; 设置编辑时tab的空格数 set expandtab \u0026quot; 将\u0026lt;TAB\u0026gt;符号转换为空格   UI Config set number \u0026quot; 显示行号 set showcmd \u0026quot; 在vim右下方显示最后一个命令，在powerline插件内有效 set cursorline \u0026quot; 当前行高亮 "});index.add({'id':110,'href':'/notes/docs/technology/other/Solution/aboutNtpdate/','title':"About Ntpdate",'content':"时间同步相关问题 #  ntpdate:no server suitable for synchronization found #  Question： #  　在使用ntpdate同步时间时，出现了no server suitable for synchronization found的报错。\n　通过ntpdate -d s2m.time.edu.cn 使用debug模式没有出现异常。\nAnswer： #  解决办法是，使用ntpdate -ubv s2m.time.edu.cn，可以正常同步了。\n主要是-u选项的作用\n-u：Direct ntpdate to use an unprivileged port for outgoing packets. This is most useful when behind a firewall that blocks incoming traffic to privileged ports, and you want to synchronize with hosts beyond the firewall. Note that the -d option always uses unprivileged ports.   "});index.add({'id':111,'href':'/notes/docs/technology/other/Solution/aboutSsh/','title':"About Ssh",'content':"ssh连接相关问题 #  pam_tally2(sshd:auth): user root (0) has time limit [3s left] since last failure 日志 #  Question： #  工作中，碰到某服务器在批量ssh登陆操作时，出现大量的无法连接的情况。\nThinking： #  查看ssh日志(/var/log/secure)， 首先注意到的是，\u0026ldquo;Failed password for root from xxx.xxx.xxx.xxx port 51230 ssh2\u0026quot;错误，但发现密码并没有错误，并且只在批量操作时才会出现，故初步判断为连接数问题。\n查看ssh连接数限制\n/usr/sbin/sshd -T | grep -i max  调整参数，更改配置文件/etc/sshd/sshd_config\nmaxsessions 1000  重启服务后，依然没有效果。\n再次查看日志，发现在做批量操作时，有大量的\u0026quot;pam_tally2(sshd:auth): user root (0) has time limit [3s left] since last failure\u0026quot;日志。\n应该是pam模块做了相应的限制\n查看配置文件 /etc/pam.d/sshd 文件\nauth required pam_tally2.so deny=10 lock_time=3 unlock_time=30 even_deny_root root_unlock_time=30  Answer： #  更改配置文件：\n#auth required pam_tally2.so deny=10 lock_time=3 unlock_time=30 even_deny_root root_unlock_time=30   "});index.add({'id':112,'href':'/notes/docs/technology/program/Advanced/design/factoryMethod/','title':"Factory Method",'content':"工厂方法模式(Factory Method Pattern) #  模式定义 #  工厂方法模式(Factory Method Pattern)又称为工厂模式，也叫虚拟构造器(Virtual Constructor)模式或者多态工厂(Polymorphic Factory)模式，它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。\n 模式结构 #    Product：抽象产品\n  ConcreteProduct：具体产品\n  Factory：抽象工厂\n  ConcreteFactory：具体工厂\n   "});index.add({'id':113,'href':'/notes/docs/technology/program/Advanced/design/simpleFactory/','title':"Simple Factory",'content':"简单工厂模式(Simple Factory Pattern) #  模式定义 #  简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。\n 模式结构 #    Factory：工厂角色\n工厂角色负责实现创建所有实例的内部逻辑\n  Product：抽象产品角色\n抽象产品角色是所创建的所有对象的父类，负责描述所有实例所共有的公共接口\n  ConcreteProduct：具体产品角色\n具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例。\n   "});index.add({'id':114,'href':'/notes/docs/technology/program/Language/python/CookBook/DataStructuresAndAlgorithms/README/','title':"R E a D M E",'content':"数据结构和算法 #    解压序列赋值给多个变量\n问题，现在有一个包含N个元素的元组或者是序列，怎样将它里面的值解压后同时赋值给N个变量？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; data = ['John',170,60,(1999,9,9)] \u0026gt;\u0026gt;\u0026gt; name, height, weight, birthday = data ### 另一种方式 \u0026gt;\u0026gt;\u0026gt; name, height, weight, (year, mon, day) = data    解压可迭代对象赋值给多个变量\n问题，如果一个可迭代对象的元素个数超过变量个数时，会抛出一个ValueError。那么怎样才能从这个可迭代对象中解压出N个元素出来？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212') \u0026gt;\u0026gt;\u0026gt; name, email, *phone_numbers = record    保留最后N个元素\n问题，在迭代操作或者其他操作的时候，怎样只保留最后有限几个元素的历史记录？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; from collections import deque \u0026gt;\u0026gt;\u0026gt; q = deque(maxlen = 3) \u0026gt;\u0026gt;\u0026gt; q.append(1) \u0026gt;\u0026gt;\u0026gt; q.append(2) \u0026gt;\u0026gt;\u0026gt; q.append(3) \u0026gt;\u0026gt;\u0026gt; q deque([1, 2, 3], maxlen=3) \u0026gt;\u0026gt;\u0026gt; q.append(4) \u0026gt;\u0026gt;\u0026gt; q deque([2, 3, 4], maxlen=3)    查找最大或最小的N个元素\n问题，怎样从一个集合中获得最大或者最小的N个元素列表？\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; import heapq \u0026gt;\u0026gt;\u0026gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2] \u0026gt;\u0026gt;\u0026gt; heapq.nlargest(3,nums) [42, 37, 23] \u0026gt;\u0026gt;\u0026gt; heapq.nsmallest(3,nums) [-4, 1, 2]    实现优先级队列\n问题，给定一个具有优先级的队列，每次pop操作取出优先级最高的Item\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; from heapq import heappush, heappop \u0026gt;\u0026gt;\u0026gt; heap = [] \u0026gt;\u0026gt;\u0026gt; data = [(2,'A'),(7,'B'),(5,'C')] \u0026gt;\u0026gt;\u0026gt; for item in data: ... heappush(heap, item) ... \u0026gt;\u0026gt;\u0026gt; print(heappop(heap)[-1]) A \u0026gt;\u0026gt;\u0026gt; print(heappop(heap)[-1]) C \u0026gt;\u0026gt;\u0026gt; print(heappop(heap)[-1]) B    字典中将键映射到多个值\n问题，字典是每个键映射到单个值的映射。如果要将键映射到多个值，则需要将多个值存储在另一个容器中，例如列表或集合。\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; d = {'a':[1,2,3],'b':[4,5]} \u0026gt;\u0026gt;\u0026gt; d = {'a':{1,2,3},'b':{4.5}} #另一种实现 \u0026gt;\u0026gt;\u0026gt; from collections import defaultdict \u0026gt;\u0026gt;\u0026gt; d = defaultdict(list) \u0026gt;\u0026gt;\u0026gt; d['a'].append(1) \u0026gt;\u0026gt;\u0026gt; d['a'].append(2) \u0026gt;\u0026gt;\u0026gt; d['b'].append(4)    有序字典\n问题，想使用字典，并且想在迭代的时候控制输出顺序。\n实现,： 详细代码\n \u0026gt;\u0026gt;\u0026gt; from collections import OrderedDict \u0026gt;\u0026gt;\u0026gt; d = OrderedDict()    用字典计算\n问题，想用字典内的数据做各种计算(最大值，最小值，排序等)\n实现： 详细代码\n \u0026gt;\u0026gt;\u0026gt; prices = {'APPLE':23.33,'ORANGE':33.55,'BANANA':11.23} \u0026gt;\u0026gt;\u0026gt; print(min(zip(prices.values(),prices.keys()))) (11.23, 'BANANA') \u0026gt;\u0026gt;\u0026gt; print(max(zip(prices.values(),prices.keys()))) (33.55, 'ORANGE') \u0026gt;\u0026gt;\u0026gt; print(sorted(zip(prices.values(),prices.keys()))) [(11.23, 'BANANA'), (23.33, 'APPLE'), (33.55, 'ORANGE')]    查找两个字典的共性\n问题，比对两个字典，返回两个字典的共性。\n实现， 详细代码\n \u0026gt;\u0026gt;\u0026gt; a = {'x':1,'y':2,'z':3} \u0026gt;\u0026gt;\u0026gt; b = {'w':10,'x':11,'y':2} \u0026gt;\u0026gt;\u0026gt; a.keys() \u0026amp; b.keys() {'x', 'y'} \u0026gt;\u0026gt;\u0026gt; a.keys() - b.keys() {'z'} \u0026gt;\u0026gt;\u0026gt; a.items() \u0026amp; b.items() {('y', 2)}    删除列表的重复项\n问题，排除列表中的重复项，并保留顺序。\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; seen = set() \u0026gt;\u0026gt;\u0026gt; for item in [1,3,5,9,1]: ... if item not in seen: ... seen.add(item) \u0026gt;\u0026gt;\u0026gt; list(seen) [1, 3, 5, 9]    命名一个分片\n问题，清除混乱的内容\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; record = '....................100 .......513.25 ..........' \u0026gt;\u0026gt;\u0026gt; SHARES = slice(20,32) \u0026gt;\u0026gt;\u0026gt; PRICE = slice(40,48) \u0026gt;\u0026gt;\u0026gt; cost = int(record[SHARES]) * float(record[PRICE]) \u0026gt;\u0026gt;\u0026gt; print(cost) 51325.0    查找队列中最常出现的item\n问题，有一个队列，想找出出现最频繁的item\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; from collections import Counter \u0026gt;\u0026gt;\u0026gt; words = ['look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes','look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',] \u0026gt;\u0026gt;\u0026gt; word_counts = Counter(words) \u0026gt;\u0026gt;\u0026gt; top_two = word_counts.most_common(2) \u0026gt;\u0026gt;\u0026gt; print(top_two) [('look', 4), ('into', 4)]    根据公共的key排序字典列表\n问题，你有一个字典的列表，你想根据一个或多个字典值排序条目。\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; rows = [ {'fname':'Brain','uid':1003}, ... {'fname':'Jhon','uid':1002}, ... {'fname':'Alin','uid':1005}] \u0026gt;\u0026gt;\u0026gt; from operator import itemgetter \u0026gt;\u0026gt;\u0026gt; rows_by_uid = sorted(rows,key=itemgetter('uid')) \u0026gt;\u0026gt;\u0026gt; print(rows_by_uid) [{'fname': 'Jhon', 'uid': 1002}, {'fname': 'Brain', 'uid': 1003}, {'fname': 'Alin', 'uid': 1005}]    排序不支持比较的对象\n问题，你想对同一类对象进行排序，但它本身并不支持比较\n实现， 详细代码\n  基于特定字段的值进行分组\n问题，有一系列字典或实例，希望根据特定字段的值来迭代数据，例如日期。\n实现， 详细代码\n  过滤队列中的元素\n问题，你有一个队列需要通过某些标准提取或者减少值\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; mylist = [1, 4, 3, -2, 5, 0] \u0026gt;\u0026gt;\u0026gt; [n for n in mylist if n \u0026gt; 0] [1, 4, 3, 5]    提取字典的子集\n问题，制作一个字典是另一个字典的一个子集\n实现， 详细代码\n  名称映射到序列中的元素\n问题，通过按名称访问元素，减少对结构中的位置的依赖\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; from collections import namedtuple \u0026gt;\u0026gt;\u0026gt; Subscriber = namedtuple('Subscriber', ['addr', 'joined']) \u0026gt;\u0026gt;\u0026gt; sub = Subscriber('test@examole.com', '2017-07-31') \u0026gt;\u0026gt;\u0026gt; sub Subscriber(addr='test@examole.com', joined='2017-07-31') \u0026gt;\u0026gt;\u0026gt; sub.addr 'test@examole.com' \u0026gt;\u0026gt;\u0026gt; sub.joined '2017-07-31'    同时转换和减少数据\n问题，您需要执行缩减功能(例如sum(),min(),max()),但首先需要转换或过滤数据.\n实现， 详细代码 \u0026raquo;\u0026gt; nums = [1,2,3,4,5] \u0026raquo;\u0026gt; s = sum(x*x for x in nums) \u0026raquo;\u0026gt; print(s) 55\n  将多个映射组合成单个映射\n问题，您有多个字典或映射，您要逻辑组合成一个映射来执行某些操作，例如查找值或检查键的存在\n实现， 详细代码\n\u0026gt;\u0026gt;\u0026gt; a = {'x': 1, 'z': 3 } \u0026gt;\u0026gt;\u0026gt; b = {'y': 2, 'z': 4 } \u0026gt;\u0026gt;\u0026gt; from collections import ChainMap \u0026gt;\u0026gt;\u0026gt; c = ChainMap(a,b) \u0026gt;\u0026gt;\u0026gt; c ChainMap({'x': 1, 'z': 3}, {'y': 2, 'z': 4})   "});index.add({'id':115,'href':'/notes/docs/technology/program/Language/python/CookBook/StringsAndText/README/','title':"R E a D M E",'content':"#字符串和文本\n   "});index.add({'id':116,'href':'/notes/docs/technology/program/Language/python/Framework/Django/django/','title':"Django",'content':"Django #  环境初始化 #  python3 install virtualenv cd demosite mkdir py3env virtualenv ./py3env/ source py3env/bin/activate #install Django pip3 install Django  项目初始化 #  django-admin startproject demosite python manage.py runserver python manage.py startapp polls  项目结构 #  demosite/ manage.py demosite/ __init__.py settings.py urls.py wsgi.py polls/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py views.py  "});index.add({'id':117,'href':'/notes/docs/technology/program/Language/python/Framework/Flask/flask/','title':"Flask",'content':"Flask #  安装 #  pip install flask   程序基本结构 #   初始化  所有 Flask 程序都必须创建一个程序实例。Web 服务器使用一种名为 Web 服务器网关接口（Web Server Gateway Interface，WSGI）的协议，把接收自客户端的所有请求都转交给这个对象处理。\nfrom flask import Flask app = Flask('__name__')  路由和函数  程序实例需要知道对每个URL请求运行哪些代码，所以保存了一个URL到Python函数的映射关系。处理URL和函数之间关系的程序称为路由。 在Flask程序中定义路由的最简便方式，是使用程序实例提供的app.route修饰器，把修饰的函数注册为路由。\n@app.route('/') def index(): return '\u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt;'   启动服务\nif name == \u0026lsquo;main\u0026rsquo; app.run(Debug=True)\n   模版 #  模板是一个包含响应文本的文件，其中包含用占位变量表示的动态部分，其具体值只在请求的上下文中才能知道。使用真实值替换变量，再返回最终得到的响应字符串，这一过程称为渲染。为了渲染模板，Flask 使用了一个名为 Jinja2 的强大模板引擎。\nJinja2模板引擎 #  templates/user.html：Jinja2 模板\n\u0026lt;h1\u0026gt;Hello {{ name }} !\u0026lt;/h1\u0026gt;   渲染模版  示例，使用render_template\n@app.route('/user/\u0026lt;name\u0026gt;') def user(name) return render_template('user.html',name=name)  变量  Jinja2 能识别所有类型的变量，甚至是一些复杂的类型，例如列表、字典和对象。\n\u0026lt;p\u0026gt;A value from a dictionary: {{ mydict['key'] }}.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;A value from a list: {{ mylist[3] }}.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;A value from a list, with a variable index: {{ mylist[myintvar] }}.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;A value from an object's method: {{ myobj.somemethod() }}.\u0026lt;/p\u0026gt;  可以使用过滤器修改变量，过滤器名添加在变量名之后，中间使用竖线分隔。\nHello, {{ name|capitalize }}  过滤器\nsafe 渲染值时不转义 capitalize 把值的首字母转换成大写，其他字母转换成小写 lower 把值转换成小写形式 upper 把值转换成大写形式 title 把值中每个单词的首字母都转换成大写 trim 把值的首尾空格去掉 striptags 渲染之前把值中所有的 HTML 标签都删掉  控制结构  Jinja2 提供了多种控制结构，可用来改变模板的渲染流程。\n{% 控制条件 %}   使用Flask-Bootstrap集成Twitter Bootstrap #  Bootstrap是Twitter开发的一个开源框架，它提供的用户界面组件可用于创建整洁且具有吸引力的网页，而且这些网页还能兼容所有现代 Web 浏览器。\npip install flask-bootstrap   初始化  示例\nfrom flask.ext.bootstrap import Bootstrap bootstrap = Bootstrap(app)   自定义错误页面 #  @app.errorhandler(404) def page_not_found(e): return render_template('404.html'), 404 @app.errorhandler(500) def internal_server_error(e): return render_template('500.html'), 500   链接 #  Flask 提供了 url_for() 辅助函数，它可以使用程序 URL 映射中保存的信息生成 URL。\n静态文件 #   使用Flask-Moment本地化日期和时间 #  示例\npip install flask-moment from flask.ext.moment import Moment moment = Moment(app) {% block scripts %} {{ super() }} {{ moment.include_moment() }} {% endblock %} \u0026lt;p\u0026gt;The local date and time is {{ moment(current_time).format('LLL') }}.\u0026lt;/p\u0026gt;   WEB表单 #  示例\npip install flask-wtf from flask.ext.wtf import Form from wtforms import StringField, SubmitField from wtforms.validators import Required class NameForm(Form): name = StringField('What is your name?', validators=[Required()]) submit = SubmitField('Submit')  表单渲染\n{% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {{ wtf.quick_form(form) }}  视图处理表单：\nform = NameForm() return render_template('index.html', form=form)   数据库 #  初始化\npip install flask-sqlalchemy from flask.ext.sqlalchemy import SQLAlchemy basedir = os.path.abspath(os.path.dirname(__file__)) app = Flask(__name__) app.config['SQLALCHEMY_DATABASE_URI'] =\\ 'sqlite:///' + os.path.join(basedir, 'data.sqlite') app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True db = SQLAlchemy(app)  模型定义\nclass Role(db.Model): __tablename__ = 'roles' id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) def __repr__(self): return '\u0026lt;Role %r\u0026gt;' % self.name  创建表\ndb.create_all()  插入行\nfrom hello import Role admin_role = Role(name='Admin') db.session.add(admin_role) db.session.commit()   电子邮件 #  pip install flask-mail   项目结构 #  多文件 Flask 程序的基本结构\nflasky\n app/  templates/ static/ main/  init.py errors.py forms.py views.py   init.py email.py models.py   migrations/ tests/  init.py test*.py   venv/ requirements.txt config.py manage.py  这种结构有 4 个顶级文件夹：\n Flask 程序一般都保存在名为 app 的包中； 和之前一样，migrations 文件夹包含数据库迁移脚本； 单元测试编写在 tests 包中； 和之前一样，venv 文件夹包含 Python 虚拟环境。 同时还创建了一些新文件： requirements.txt 列出了所有依赖包，便于在其他电脑中重新生成相同的虚拟环境； config.py 存储配置； manage.py 用于启动程序以及其他的程序任务。  "});index.add({'id':118,'href':'/notes/docs/technology/program/Language/python/Framework/Scrapy/scrapy/','title':"Scrapy",'content':"#Scrapy Scrapy是一个快速的高级Web爬网和Web抓取框架，用于抓取网站并从其页面提取结构化数据。\n安装 #  pip install scrapy scrapy startproject scrapytest   第一个爬虫 #  "});index.add({'id':119,'href':'/notes/docs/technology/security/Firewall/firewalld/','title':"Firewalld",'content':"Firewalld #  firewalld是CentOS7默认的防火墙服务，用于管理网络数据包的流动和转发。\n 基础命令 #    启动\n $ systemctl start firewalld.service    查看状态\n $ systemctl status firewalld.service    关闭\n $ systemctl stop firewalld.service    开启和关闭开机启动\n $ systemctl enable firewalld.service $ systemctl disable firewalld.service    Rule配置：firewall-cmd命令\n   Options Description     -h, \u0026ndash;help Prints a short help text and exists   -V, \u0026ndash;version Print the version string of firewalld   -q, \u0026ndash;quiet Do not print status messages   \u0026ndash;state Return and print firewalld state   \u0026ndash;reload Reload firewall and keep state information   \u0026ndash;complete-reload Reload firewall and loose state information   \u0026ndash;runtime-to-permanent Create permanent from runtime configuration   \u0026ndash;permanent Set an option permanently   \u0026ndash;zone=\u0026lt;zone\u0026gt; Use this zone to set or query options, else default zone   \u0026ndash;timeout=\u0026lt;timeval\u0026gt; Enable an option for timeval time, where timeval is,a number followed by one of letters \u0026rsquo;s\u0026rsquo; or \u0026rsquo;m\u0026rsquo; or \u0026lsquo;h\u0026rsquo;       概念 #  区域(Zones) #  一个规则管理群组的概念，定义了可信任级别。其中预先定义的zones有以下几个：\n  drop\n最低信任级别，任何流入网络的包都被丢弃，不作出任何响应。只允许流出的网络连接。\n  block\n任何进入的网络连接都被拒绝，并返回 IPv4 的 icmp-host-prohibited 报文或者 IPv6 的 icmp6-adm-prohibited 报文。只允许由该系统初始化的网络连接。\n  public\n用以可以公开的部分。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。\n  external\n用在路由器等启用伪装的外部网络。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。\n  internal\n用在内部网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。\n  dmz\n用以允许隔离区（dmz）中的电脑有限地被外界网络访问。只接受被选中的连接。\n  work\n用在工作网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。\n  home\n用在家庭网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。\n  trusted\n允许所有网络连接。\n  服务(service) #  服务是端口和/或协议入口的组合。备选内容包括 netfilter 助手模块以及 IPv4、IPv6地址。\n端口和协议(port/protocol) #  定义了 tcp 或 udp 端口，端口可以是一个端口或者端口范围。\nICMP阻塞 #  可以选择 Internet 控制报文协议的报文。这些报文可以是信息请求亦可是对信息请求或错误条件创建的响应.\n伪装 #  私有网络地址可以被映射到公开的IP地址。这是一次正规的地址转换。\n端口转发 #  端口可以映射到另一个端口以及/或者其他主机。\n 配置文件 #    区域配置文件\n /usr/lib/firewalld/zones(原始文件目录)    配置文件目录\n /etc/firewalld/zones    配置文件格式\n \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;utf-8\u0026quot;?\u0026gt; \u0026lt;zone\u0026gt; \u0026lt;short\u0026gt;Public\u0026lt;/short\u0026gt; \u0026lt;!--区域名称--\u0026gt; \u0026lt;description\u0026gt;For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted.\u0026lt;/description\u0026gt; \u0026lt;service name=\u0026quot;dhcpv6-client\u0026quot;/\u0026gt; \u0026lt;service name=\u0026quot;ssh\u0026quot;/\u0026gt; \u0026lt;!--服务名称,调用ssh服务配置文件--\u0026gt; \u0026lt;port protocol=\u0026quot;tcp\u0026quot; port=\u0026quot;2222\u0026quot;/\u0026gt; \u0026lt;!--协议、端口--\u0026gt; \u0026lt;/zone\u0026gt;      服务配置文件\n /usr/lib/firewalld/services (原始文件目录)    配置文件目录\n /etc/firewalld/zones (zones优先调用目录)    配置文件格式\n \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;utf-8\u0026quot;?\u0026gt; \u0026lt;service\u0026gt; \u0026lt;short\u0026gt;SSH\u0026lt;/short\u0026gt; \u0026lt;!--服务名称--\u0026gt; \u0026lt;description\u0026gt;Secure Shell (SSH) is a protocol for logging into and executing commands on remote machines. It provides secure encrypted communications. If you plan on accessing your machine remotely via SSH over a firewalled interface, enable this option. You need the openssh-server package installed for this option to be useful.\u0026lt;/description\u0026gt; \u0026lt;port protocol=\u0026quot;tcp\u0026quot; port=\u0026quot;22\u0026quot;/\u0026gt; \u0026lt;!--配置协议端口--\u0026gt; \u0026lt;/service\u0026gt;      "});index.add({'id':120,'href':'/notes/docs/technology/security/Firewall/iptables/','title':"Iptables",'content':"Iptables #  iptables：一个运行在用户空间的应用软件，通过控制Linux内核netfilter模块，来管理网络数据包的流动与转送。\nNetfilter：Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：\n  网络地址转换(Network Address Translate)\n  数据包内容修改\n  数据包过滤\n  Netfilter的配置表：存放设置的规则的文件，存放在内核内存中。iptables程序通过修改这个规则文件来控制网络数据包流动。 该配置表由表tables、链chains、规则rules组成。\n Netfilter配置表 #  表(tables) #  用于实现特定的功能\n  raw表\n主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链 OUTPUT、PREROUTING。\niptables中数据包和4种被跟踪连接的4种不同状态：\n NEW：该包想要开始一个连接（重新连接或将连接重定向） RELATED：该包是属于某个已经建立的连接所建立的新连接。 ESTABLISHED ：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。 INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。    mangle表\n主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。\n  nat表\n主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包 的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。\n表对应的内核模块为 iptable_nat，包含三个链：\n PREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址 OUTPUT链：改变本地产生的包的目的地址 POSTROUTING链：在包就要离开防火墙之前改变其源地址    filter表\n主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptable_filter，包含三个规则链：\n INPUT链：INPUT针对那些目的地是本地的包 FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包 OUTPUT链：OUTPUT是用来过滤所有本地生成的包    链(chains) #  在处理各种数据包时，根据防火墙规则的不同介入时机，iptables供涉及5种默认规则链，从应用时间点的角度理解这些链：\n  INPUT链：当接收到防火墙本机地址的数据包（入站）时，应用此链中的规则。\n  OUTPUT链：当防火墙本机向外发送数据包（出站）时，应用此链中的规则。\n  FORWARD链：当接收到需要通过防火墙发送给其他地址的数据包（转发）时，应用此链中的规则。\n  PREROUTING链：在对数据包作路由选择之前，应用此链中的规则，如DNAT。\n  POSTROUTING链：在对数据包作路由选择之后，应用此链中的规则，如SNAT。\n  规则(rules) #    ACCEPT：允许数据包通过\n  DROP：直接丢弃数据包，不给任何回应信息\n  REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息。\n  SNAT：源地址转换。在进入路由层面的route之前，重新改写源地址，目标地址不变，并在本机建立NAT表项，当数据返回时，根据NAT表将 目的地址数据改写为数据发送出去时候的源地址，并发送给主机。解决内网用户用同一个公网地址上网的问题。 MASQUERADE，是SNAT的一种特殊形式，适用于像adsl这种临时会变的ip上\n  DNAT:目标地址转换。和SNAT相反，IP包经过route之后、出本地的网络栈之前，重新修改目标地址，源地址不变，在本机建立NAT表项，当 数据返回时，根据NAT表将源地址修改为数据发送过来时的目标地址，并发给远程主机。可以隐藏后端服务器的真实地址。 REDIRECT：是DNAT的一种特殊形式，将网络包转发到本地host上（不管IP头部指定的目标地址是啥），方便在本机做端口转发。\n  LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则\n  除去最后一个LOG，前3条规则匹配数据包后，该数据包不会再往下继续匹配了，所以编写的规则顺序极其关键。\n 原理 #     从上图中，我们可以总结出以下规律：\n  一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转发出去。\n  如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经 过OUTPUT链，然后到达POSTROUTING链输出。\n  如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过 FORWARD链，然后到达POSTROUTING链输出。\n   规则编写 #  命令格式：iptables -t TABLE command CHAIN parameter match -j TARGET\n    command 描述     -P \u0026ndash;policy 定义默认策略   -L \u0026ndash;list 查看iptables规则列表   -A \u0026ndash;append 在规则列表的最后增加1条规则   -I \u0026ndash;insert 在指定的位置插入1条规则   -D \u0026ndash;delete 从规则列表中删除1条规则   -R \u0026ndash;replace 替换规则列表中的某条规则   -F \u0026ndash;flush 删除表中所有规则   -Z \u0026ndash;zero 将表中数据包计数器和流量计数器归零   -X \u0026ndash;delete-chain 删除自定义链   -v \u0026ndash;verbose 与-L他命令一起使用显示更多更详细的信息   -nL 查看当前运行的防火墙规则列表       parameter match 描述     -i \u0026ndash;in-interface 网络接口名\u0026gt; 指定数据包从哪个网络接口进入，   -o \u0026ndash;out-interface 网络接口名\u0026gt; 指定数据包从哪个网络接口输出   -p \u0026mdash;proto 协议类型 指定数据包匹配的协议，如TCP、UDP和ICMP等   -s \u0026ndash;source 源地址或子网\u0026gt; 指定数据包匹配的源地址   \u0026ndash;sport 源端口号\u0026gt; 指定数据包匹配的源端口号   -d \u0026ndash;destination 目的地址或子网\u0026gt; 指定数据包匹配的目的地址   \u0026ndash;dport 目的端口号\u0026gt; 指定数据包匹配的目的端口号   -m \u0026ndash;match 匹配的模块 指定数据包规则所使用的过滤模块    -m：extend matches，这个选项用于提供更多的匹配参数，如：\n-m state –-state ESTABLISHED,RELATED -m tcp –-dport 22 -m multiport –-dports 80,8080 -m icmp –-icmp-type 8   "});index.add({'id':121,'href':'/notes/docs/technology/system/Linux/guideBook/fileOperation/','title':"File Operation",'content':"一切皆文件 #    列出文件列表\n ls [option] /PATH #不指定路径，默认为当前路径 option -l:长格式 文件类型: -:普通文件 d:目录文件 b:块设备文件（block） c：字符设备文件（character） l：符号链接文件（symbolic link file） p：命令管道（pipe） s：套接字文件（socket） 文件权限：9位，每三位一组(u-g-o),每一组：rwx（读、写、执行） 文件硬链接的次数 文件的属主(owner) 文件的属组(group) 文件的大小(size)，单位是字节 时间戳(timestamp)：最近一次被修改的时间 访问：access 修改：modify，文件内容发生改变 改变：change，metadata，元数据 文件名 -h:做单位转换，默认bit -a:显示以.开头的隐藏文件 . 表示当前目录 .. 表示父目录 -d：显示目录自身属性 -i：index node，inode -r：逆序显示文件 -R：递归(recursive)显示    进入目录\n cd /PATH cd ~USERNAME:进入指定用户的家目录 cd -:在当前目录和前一次所在目录之间来回切换    显示文件类型\n type /PATH/FILENAME    显示当前路径\n pwd    目录管理\n  创建空目录\n mkdir [option] /PATH option -p:若父目录不存在，则自动创建 -v:列出过程详细信息 -m:指定目录权限    删除空目录\n rmdir /PATH      文件管理\n  创建文件\n touch [option] /PATH option:若文件存在 -a:修改访问时间 -m:修改修改时间 -c:修改改变时间    查看文件状态\n stat /PATH    删除文件\n rm [option] /PATH option -i:提示 -f:强制删除，不提示 -r:递归删除    复制文件\n cp [option] SRC DEST option -r:递归 -i:提示是否覆盖 -p:保留属性 -a:归档复制，保留所有属性    移动文件\n mv SRC DEST      文本查看\n  连接并显示\n cat [option] /PATH/FILENAME option -n:显示行号 -E:显示行尾    分屏显示\n more /PATH/FILENAME less /PATH/FILENAME head [option] /PATH/FILENAME option -n number:显示前n行 tail [option] /PATH/FILENAME option -n number:显示后n行 -f:查看文件尾部，不退出，等待显示后续追加至此文件的新内容      文本处理\n  文本分割\n cut [option] /PATH/FILENAME option -d:指定分隔符，默认是空格 -f number:指定要显示的字段    文本排序\n sort [option] /PATH/FILENAME option -n:数值排序 -r:降序 #默认为升序 -t:字段分隔符 -k:以哪个字段为关键字进行排序 -u:排序后相同的行只显示一次    文本去重\n uniq [option] /PATH/FILENAME option -c:只显示文件中行重复的次数 -d:只显示重复的行    文本统计\n wc [option] /PATH/FILENAME option -l:统计行数 -w:统计单词数 -c:统计字符数 -L:打印最长的行    字符转换\n tr [option] SET1 [SET2] option -d:删除出现在字符集中的所有字符      "});index.add({'id':122,'href':'/notes/docs/technology/system/Linux/guideBook/permissionsOperation/','title':"Permissions Operation",'content':"权限操作 #  权限 #    可读(r)(4)\n  可写(w)(2)\n  可执行(x)(1)\n  特殊权限\n  SUID(u+s): 运行某程序时，相应进程的属主是程序文件自身的属主\n  SGID(g+s)：运行某程序时，相应进程的属组是程序文件自身的属组\n  Sticky(o+t)：在一个公共目录，每个用户都可以创建删除自己的文件，但不能删除别人的文件\n     用户和组 #    用户(UID)\n  类别\n  管理员：0\n  普通用户：1-65535\n  系统用户：1-499\n  一般用户：500-65535\n      配置文件\n  /etc/passwd\n字段详解(以\u0026rdquo;:\u0026ldquo;为分割符)\n用户名 : 密码 : UID : GID : 注释 : 家目录 : 默认shell\n  /etc/shadow\n字段详解(以\u0026rdquo;:\u0026ldquo;为分隔符)\n用户名 : 密码 : 最近一次修改密码时间 : 最短使用期限 : 最长使用期限 : 警告时间 : 非活动时间 : 过期时间\n      组(GID)\n  类别\n  私有组：创建用户时，没指定所组，则系统默认创建同名组\n  基本组：用户的默认组\n  附加组：\n    配置文件\n  /etc/group\n字段详解(以\u0026rdquo;:\u0026ldquo;为分隔符)\n组名 : 密码 : GID : 以此组为其附加组的用户列表\n  /etc/gshadow\n       用户管理 #    添加用户\n useradd [options] USERNAME option -u：UID -g：groupname 指定基本组 -G：groupname,... 指定附加组 -c：\u0026quot;COMMENT\u0026quot; -d：指定家目录 -s：指定SHELL路径 -m -k：若家目录不存在，则自动创建 -r：添加系统用户    删除用户\n userdel [options] USERNAME option -r：同时删除用户的家目录    查看用户的帐号属性信息\n id [options] USERNAME option -u：查看UID -g：查看GID -G: 查看所有的GID -n：查看组名 finger USERNAME    修改用户帐号属性\n usermod [options] USERNAME option -u：UID -g：GID -a -g GID：不使用-a选项，会覆盖此前的附加组 -d -m：指定新的家目录，并把之前家目录的文件拷贝到新的家目录中 -c： -s：指定SHELL路径 -L：锁定帐号 -U：解锁帐号    密码管理\n passwd [USERNAME] --stdin：标准输入 -d：删除用户密码    检查用户帐号完整性\n pwck     组管理 #    创建用户组：\n groupadd [option] GROUPNAME -g：GID -r：添加为系统组    修改组的相关属性\n groupmod [option] GROUPNAME -g：GID -n：GRPNAME    删除组\n groupdel GROUPNAME    更改组密码\n gpasswd GROUPNAME     权限管理 #    改变文件属主\n chown USERNAME file,... -R：修改目录及其内部文件的属主 --reference=/path/to/somefile file,... 指定属主与该文件相同 chown USERNAME:GROUPNAME file chown USERNAME.GROUPNAME file    改变属组\n chgrp GROUPNAME file,...    修改文件的权限\n chmod MODE file,... -R： --reference=/path/to/somefile 修改单个用户的权限：u,g,o,a chmod 用户类别+|-MODE file,...     "});index.add({'id':123,'href':'/notes/docs/','title':"Docs",'content':""});})();